{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#CIFAR100"
      ],
      "metadata": {
        "id": "Pe9EjW6fukVG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90TRrimFstfu",
        "outputId": "9fe1bb98-8b3b-422f-e9aa-a28acf3d2a55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'l2p-pytorch'...\n",
            "remote: Enumerating objects: 172, done.\u001b[K\n",
            "remote: Counting objects: 100% (172/172), done.\u001b[K\n",
            "remote: Compressing objects: 100% (134/134), done.\u001b[K\n",
            "remote: Total 172 (delta 91), reused 105 (delta 37), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (172/172), 67.80 KiB | 5.21 MiB/s, done.\n",
            "Resolving deltas: 100% (91/91), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/JH-LEE-KR/l2p-pytorch\n",
        "!cd l2p-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /content/l2p-pytorch/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 939
        },
        "id": "vfW9EfPptjAf",
        "outputId": "dff1417b-ead2-4e1f-8418-fd5434918120"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting timm==0.6.7\n",
            "  Downloading timm-0.6.7-py3-none-any.whl (509 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.0/510.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow==9.2.0\n",
            "  Downloading Pillow-9.2.0-cp39-cp39-manylinux_2_28_x86_64.whl (3.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting matplotlib==3.5.3\n",
            "  Downloading matplotlib-3.5.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchprofile==0.0.4\n",
            "  Downloading torchprofile-0.0.4-py3-none-any.whl (7.7 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from timm==0.6.7->-r /content/l2p-pytorch/requirements.txt (line 1)) (0.15.1+cu118)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.9/dist-packages (from timm==0.6.7->-r /content/l2p-pytorch/requirements.txt (line 1)) (2.0.0+cu118)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.5.3->-r /content/l2p-pytorch/requirements.txt (line 3)) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.5.3->-r /content/l2p-pytorch/requirements.txt (line 3)) (23.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.5.3->-r /content/l2p-pytorch/requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.5.3->-r /content/l2p-pytorch/requirements.txt (line 3)) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.5.3->-r /content/l2p-pytorch/requirements.txt (line 3)) (4.39.3)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.5.3->-r /content/l2p-pytorch/requirements.txt (line 3)) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.5.3->-r /content/l2p-pytorch/requirements.txt (line 3)) (1.4.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib==3.5.3->-r /content/l2p-pytorch/requirements.txt (line 3)) (1.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.4->timm==0.6.7->-r /content/l2p-pytorch/requirements.txt (line 1)) (3.12.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.4->timm==0.6.7->-r /content/l2p-pytorch/requirements.txt (line 1)) (3.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.4->timm==0.6.7->-r /content/l2p-pytorch/requirements.txt (line 1)) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.4->timm==0.6.7->-r /content/l2p-pytorch/requirements.txt (line 1)) (2.0.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.4->timm==0.6.7->-r /content/l2p-pytorch/requirements.txt (line 1)) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.4->timm==0.6.7->-r /content/l2p-pytorch/requirements.txt (line 1)) (1.11.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.4->timm==0.6.7->-r /content/l2p-pytorch/requirements.txt (line 1)) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.4->timm==0.6.7->-r /content/l2p-pytorch/requirements.txt (line 1)) (16.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision->timm==0.6.7->-r /content/l2p-pytorch/requirements.txt (line 1)) (2.27.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.4->timm==0.6.7->-r /content/l2p-pytorch/requirements.txt (line 1)) (2.1.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->timm==0.6.7->-r /content/l2p-pytorch/requirements.txt (line 1)) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->timm==0.6.7->-r /content/l2p-pytorch/requirements.txt (line 1)) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->timm==0.6.7->-r /content/l2p-pytorch/requirements.txt (line 1)) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->timm==0.6.7->-r /content/l2p-pytorch/requirements.txt (line 1)) (2.0.12)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.4->timm==0.6.7->-r /content/l2p-pytorch/requirements.txt (line 1)) (1.3.0)\n",
            "Installing collected packages: pillow, matplotlib, torchprofile, timm\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 8.4.0\n",
            "    Uninstalling Pillow-8.4.0:\n",
            "      Successfully uninstalled Pillow-8.4.0\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.7.1\n",
            "    Uninstalling matplotlib-3.7.1:\n",
            "      Successfully uninstalled matplotlib-3.7.1\n",
            "Successfully installed matplotlib-3.5.3 pillow-9.2.0 timm-0.6.7 torchprofile-0.0.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Xv1qg6OpQvM",
        "outputId": "655771bb-e3d5-40bc-da2f-5a5d3303f25c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/Shareddrives/Colab/AIP_PROJECT/l2p_configs_files.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vm3QGoxWpc_H",
        "outputId": "911cbf0a-b806-4720-d8f5-bb360f2a2ad7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/Shareddrives/Colab/AIP_PROJECT/l2p_configs_files.zip\n",
            "  inflating: cifar100_l2p.py         \n",
            "  inflating: datasets.py             \n",
            "  inflating: Imagenet_R.py           \n",
            "  inflating: main.py                 \n",
            "  inflating: TinyImagenet.py         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm /content/l2p-pytorch/main.py\n",
        "!rm /content/l2p-pytorch/datasets.py\n",
        "!rm /content/l2p-pytorch/configs/cifar100_l2p.py\n",
        "!cp /content/cifar100_l2p.py /content/l2p-pytorch/configs/cifar100_l2p.py\n",
        "!cp /content/TinyImagenet.py /content/l2p-pytorch/configs/TinyImagenet.py\n",
        "!cp /content/Imagenet_R.py /content/l2p-pytorch/configs/Imagenet_R.py\n",
        "!cp /content/datasets.py /content/l2p-pytorch/datasets.py\n",
        "!cp /content/main.py /content/l2p-pytorch/main.py"
      ],
      "metadata": {
        "id": "S8X6GXjIovvt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m torch.distributed.launch \\\n",
        "        --nproc_per_node=1 \\\n",
        "        --use_env /content/l2p-pytorch/main.py \\\n",
        "        cifar100_l2p \\\n",
        "        --model vit_base_patch16_224 \\\n",
        "        --batch-size 16 \\\n",
        "        --data-path /local_datasets/ \\\n",
        "        --output_dir ./output "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YB7KPZw1tpvm",
        "outputId": "75116c77-7c22-451d-c52e-a15da416ce31"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated\n",
            "and will be removed in future. Use torchrun.\n",
            "Note that --use-env is set by default in torchrun.\n",
            "If your script expects `--local-rank` argument to be set, please\n",
            "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
            "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
            "further instructions\n",
            "\n",
            "  warnings.warn(\n",
            "MAIN OK\n",
            "| distributed init (rank 0): env://\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to /local_datasets/cifar-100-python.tar.gz\n",
            "100% 169001437/169001437 [00:02<00:00, 73011877.22it/s]\n",
            "Extracting /local_datasets/cifar-100-python.tar.gz to /local_datasets/\n",
            "Files already downloaded and verified\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Creating original model: vit_base_patch16_224\n",
            "Creating model: vit_base_patch16_224\n",
            "Namespace(subparser_name='cifar100_l2p', batch_size=16, epochs=5, model='vit_base_patch16_224', input_size=224, pretrained=True, drop=0.0, drop_path=0.0, opt='adam', opt_eps=1e-08, opt_betas=(0.9, 0.999), clip_grad=1.0, momentum=0.9, weight_decay=0.0, reinit_optimizer=True, sched='constant', lr=0.03, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, unscale_lr=True, color_jitter=None, aa=None, smoothing=0.1, train_interpolation='bicubic', reprob=0.0, remode='pixel', recount=1, data_path='/local_datasets/', dataset='Split-CIFAR100', name='Split-CIFAR100', shuffle=False, output_dir='./output', device='cuda', seed=42, eval=False, num_workers=4, pin_mem=True, world_size=1, dist_url='env://', num_tasks=10, train_mask=True, task_inc=False, prompt_pool=True, size=10, length=5, top_k=5, initializer='uniform', prompt_key=True, prompt_key_init='uniform', use_prompt_mask=False, shared_prompt_pool=False, shared_prompt_key=False, batchwise_prompt=True, embedding_key='cls', predefined_key='', pull_constraint=True, pull_constraint_coeff=0.1, global_pool='token', head_type='prompt', freeze=['blocks', 'patch_embed', 'cls_token', 'norm', 'pos_embed'], print_freq=10, rank=0, gpu=0, distributed=True, dist_backend='nccl', nb_classes=100)\n",
            "number of params: 122980\n",
            "Start training for 5 epochs\n",
            "Train: Epoch[1/5]  [  0/313]  eta: 0:14:45  Lr: 0.001875  Loss: 2.3091  Acc@1: 25.0000 (25.0000)  Acc@5: 43.7500 (43.7500)  time: 2.8292  data: 0.2444  max mem: 2371\n",
            "Train: Epoch[1/5]  [ 10/313]  eta: 0:03:54  Lr: 0.001875  Loss: 2.0322  Acc@1: 43.7500 (40.9091)  Acc@5: 75.0000 (73.2955)  time: 0.7752  data: 0.0225  max mem: 2372\n",
            "Train: Epoch[1/5]  [ 20/313]  eta: 0:03:20  Lr: 0.001875  Loss: 1.8641  Acc@1: 50.0000 (52.0833)  Acc@5: 81.2500 (80.0595)  time: 0.5774  data: 0.0015  max mem: 2372\n",
            "Train: Epoch[1/5]  [ 30/313]  eta: 0:03:05  Lr: 0.001875  Loss: 1.7420  Acc@1: 62.5000 (55.2419)  Acc@5: 93.7500 (84.4758)  time: 0.5886  data: 0.0016  max mem: 2372\n",
            "Train: Epoch[1/5]  [ 40/313]  eta: 0:02:54  Lr: 0.001875  Loss: 1.3590  Acc@1: 62.5000 (59.9085)  Acc@5: 93.7500 (87.0427)  time: 0.5924  data: 0.0020  max mem: 2372\n",
            "Train: Epoch[1/5]  [ 50/313]  eta: 0:02:46  Lr: 0.001875  Loss: 1.3117  Acc@1: 75.0000 (62.2549)  Acc@5: 93.7500 (88.6029)  time: 0.5970  data: 0.0027  max mem: 2372\n",
            "Train: Epoch[1/5]  [ 60/313]  eta: 0:02:38  Lr: 0.001875  Loss: 1.3754  Acc@1: 75.0000 (63.7295)  Acc@5: 93.7500 (89.2418)  time: 0.6054  data: 0.0015  max mem: 2372\n",
            "Train: Epoch[1/5]  [ 70/313]  eta: 0:02:32  Lr: 0.001875  Loss: 1.0878  Acc@1: 75.0000 (65.3169)  Acc@5: 93.7500 (90.1408)  time: 0.6153  data: 0.0024  max mem: 2372\n",
            "Train: Epoch[1/5]  [ 80/313]  eta: 0:02:26  Lr: 0.001875  Loss: 0.9611  Acc@1: 81.2500 (67.2840)  Acc@5: 100.0000 (91.0494)  time: 0.6261  data: 0.0021  max mem: 2372\n",
            "Train: Epoch[1/5]  [ 90/313]  eta: 0:02:20  Lr: 0.001875  Loss: 0.9141  Acc@1: 75.0000 (67.9258)  Acc@5: 93.7500 (91.4148)  time: 0.6303  data: 0.0027  max mem: 2372\n",
            "Train: Epoch[1/5]  [100/313]  eta: 0:02:13  Lr: 0.001875  Loss: 0.9710  Acc@1: 81.2500 (69.3069)  Acc@5: 100.0000 (92.0173)  time: 0.6337  data: 0.0027  max mem: 2372\n",
            "Train: Epoch[1/5]  [110/313]  eta: 0:02:08  Lr: 0.001875  Loss: 1.1615  Acc@1: 81.2500 (69.8761)  Acc@5: 93.7500 (92.2297)  time: 0.6438  data: 0.0017  max mem: 2372\n",
            "Train: Epoch[1/5]  [120/313]  eta: 0:02:02  Lr: 0.001875  Loss: 0.9606  Acc@1: 75.0000 (70.4545)  Acc@5: 93.7500 (92.7169)  time: 0.6568  data: 0.0018  max mem: 2372\n",
            "Train: Epoch[1/5]  [130/313]  eta: 0:01:56  Lr: 0.001875  Loss: 0.6941  Acc@1: 81.2500 (71.1832)  Acc@5: 100.0000 (93.1775)  time: 0.6717  data: 0.0023  max mem: 2372\n",
            "Train: Epoch[1/5]  [140/313]  eta: 0:01:50  Lr: 0.001875  Loss: 0.3180  Acc@1: 81.2500 (72.0745)  Acc@5: 100.0000 (93.5284)  time: 0.6837  data: 0.0026  max mem: 2372\n",
            "Train: Epoch[1/5]  [150/313]  eta: 0:01:44  Lr: 0.001875  Loss: 0.5495  Acc@1: 81.2500 (72.7235)  Acc@5: 100.0000 (93.7914)  time: 0.6838  data: 0.0014  max mem: 2372\n",
            "Train: Epoch[1/5]  [160/313]  eta: 0:01:38  Lr: 0.001875  Loss: 0.7476  Acc@1: 81.2500 (73.0590)  Acc@5: 100.0000 (94.0606)  time: 0.6739  data: 0.0014  max mem: 2372\n",
            "Train: Epoch[1/5]  [170/313]  eta: 0:01:32  Lr: 0.001875  Loss: 0.7472  Acc@1: 81.2500 (73.6111)  Acc@5: 100.0000 (94.2617)  time: 0.6639  data: 0.0013  max mem: 2372\n",
            "Train: Epoch[1/5]  [180/313]  eta: 0:01:25  Lr: 0.001875  Loss: 0.8324  Acc@1: 81.2500 (73.7224)  Acc@5: 100.0000 (94.4751)  time: 0.6557  data: 0.0026  max mem: 2372\n",
            "Train: Epoch[1/5]  [190/313]  eta: 0:01:19  Lr: 0.001875  Loss: 0.8964  Acc@1: 81.2500 (74.3783)  Acc@5: 100.0000 (94.6008)  time: 0.6492  data: 0.0020  max mem: 2372\n",
            "Train: Epoch[1/5]  [200/313]  eta: 0:01:13  Lr: 0.001875  Loss: 0.7813  Acc@1: 81.2500 (74.7201)  Acc@5: 93.7500 (94.5274)  time: 0.6460  data: 0.0015  max mem: 2372\n",
            "Train: Epoch[1/5]  [210/313]  eta: 0:01:06  Lr: 0.001875  Loss: 0.6250  Acc@1: 75.0000 (74.9111)  Acc@5: 93.7500 (94.6979)  time: 0.6460  data: 0.0022  max mem: 2372\n",
            "Train: Epoch[1/5]  [220/313]  eta: 0:01:00  Lr: 0.001875  Loss: 0.5610  Acc@1: 75.0000 (75.1131)  Acc@5: 100.0000 (94.8529)  time: 0.6466  data: 0.0020  max mem: 2372\n",
            "Train: Epoch[1/5]  [230/313]  eta: 0:00:53  Lr: 0.001875  Loss: 0.8455  Acc@1: 81.2500 (75.2165)  Acc@5: 100.0000 (95.0487)  time: 0.6493  data: 0.0039  max mem: 2372\n",
            "Train: Epoch[1/5]  [240/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.4866  Acc@1: 87.5000 (75.9077)  Acc@5: 100.0000 (95.2023)  time: 0.6536  data: 0.0047  max mem: 2372\n",
            "Train: Epoch[1/5]  [250/313]  eta: 0:00:40  Lr: 0.001875  Loss: 0.2145  Acc@1: 87.5000 (76.0956)  Acc@5: 100.0000 (95.2938)  time: 0.6577  data: 0.0020  max mem: 2372\n",
            "Train: Epoch[1/5]  [260/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.3066  Acc@1: 81.2500 (76.4128)  Acc@5: 100.0000 (95.4023)  time: 0.6613  data: 0.0015  max mem: 2372\n",
            "Train: Epoch[1/5]  [270/313]  eta: 0:00:27  Lr: 0.001875  Loss: 0.0766  Acc@1: 81.2500 (76.5913)  Acc@5: 100.0000 (95.5028)  time: 0.6625  data: 0.0022  max mem: 2372\n",
            "Train: Epoch[1/5]  [280/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.2381  Acc@1: 87.5000 (76.8906)  Acc@5: 100.0000 (95.6628)  time: 0.6623  data: 0.0014  max mem: 2372\n",
            "Train: Epoch[1/5]  [290/313]  eta: 0:00:14  Lr: 0.001875  Loss: 0.3271  Acc@1: 81.2500 (76.9330)  Acc@5: 100.0000 (95.6830)  time: 0.6603  data: 0.0023  max mem: 2372\n",
            "Train: Epoch[1/5]  [300/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.7465  Acc@1: 81.2500 (77.1802)  Acc@5: 100.0000 (95.7434)  time: 0.6573  data: 0.0020  max mem: 2372\n",
            "Train: Epoch[1/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.4520  Acc@1: 81.2500 (77.2508)  Acc@5: 93.7500 (95.7596)  time: 0.6555  data: 0.0012  max mem: 2372\n",
            "Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.6269  Acc@1: 81.2500 (77.2200)  Acc@5: 93.7500 (95.7800)  time: 0.6421  data: 0.0012  max mem: 2372\n",
            "Train: Epoch[1/5] Total time: 0:03:23 (0.6490 s / it)\n",
            "Averaged stats: Lr: 0.001875  Loss: 0.6269  Acc@1: 81.2500 (77.2200)  Acc@5: 93.7500 (95.7800)\n",
            "Train: Epoch[2/5]  [  0/313]  eta: 0:04:17  Lr: 0.001875  Loss: 0.2454  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.8231  data: 0.2128  max mem: 2372\n",
            "Train: Epoch[2/5]  [ 10/313]  eta: 0:03:23  Lr: 0.001875  Loss: 0.6784  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (96.0227)  time: 0.6702  data: 0.0208  max mem: 2372\n",
            "Train: Epoch[2/5]  [ 20/313]  eta: 0:03:13  Lr: 0.001875  Loss: 0.2386  Acc@1: 81.2500 (81.5476)  Acc@5: 100.0000 (97.0238)  time: 0.6536  data: 0.0030  max mem: 2372\n",
            "Train: Epoch[2/5]  [ 30/313]  eta: 0:03:06  Lr: 0.001875  Loss: 0.4108  Acc@1: 87.5000 (82.6613)  Acc@5: 100.0000 (97.1774)  time: 0.6528  data: 0.0024  max mem: 2372\n",
            "Train: Epoch[2/5]  [ 40/313]  eta: 0:02:59  Lr: 0.001875  Loss: 0.3857  Acc@1: 87.5000 (83.9939)  Acc@5: 100.0000 (97.1037)  time: 0.6545  data: 0.0029  max mem: 2372\n",
            "Train: Epoch[2/5]  [ 50/313]  eta: 0:02:52  Lr: 0.001875  Loss: 0.0765  Acc@1: 87.5000 (84.4363)  Acc@5: 100.0000 (97.5490)  time: 0.6546  data: 0.0029  max mem: 2372\n",
            "Train: Epoch[2/5]  [ 60/313]  eta: 0:02:46  Lr: 0.001875  Loss: 0.2102  Acc@1: 87.5000 (84.7336)  Acc@5: 100.0000 (97.5410)  time: 0.6546  data: 0.0025  max mem: 2372\n",
            "Train: Epoch[2/5]  [ 70/313]  eta: 0:02:39  Lr: 0.001875  Loss: 0.6450  Acc@1: 81.2500 (84.1549)  Acc@5: 100.0000 (97.7993)  time: 0.6559  data: 0.0025  max mem: 2372\n",
            "Train: Epoch[2/5]  [ 80/313]  eta: 0:02:33  Lr: 0.001875  Loss: 0.1885  Acc@1: 81.2500 (83.9506)  Acc@5: 100.0000 (97.8395)  time: 0.6564  data: 0.0022  max mem: 2372\n",
            "Train: Epoch[2/5]  [ 90/313]  eta: 0:02:26  Lr: 0.001875  Loss: 0.2915  Acc@1: 81.2500 (83.8599)  Acc@5: 100.0000 (97.8709)  time: 0.6567  data: 0.0026  max mem: 2372\n",
            "Train: Epoch[2/5]  [100/313]  eta: 0:02:19  Lr: 0.001875  Loss: 0.1869  Acc@1: 87.5000 (83.9728)  Acc@5: 100.0000 (97.9579)  time: 0.6574  data: 0.0019  max mem: 2372\n",
            "Train: Epoch[2/5]  [110/313]  eta: 0:02:13  Lr: 0.001875  Loss: 0.4151  Acc@1: 87.5000 (83.8401)  Acc@5: 100.0000 (98.0293)  time: 0.6581  data: 0.0029  max mem: 2372\n",
            "Train: Epoch[2/5]  [120/313]  eta: 0:02:06  Lr: 0.001875  Loss: 0.3245  Acc@1: 81.2500 (83.6260)  Acc@5: 100.0000 (97.9855)  time: 0.6592  data: 0.0024  max mem: 2372\n",
            "Train: Epoch[2/5]  [130/313]  eta: 0:02:00  Lr: 0.001875  Loss: -0.0137  Acc@1: 87.5000 (83.9695)  Acc@5: 100.0000 (97.9008)  time: 0.6599  data: 0.0031  max mem: 2372\n",
            "Train: Epoch[2/5]  [140/313]  eta: 0:01:53  Lr: 0.001875  Loss: 0.6070  Acc@1: 87.5000 (84.0426)  Acc@5: 93.7500 (97.7837)  time: 0.6595  data: 0.0025  max mem: 2372\n",
            "Train: Epoch[2/5]  [150/313]  eta: 0:01:47  Lr: 0.001875  Loss: 0.4704  Acc@1: 81.2500 (83.9404)  Acc@5: 93.7500 (97.7649)  time: 0.6586  data: 0.0023  max mem: 2372\n",
            "Train: Epoch[2/5]  [160/313]  eta: 0:01:40  Lr: 0.001875  Loss: 0.1115  Acc@1: 81.2500 (83.8898)  Acc@5: 100.0000 (97.7484)  time: 0.6590  data: 0.0022  max mem: 2372\n",
            "Train: Epoch[2/5]  [170/313]  eta: 0:01:34  Lr: 0.001875  Loss: 0.1325  Acc@1: 87.5000 (83.9547)  Acc@5: 100.0000 (97.7705)  time: 0.6592  data: 0.0021  max mem: 2372\n",
            "Train: Epoch[2/5]  [180/313]  eta: 0:01:27  Lr: 0.001875  Loss: 0.0935  Acc@1: 81.2500 (83.8052)  Acc@5: 100.0000 (97.7210)  time: 0.6577  data: 0.0021  max mem: 2372\n",
            "Train: Epoch[2/5]  [190/313]  eta: 0:01:20  Lr: 0.001875  Loss: 0.2812  Acc@1: 81.2500 (83.9332)  Acc@5: 100.0000 (97.8076)  time: 0.6573  data: 0.0028  max mem: 2372\n",
            "Train: Epoch[2/5]  [200/313]  eta: 0:01:14  Lr: 0.001875  Loss: 0.2206  Acc@1: 81.2500 (83.8930)  Acc@5: 100.0000 (97.8856)  time: 0.6572  data: 0.0028  max mem: 2372\n",
            "Train: Epoch[2/5]  [210/313]  eta: 0:01:07  Lr: 0.001875  Loss: 0.3768  Acc@1: 87.5000 (84.1232)  Acc@5: 100.0000 (97.9265)  time: 0.6575  data: 0.0015  max mem: 2372\n",
            "Train: Epoch[2/5]  [220/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.4818  Acc@1: 87.5000 (83.9649)  Acc@5: 100.0000 (97.8507)  time: 0.6574  data: 0.0019  max mem: 2372\n",
            "Train: Epoch[2/5]  [230/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.0199  Acc@1: 81.2500 (84.1450)  Acc@5: 100.0000 (97.9167)  time: 0.6564  data: 0.0018  max mem: 2372\n",
            "Train: Epoch[2/5]  [240/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.0071  Acc@1: 87.5000 (84.2583)  Acc@5: 100.0000 (98.0031)  time: 0.6564  data: 0.0024  max mem: 2372\n",
            "Train: Epoch[2/5]  [250/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.6752  Acc@1: 81.2500 (84.2380)  Acc@5: 100.0000 (97.9582)  time: 0.6565  data: 0.0012  max mem: 2372\n",
            "Train: Epoch[2/5]  [260/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.6758  Acc@1: 81.2500 (83.9559)  Acc@5: 100.0000 (97.9167)  time: 0.6567  data: 0.0016  max mem: 2372\n",
            "Train: Epoch[2/5]  [270/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.2262  Acc@1: 81.2500 (83.9714)  Acc@5: 100.0000 (97.9474)  time: 0.6565  data: 0.0017  max mem: 2372\n",
            "Train: Epoch[2/5]  [280/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.5716  Acc@1: 81.2500 (83.9190)  Acc@5: 100.0000 (97.9315)  time: 0.6559  data: 0.0022  max mem: 2372\n",
            "Train: Epoch[2/5]  [290/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.3912  Acc@1: 81.2500 (83.9132)  Acc@5: 100.0000 (97.9167)  time: 0.6559  data: 0.0021  max mem: 2372\n",
            "Train: Epoch[2/5]  [300/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.2266  Acc@1: 87.5000 (84.0116)  Acc@5: 100.0000 (97.9651)  time: 0.6557  data: 0.0019  max mem: 2372\n",
            "Train: Epoch[2/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.4708  Acc@1: 87.5000 (84.0635)  Acc@5: 100.0000 (97.9904)  time: 0.6555  data: 0.0018  max mem: 2372\n",
            "Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1653  Acc@1: 87.5000 (84.1200)  Acc@5: 100.0000 (98.0000)  time: 0.6394  data: 0.0018  max mem: 2372\n",
            "Train: Epoch[2/5] Total time: 0:03:25 (0.6564 s / it)\n",
            "Averaged stats: Lr: 0.001875  Loss: -0.1653  Acc@1: 87.5000 (84.1200)  Acc@5: 100.0000 (98.0000)\n",
            "Train: Epoch[3/5]  [  0/313]  eta: 0:03:54  Lr: 0.001875  Loss: 0.1444  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.7504  data: 0.1366  max mem: 2372\n",
            "Train: Epoch[3/5]  [ 10/313]  eta: 0:03:21  Lr: 0.001875  Loss: 0.7582  Acc@1: 87.5000 (86.9318)  Acc@5: 100.0000 (98.2955)  time: 0.6641  data: 0.0150  max mem: 2372\n",
            "Train: Epoch[3/5]  [ 20/313]  eta: 0:03:13  Lr: 0.001875  Loss: 0.4070  Acc@1: 81.2500 (83.3333)  Acc@5: 100.0000 (98.5119)  time: 0.6546  data: 0.0015  max mem: 2372\n",
            "Train: Epoch[3/5]  [ 30/313]  eta: 0:03:06  Lr: 0.001875  Loss: 0.0670  Acc@1: 87.5000 (85.4839)  Acc@5: 100.0000 (98.7903)  time: 0.6540  data: 0.0021  max mem: 2372\n",
            "Train: Epoch[3/5]  [ 40/313]  eta: 0:02:59  Lr: 0.001875  Loss: 0.0351  Acc@1: 87.5000 (86.1280)  Acc@5: 100.0000 (98.3232)  time: 0.6543  data: 0.0023  max mem: 2372\n",
            "Train: Epoch[3/5]  [ 50/313]  eta: 0:02:52  Lr: 0.001875  Loss: 0.2251  Acc@1: 87.5000 (86.3971)  Acc@5: 100.0000 (98.5294)  time: 0.6548  data: 0.0028  max mem: 2372\n",
            "Train: Epoch[3/5]  [ 60/313]  eta: 0:02:46  Lr: 0.001875  Loss: 0.5960  Acc@1: 81.2500 (85.5533)  Acc@5: 100.0000 (98.1557)  time: 0.6548  data: 0.0044  max mem: 2372\n",
            "Train: Epoch[3/5]  [ 70/313]  eta: 0:02:39  Lr: 0.001875  Loss: 0.5890  Acc@1: 87.5000 (85.8275)  Acc@5: 100.0000 (98.2394)  time: 0.6539  data: 0.0022  max mem: 2372\n",
            "Train: Epoch[3/5]  [ 80/313]  eta: 0:02:32  Lr: 0.001875  Loss: 0.2784  Acc@1: 87.5000 (86.3426)  Acc@5: 100.0000 (98.2253)  time: 0.6533  data: 0.0029  max mem: 2372\n",
            "Train: Epoch[3/5]  [ 90/313]  eta: 0:02:26  Lr: 0.001875  Loss: 0.0088  Acc@1: 87.5000 (86.4011)  Acc@5: 100.0000 (98.2143)  time: 0.6540  data: 0.0027  max mem: 2372\n",
            "Train: Epoch[3/5]  [100/313]  eta: 0:02:19  Lr: 0.001875  Loss: 0.2444  Acc@1: 81.2500 (85.9530)  Acc@5: 100.0000 (98.2673)  time: 0.6545  data: 0.0027  max mem: 2372\n",
            "Train: Epoch[3/5]  [110/313]  eta: 0:02:13  Lr: 0.001875  Loss: 0.0006  Acc@1: 81.2500 (86.4302)  Acc@5: 100.0000 (98.3108)  time: 0.6543  data: 0.0027  max mem: 2372\n",
            "Train: Epoch[3/5]  [120/313]  eta: 0:02:06  Lr: 0.001875  Loss: 0.6152  Acc@1: 87.5000 (86.0537)  Acc@5: 100.0000 (98.3988)  time: 0.6541  data: 0.0021  max mem: 2372\n",
            "Train: Epoch[3/5]  [130/313]  eta: 0:01:59  Lr: 0.001875  Loss: 0.2668  Acc@1: 87.5000 (86.5458)  Acc@5: 100.0000 (98.3779)  time: 0.6533  data: 0.0021  max mem: 2372\n",
            "Train: Epoch[3/5]  [140/313]  eta: 0:01:53  Lr: 0.001875  Loss: 0.2638  Acc@1: 87.5000 (86.7021)  Acc@5: 100.0000 (98.3599)  time: 0.6533  data: 0.0017  max mem: 2372\n",
            "Train: Epoch[3/5]  [150/313]  eta: 0:01:46  Lr: 0.001875  Loss: 0.2663  Acc@1: 87.5000 (86.5066)  Acc@5: 100.0000 (98.3858)  time: 0.6542  data: 0.0023  max mem: 2372\n",
            "Train: Epoch[3/5]  [160/313]  eta: 0:01:40  Lr: 0.001875  Loss: 0.1329  Acc@1: 87.5000 (86.8401)  Acc@5: 100.0000 (98.4860)  time: 0.6545  data: 0.0017  max mem: 2372\n",
            "Train: Epoch[3/5]  [170/313]  eta: 0:01:33  Lr: 0.001875  Loss: 0.3744  Acc@1: 87.5000 (86.7325)  Acc@5: 100.0000 (98.5380)  time: 0.6542  data: 0.0021  max mem: 2372\n",
            "Train: Epoch[3/5]  [180/313]  eta: 0:01:27  Lr: 0.001875  Loss: -0.1270  Acc@1: 87.5000 (86.6022)  Acc@5: 100.0000 (98.4807)  time: 0.6542  data: 0.0017  max mem: 2372\n",
            "Train: Epoch[3/5]  [190/313]  eta: 0:01:20  Lr: 0.001875  Loss: 0.0192  Acc@1: 87.5000 (86.6819)  Acc@5: 100.0000 (98.4948)  time: 0.6539  data: 0.0023  max mem: 2372\n",
            "Train: Epoch[3/5]  [200/313]  eta: 0:01:13  Lr: 0.001875  Loss: 0.2479  Acc@1: 87.5000 (86.8159)  Acc@5: 100.0000 (98.5075)  time: 0.6543  data: 0.0020  max mem: 2372\n",
            "Train: Epoch[3/5]  [210/313]  eta: 0:01:07  Lr: 0.001875  Loss: 0.1108  Acc@1: 87.5000 (86.6114)  Acc@5: 100.0000 (98.5190)  time: 0.6546  data: 0.0021  max mem: 2372\n",
            "Train: Epoch[3/5]  [220/313]  eta: 0:01:00  Lr: 0.001875  Loss: 0.1243  Acc@1: 87.5000 (86.6233)  Acc@5: 100.0000 (98.4729)  time: 0.6544  data: 0.0021  max mem: 2372\n",
            "Train: Epoch[3/5]  [230/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.3214  Acc@1: 87.5000 (86.5801)  Acc@5: 100.0000 (98.4848)  time: 0.6546  data: 0.0028  max mem: 2372\n",
            "Train: Epoch[3/5]  [240/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.2679  Acc@1: 87.5000 (86.5145)  Acc@5: 100.0000 (98.4180)  time: 0.6553  data: 0.0028  max mem: 2372\n",
            "Train: Epoch[3/5]  [250/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.1605  Acc@1: 87.5000 (86.5289)  Acc@5: 100.0000 (98.3815)  time: 0.6556  data: 0.0027  max mem: 2372\n",
            "Train: Epoch[3/5]  [260/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.2919  Acc@1: 87.5000 (86.6379)  Acc@5: 100.0000 (98.3716)  time: 0.6552  data: 0.0027  max mem: 2372\n",
            "Train: Epoch[3/5]  [270/313]  eta: 0:00:28  Lr: 0.001875  Loss: -0.0293  Acc@1: 87.5000 (86.6697)  Acc@5: 100.0000 (98.3856)  time: 0.6552  data: 0.0015  max mem: 2372\n",
            "Train: Epoch[3/5]  [280/313]  eta: 0:00:21  Lr: 0.001875  Loss: -0.0879  Acc@1: 87.5000 (86.6993)  Acc@5: 100.0000 (98.3986)  time: 0.6555  data: 0.0028  max mem: 2372\n",
            "Train: Epoch[3/5]  [290/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.3688  Acc@1: 87.5000 (86.6838)  Acc@5: 100.0000 (98.3892)  time: 0.6551  data: 0.0023  max mem: 2372\n",
            "Train: Epoch[3/5]  [300/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.1085  Acc@1: 87.5000 (86.7317)  Acc@5: 100.0000 (98.4219)  time: 0.6551  data: 0.0018  max mem: 2372\n",
            "Train: Epoch[3/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.1606  Acc@1: 87.5000 (86.7966)  Acc@5: 100.0000 (98.4526)  time: 0.6558  data: 0.0011  max mem: 2372\n",
            "Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.8570  Acc@1: 87.5000 (86.7800)  Acc@5: 100.0000 (98.4000)  time: 0.6393  data: 0.0008  max mem: 2372\n",
            "Train: Epoch[3/5] Total time: 0:03:24 (0.6541 s / it)\n",
            "Averaged stats: Lr: 0.001875  Loss: 0.8570  Acc@1: 87.5000 (86.7800)  Acc@5: 100.0000 (98.4000)\n",
            "Train: Epoch[4/5]  [  0/313]  eta: 0:04:37  Lr: 0.001875  Loss: 0.0763  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.8879  data: 0.2754  max mem: 2372\n",
            "Train: Epoch[4/5]  [ 10/313]  eta: 0:03:25  Lr: 0.001875  Loss: 0.2817  Acc@1: 87.5000 (88.0682)  Acc@5: 100.0000 (98.2955)  time: 0.6774  data: 0.0268  max mem: 2372\n",
            "Train: Epoch[4/5]  [ 20/313]  eta: 0:03:15  Lr: 0.001875  Loss: 0.1496  Acc@1: 87.5000 (88.0952)  Acc@5: 100.0000 (98.5119)  time: 0.6556  data: 0.0016  max mem: 2372\n",
            "Train: Epoch[4/5]  [ 30/313]  eta: 0:03:07  Lr: 0.001875  Loss: 0.1025  Acc@1: 87.5000 (87.7016)  Acc@5: 100.0000 (98.3871)  time: 0.6549  data: 0.0024  max mem: 2372\n",
            "Train: Epoch[4/5]  [ 40/313]  eta: 0:03:00  Lr: 0.001875  Loss: 0.0566  Acc@1: 87.5000 (87.1951)  Acc@5: 100.0000 (98.0183)  time: 0.6555  data: 0.0019  max mem: 2372\n",
            "Train: Epoch[4/5]  [ 50/313]  eta: 0:02:53  Lr: 0.001875  Loss: 0.0367  Acc@1: 87.5000 (87.6225)  Acc@5: 100.0000 (98.1618)  time: 0.6559  data: 0.0024  max mem: 2372\n",
            "Train: Epoch[4/5]  [ 60/313]  eta: 0:02:46  Lr: 0.001875  Loss: 0.2492  Acc@1: 87.5000 (87.3975)  Acc@5: 100.0000 (97.8484)  time: 0.6557  data: 0.0025  max mem: 2372\n",
            "Train: Epoch[4/5]  [ 70/313]  eta: 0:02:40  Lr: 0.001875  Loss: 0.3706  Acc@1: 87.5000 (86.7958)  Acc@5: 100.0000 (97.8873)  time: 0.6554  data: 0.0016  max mem: 2372\n",
            "Train: Epoch[4/5]  [ 80/313]  eta: 0:02:33  Lr: 0.001875  Loss: -0.1889  Acc@1: 81.2500 (86.5741)  Acc@5: 100.0000 (97.9167)  time: 0.6557  data: 0.0015  max mem: 2372\n",
            "Train: Epoch[4/5]  [ 90/313]  eta: 0:02:26  Lr: 0.001875  Loss: -0.0531  Acc@1: 87.5000 (86.7445)  Acc@5: 100.0000 (97.9396)  time: 0.6561  data: 0.0023  max mem: 2372\n",
            "Train: Epoch[4/5]  [100/313]  eta: 0:02:20  Lr: 0.001875  Loss: -0.0553  Acc@1: 87.5000 (86.7574)  Acc@5: 100.0000 (98.1436)  time: 0.6559  data: 0.0030  max mem: 2372\n",
            "Train: Epoch[4/5]  [110/313]  eta: 0:02:13  Lr: 0.001875  Loss: 0.1000  Acc@1: 87.5000 (86.6554)  Acc@5: 100.0000 (98.2545)  time: 0.6558  data: 0.0022  max mem: 2372\n",
            "Train: Epoch[4/5]  [120/313]  eta: 0:02:06  Lr: 0.001875  Loss: 0.2282  Acc@1: 81.2500 (86.2087)  Acc@5: 100.0000 (98.1405)  time: 0.6558  data: 0.0032  max mem: 2372\n",
            "Train: Epoch[4/5]  [130/313]  eta: 0:02:00  Lr: 0.001875  Loss: -0.0865  Acc@1: 81.2500 (86.4981)  Acc@5: 100.0000 (98.1870)  time: 0.6560  data: 0.0023  max mem: 2372\n",
            "Train: Epoch[4/5]  [140/313]  eta: 0:01:53  Lr: 0.001875  Loss: -0.0091  Acc@1: 93.7500 (86.8794)  Acc@5: 100.0000 (98.2270)  time: 0.6562  data: 0.0024  max mem: 2372\n",
            "Train: Epoch[4/5]  [150/313]  eta: 0:01:47  Lr: 0.001875  Loss: 0.6591  Acc@1: 93.7500 (87.0861)  Acc@5: 100.0000 (98.2202)  time: 0.6561  data: 0.0021  max mem: 2372\n",
            "Train: Epoch[4/5]  [160/313]  eta: 0:01:40  Lr: 0.001875  Loss: 0.0276  Acc@1: 87.5000 (86.9565)  Acc@5: 100.0000 (98.2531)  time: 0.6558  data: 0.0023  max mem: 2372\n",
            "Train: Epoch[4/5]  [170/313]  eta: 0:01:33  Lr: 0.001875  Loss: -0.0710  Acc@1: 87.5000 (86.9152)  Acc@5: 100.0000 (98.2822)  time: 0.6558  data: 0.0023  max mem: 2372\n",
            "Train: Epoch[4/5]  [180/313]  eta: 0:01:27  Lr: 0.001875  Loss: 0.2036  Acc@1: 87.5000 (87.1547)  Acc@5: 100.0000 (98.3771)  time: 0.6552  data: 0.0023  max mem: 2372\n",
            "Train: Epoch[4/5]  [190/313]  eta: 0:01:20  Lr: 0.001875  Loss: 0.1008  Acc@1: 93.7500 (87.2382)  Acc@5: 100.0000 (98.3312)  time: 0.6554  data: 0.0036  max mem: 2372\n",
            "Train: Epoch[4/5]  [200/313]  eta: 0:01:14  Lr: 0.001875  Loss: 0.4232  Acc@1: 87.5000 (87.2823)  Acc@5: 100.0000 (98.3520)  time: 0.6559  data: 0.0022  max mem: 2372\n",
            "Train: Epoch[4/5]  [210/313]  eta: 0:01:07  Lr: 0.001875  Loss: 0.4820  Acc@1: 87.5000 (87.1742)  Acc@5: 100.0000 (98.3412)  time: 0.6560  data: 0.0026  max mem: 2372\n",
            "Train: Epoch[4/5]  [220/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.3624  Acc@1: 87.5000 (87.3303)  Acc@5: 100.0000 (98.3597)  time: 0.6559  data: 0.0022  max mem: 2372\n",
            "Train: Epoch[4/5]  [230/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.0266  Acc@1: 87.5000 (87.3377)  Acc@5: 100.0000 (98.3496)  time: 0.6560  data: 0.0031  max mem: 2372\n",
            "Train: Epoch[4/5]  [240/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.0112  Acc@1: 87.5000 (87.3963)  Acc@5: 100.0000 (98.3402)  time: 0.6565  data: 0.0028  max mem: 2372\n",
            "Train: Epoch[4/5]  [250/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.2450  Acc@1: 87.5000 (87.4004)  Acc@5: 100.0000 (98.3566)  time: 0.6562  data: 0.0024  max mem: 2372\n",
            "Train: Epoch[4/5]  [260/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.2757  Acc@1: 87.5000 (87.3324)  Acc@5: 100.0000 (98.3477)  time: 0.6554  data: 0.0024  max mem: 2372\n",
            "Train: Epoch[4/5]  [270/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.5370  Acc@1: 87.5000 (87.2924)  Acc@5: 100.0000 (98.3164)  time: 0.6555  data: 0.0023  max mem: 2372\n",
            "Train: Epoch[4/5]  [280/313]  eta: 0:00:21  Lr: 0.001875  Loss: -0.1037  Acc@1: 87.5000 (87.2109)  Acc@5: 100.0000 (98.3096)  time: 0.6562  data: 0.0022  max mem: 2372\n",
            "Train: Epoch[4/5]  [290/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.2561  Acc@1: 87.5000 (87.1349)  Acc@5: 100.0000 (98.3247)  time: 0.6560  data: 0.0023  max mem: 2372\n",
            "Train: Epoch[4/5]  [300/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.2452  Acc@1: 87.5000 (87.2093)  Acc@5: 100.0000 (98.3804)  time: 0.6556  data: 0.0027  max mem: 2372\n",
            "Train: Epoch[4/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.3453  Acc@1: 87.5000 (87.1785)  Acc@5: 100.0000 (98.3521)  time: 0.6558  data: 0.0008  max mem: 2372\n",
            "Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.1000  Acc@1: 87.5000 (87.2000)  Acc@5: 100.0000 (98.3400)  time: 0.6397  data: 0.0004  max mem: 2372\n",
            "Train: Epoch[4/5] Total time: 0:03:25 (0.6558 s / it)\n",
            "Averaged stats: Lr: 0.001875  Loss: 0.1000  Acc@1: 87.5000 (87.2000)  Acc@5: 100.0000 (98.3400)\n",
            "Train: Epoch[5/5]  [  0/313]  eta: 0:04:33  Lr: 0.001875  Loss: 0.2335  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.8737  data: 0.2493  max mem: 2372\n",
            "Train: Epoch[5/5]  [ 10/313]  eta: 0:03:24  Lr: 0.001875  Loss: 0.2571  Acc@1: 87.5000 (86.3636)  Acc@5: 100.0000 (99.4318)  time: 0.6759  data: 0.0230  max mem: 2372\n",
            "Train: Epoch[5/5]  [ 20/313]  eta: 0:03:15  Lr: 0.001875  Loss: 0.2970  Acc@1: 87.5000 (88.0952)  Acc@5: 100.0000 (98.5119)  time: 0.6554  data: 0.0011  max mem: 2372\n",
            "Train: Epoch[5/5]  [ 30/313]  eta: 0:03:07  Lr: 0.001875  Loss: 0.4684  Acc@1: 87.5000 (86.4919)  Acc@5: 100.0000 (97.9839)  time: 0.6555  data: 0.0020  max mem: 2372\n",
            "Train: Epoch[5/5]  [ 40/313]  eta: 0:03:00  Lr: 0.001875  Loss: 0.4358  Acc@1: 81.2500 (85.2134)  Acc@5: 100.0000 (98.1707)  time: 0.6562  data: 0.0019  max mem: 2372\n",
            "Train: Epoch[5/5]  [ 50/313]  eta: 0:02:53  Lr: 0.001875  Loss: 0.0295  Acc@1: 87.5000 (85.9069)  Acc@5: 100.0000 (98.2843)  time: 0.6566  data: 0.0023  max mem: 2372\n",
            "Train: Epoch[5/5]  [ 60/313]  eta: 0:02:46  Lr: 0.001875  Loss: 0.3583  Acc@1: 87.5000 (85.3484)  Acc@5: 100.0000 (98.3607)  time: 0.6567  data: 0.0018  max mem: 2372\n",
            "Train: Epoch[5/5]  [ 70/313]  eta: 0:02:40  Lr: 0.001875  Loss: -0.0295  Acc@1: 87.5000 (85.2993)  Acc@5: 100.0000 (98.3275)  time: 0.6564  data: 0.0022  max mem: 2372\n",
            "Train: Epoch[5/5]  [ 80/313]  eta: 0:02:33  Lr: 0.001875  Loss: 0.5800  Acc@1: 87.5000 (85.1852)  Acc@5: 100.0000 (98.5340)  time: 0.6563  data: 0.0020  max mem: 2372\n",
            "Train: Epoch[5/5]  [ 90/313]  eta: 0:02:26  Lr: 0.001875  Loss: 0.1390  Acc@1: 87.5000 (85.0962)  Acc@5: 100.0000 (98.6264)  time: 0.6561  data: 0.0029  max mem: 2372\n",
            "Train: Epoch[5/5]  [100/313]  eta: 0:02:20  Lr: 0.001875  Loss: 0.2156  Acc@1: 87.5000 (84.9629)  Acc@5: 100.0000 (98.7624)  time: 0.6561  data: 0.0028  max mem: 2372\n",
            "Train: Epoch[5/5]  [110/313]  eta: 0:02:13  Lr: 0.001875  Loss: 0.1784  Acc@1: 87.5000 (85.1351)  Acc@5: 100.0000 (98.7613)  time: 0.6566  data: 0.0021  max mem: 2372\n",
            "Train: Epoch[5/5]  [120/313]  eta: 0:02:07  Lr: 0.001875  Loss: 0.0797  Acc@1: 87.5000 (85.2273)  Acc@5: 100.0000 (98.8120)  time: 0.6571  data: 0.0022  max mem: 2372\n",
            "Train: Epoch[5/5]  [130/313]  eta: 0:02:00  Lr: 0.001875  Loss: 0.3422  Acc@1: 87.5000 (85.1622)  Acc@5: 100.0000 (98.8073)  time: 0.6569  data: 0.0021  max mem: 2372\n",
            "Train: Epoch[5/5]  [140/313]  eta: 0:01:53  Lr: 0.001875  Loss: -0.0149  Acc@1: 87.5000 (85.3723)  Acc@5: 100.0000 (98.8918)  time: 0.6562  data: 0.0023  max mem: 2372\n",
            "Train: Epoch[5/5]  [150/313]  eta: 0:01:47  Lr: 0.001875  Loss: 0.0963  Acc@1: 87.5000 (85.2235)  Acc@5: 100.0000 (98.8825)  time: 0.6566  data: 0.0017  max mem: 2372\n",
            "Train: Epoch[5/5]  [160/313]  eta: 0:01:40  Lr: 0.001875  Loss: 0.1716  Acc@1: 81.2500 (85.2873)  Acc@5: 100.0000 (98.7966)  time: 0.6573  data: 0.0026  max mem: 2372\n",
            "Train: Epoch[5/5]  [170/313]  eta: 0:01:34  Lr: 0.001875  Loss: 0.3358  Acc@1: 87.5000 (85.7456)  Acc@5: 100.0000 (98.8670)  time: 0.6577  data: 0.0023  max mem: 2372\n",
            "Train: Epoch[5/5]  [180/313]  eta: 0:01:27  Lr: 0.001875  Loss: 0.2785  Acc@1: 93.7500 (85.8425)  Acc@5: 100.0000 (98.8260)  time: 0.6577  data: 0.0021  max mem: 2372\n",
            "Train: Epoch[5/5]  [190/313]  eta: 0:01:20  Lr: 0.001875  Loss: 0.2968  Acc@1: 87.5000 (85.9948)  Acc@5: 100.0000 (98.8220)  time: 0.6572  data: 0.0016  max mem: 2372\n",
            "Train: Epoch[5/5]  [200/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.1319  Acc@1: 87.5000 (86.1940)  Acc@5: 100.0000 (98.8184)  time: 0.6572  data: 0.0022  max mem: 2372\n",
            "Train: Epoch[5/5]  [210/313]  eta: 0:01:07  Lr: 0.001875  Loss: 0.0962  Acc@1: 87.5000 (86.0190)  Acc@5: 100.0000 (98.7855)  time: 0.6571  data: 0.0022  max mem: 2372\n",
            "Train: Epoch[5/5]  [220/313]  eta: 0:01:01  Lr: 0.001875  Loss: -0.0406  Acc@1: 87.5000 (86.1708)  Acc@5: 100.0000 (98.8122)  time: 0.6574  data: 0.0020  max mem: 2372\n",
            "Train: Epoch[5/5]  [230/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.0630  Acc@1: 87.5000 (86.2284)  Acc@5: 100.0000 (98.8095)  time: 0.6572  data: 0.0019  max mem: 2372\n",
            "Train: Epoch[5/5]  [240/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.1917  Acc@1: 87.5000 (86.3071)  Acc@5: 100.0000 (98.8071)  time: 0.6562  data: 0.0020  max mem: 2372\n",
            "Train: Epoch[5/5]  [250/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.2289  Acc@1: 87.5000 (86.3795)  Acc@5: 100.0000 (98.8048)  time: 0.6565  data: 0.0022  max mem: 2372\n",
            "Train: Epoch[5/5]  [260/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.0050  Acc@1: 87.5000 (86.4703)  Acc@5: 100.0000 (98.7787)  time: 0.6569  data: 0.0019  max mem: 2372\n",
            "Train: Epoch[5/5]  [270/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.2026  Acc@1: 87.5000 (86.4391)  Acc@5: 100.0000 (98.7085)  time: 0.6573  data: 0.0028  max mem: 2372\n",
            "Train: Epoch[5/5]  [280/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.0951  Acc@1: 87.5000 (86.5214)  Acc@5: 100.0000 (98.7100)  time: 0.6574  data: 0.0027  max mem: 2372\n",
            "Train: Epoch[5/5]  [290/313]  eta: 0:00:15  Lr: 0.001875  Loss: -0.1122  Acc@1: 87.5000 (86.7053)  Acc@5: 100.0000 (98.7543)  time: 0.6567  data: 0.0026  max mem: 2372\n",
            "Train: Epoch[5/5]  [300/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.2006  Acc@1: 87.5000 (86.6694)  Acc@5: 100.0000 (98.7334)  time: 0.6568  data: 0.0022  max mem: 2372\n",
            "Train: Epoch[5/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.0673  Acc@1: 87.5000 (86.7363)  Acc@5: 100.0000 (98.7339)  time: 0.6570  data: 0.0021  max mem: 2372\n",
            "Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.0153  Acc@1: 87.5000 (86.7600)  Acc@5: 100.0000 (98.7200)  time: 0.6407  data: 0.0021  max mem: 2372\n",
            "Train: Epoch[5/5] Total time: 0:03:25 (0.6566 s / it)\n",
            "Averaged stats: Lr: 0.001875  Loss: -0.0153  Acc@1: 87.5000 (86.7600)  Acc@5: 100.0000 (98.7200)\n",
            "Test: [Task 1]  [ 0/63]  eta: 0:00:40  Loss: 0.4745 (0.4745)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.6432  data: 0.2531  max mem: 2372\n",
            "Test: [Task 1]  [10/63]  eta: 0:00:23  Loss: 0.4401 (0.4363)  Acc@1: 100.0000 (97.1591)  Acc@5: 100.0000 (100.0000)  time: 0.4465  data: 0.0234  max mem: 2372\n",
            "Test: [Task 1]  [20/63]  eta: 0:00:18  Loss: 0.4390 (0.4939)  Acc@1: 93.7500 (95.5357)  Acc@5: 100.0000 (100.0000)  time: 0.4271  data: 0.0014  max mem: 2372\n",
            "Test: [Task 1]  [30/63]  eta: 0:00:14  Loss: 0.3494 (0.4385)  Acc@1: 100.0000 (96.7742)  Acc@5: 100.0000 (100.0000)  time: 0.4267  data: 0.0041  max mem: 2372\n",
            "Test: [Task 1]  [40/63]  eta: 0:00:09  Loss: 0.3218 (0.4334)  Acc@1: 100.0000 (96.9512)  Acc@5: 100.0000 (100.0000)  time: 0.4262  data: 0.0030  max mem: 2372\n",
            "Test: [Task 1]  [50/63]  eta: 0:00:05  Loss: 0.3670 (0.4215)  Acc@1: 100.0000 (97.1814)  Acc@5: 100.0000 (99.8775)  time: 0.4260  data: 0.0003  max mem: 2372\n",
            "Test: [Task 1]  [60/63]  eta: 0:00:01  Loss: 0.3710 (0.4158)  Acc@1: 100.0000 (97.4385)  Acc@5: 100.0000 (99.8975)  time: 0.4257  data: 0.0012  max mem: 2372\n",
            "Test: [Task 1]  [62/63]  eta: 0:00:00  Loss: 0.3670 (0.4151)  Acc@1: 100.0000 (97.5000)  Acc@5: 100.0000 (99.9000)  time: 0.4149  data: 0.0012  max mem: 2372\n",
            "Test: [Task 1] Total time: 0:00:26 (0.4271 s / it)\n",
            "* Acc@1 97.500 Acc@5 99.900 loss 0.415\n",
            "[Average accuracy till task1]\tAcc@1: 97.5000\tAcc@5: 99.9000\tLoss: 0.4151\n",
            "Train: Epoch[1/5]  [  0/313]  eta: 0:04:27  Lr: 0.001875  Loss: 2.0977  Acc@1: 18.7500 (18.7500)  Acc@5: 43.7500 (43.7500)  time: 0.8539  data: 0.2409  max mem: 2372\n",
            "Train: Epoch[1/5]  [ 10/313]  eta: 0:03:24  Lr: 0.001875  Loss: 1.9083  Acc@1: 43.7500 (36.3636)  Acc@5: 75.0000 (72.7273)  time: 0.6756  data: 0.0223  max mem: 2372\n",
            "Train: Epoch[1/5]  [ 20/313]  eta: 0:03:14  Lr: 0.001875  Loss: 1.7584  Acc@1: 56.2500 (50.8929)  Acc@5: 93.7500 (83.0357)  time: 0.6556  data: 0.0012  max mem: 2372\n",
            "Train: Epoch[1/5]  [ 30/313]  eta: 0:03:07  Lr: 0.001875  Loss: 1.4678  Acc@1: 68.7500 (59.6774)  Acc@5: 93.7500 (87.5000)  time: 0.6545  data: 0.0012  max mem: 2372\n",
            "Train: Epoch[1/5]  [ 40/313]  eta: 0:03:00  Lr: 0.001875  Loss: 1.1703  Acc@1: 68.7500 (61.4329)  Acc@5: 100.0000 (89.3293)  time: 0.6556  data: 0.0022  max mem: 2372\n",
            "Train: Epoch[1/5]  [ 50/313]  eta: 0:02:53  Lr: 0.001875  Loss: 1.2254  Acc@1: 68.7500 (64.5833)  Acc@5: 93.7500 (90.4412)  time: 0.6557  data: 0.0023  max mem: 2372\n",
            "Train: Epoch[1/5]  [ 60/313]  eta: 0:02:46  Lr: 0.001875  Loss: 0.7496  Acc@1: 75.0000 (66.9057)  Acc@5: 93.7500 (91.1885)  time: 0.6560  data: 0.0013  max mem: 2372\n",
            "Train: Epoch[1/5]  [ 70/313]  eta: 0:02:40  Lr: 0.001875  Loss: 0.8205  Acc@1: 81.2500 (68.4859)  Acc@5: 93.7500 (91.6373)  time: 0.6562  data: 0.0020  max mem: 2372\n",
            "Train: Epoch[1/5]  [ 80/313]  eta: 0:02:33  Lr: 0.001875  Loss: 0.6943  Acc@1: 81.2500 (70.6790)  Acc@5: 100.0000 (92.5154)  time: 0.6559  data: 0.0015  max mem: 2372\n",
            "Train: Epoch[1/5]  [ 90/313]  eta: 0:02:26  Lr: 0.001875  Loss: 0.6572  Acc@1: 81.2500 (71.3599)  Acc@5: 100.0000 (93.0632)  time: 0.6565  data: 0.0019  max mem: 2372\n",
            "Train: Epoch[1/5]  [100/313]  eta: 0:02:20  Lr: 0.001875  Loss: 0.4786  Acc@1: 81.2500 (72.4010)  Acc@5: 100.0000 (93.4406)  time: 0.6574  data: 0.0022  max mem: 2372\n",
            "Train: Epoch[1/5]  [110/313]  eta: 0:02:13  Lr: 0.001875  Loss: 0.6959  Acc@1: 87.5000 (73.4797)  Acc@5: 100.0000 (93.9189)  time: 0.6580  data: 0.0035  max mem: 2372\n",
            "Train: Epoch[1/5]  [120/313]  eta: 0:02:07  Lr: 0.001875  Loss: 0.3958  Acc@1: 87.5000 (74.5351)  Acc@5: 100.0000 (94.2665)  time: 0.6588  data: 0.0041  max mem: 2372\n",
            "Train: Epoch[1/5]  [130/313]  eta: 0:02:00  Lr: 0.001875  Loss: 0.9268  Acc@1: 81.2500 (74.8092)  Acc@5: 100.0000 (94.4656)  time: 0.6585  data: 0.0035  max mem: 2372\n",
            "Train: Epoch[1/5]  [140/313]  eta: 0:01:53  Lr: 0.001875  Loss: 0.5753  Acc@1: 81.2500 (75.0887)  Acc@5: 100.0000 (94.7695)  time: 0.6570  data: 0.0023  max mem: 2372\n",
            "Train: Epoch[1/5]  [150/313]  eta: 0:01:47  Lr: 0.001875  Loss: 0.6309  Acc@1: 81.2500 (75.7036)  Acc@5: 100.0000 (95.0331)  time: 0.6568  data: 0.0018  max mem: 2372\n",
            "Train: Epoch[1/5]  [160/313]  eta: 0:01:40  Lr: 0.001875  Loss: 0.2876  Acc@1: 81.2500 (76.1646)  Acc@5: 100.0000 (95.1863)  time: 0.6573  data: 0.0036  max mem: 2372\n",
            "Train: Epoch[1/5]  [170/313]  eta: 0:01:34  Lr: 0.001875  Loss: 0.3202  Acc@1: 81.2500 (76.5351)  Acc@5: 100.0000 (95.3216)  time: 0.6576  data: 0.0035  max mem: 2372\n",
            "Train: Epoch[1/5]  [180/313]  eta: 0:01:27  Lr: 0.001875  Loss: 0.2795  Acc@1: 81.2500 (76.8992)  Acc@5: 93.7500 (95.3039)  time: 0.6572  data: 0.0027  max mem: 2372\n",
            "Train: Epoch[1/5]  [190/313]  eta: 0:01:20  Lr: 0.001875  Loss: 0.3898  Acc@1: 81.2500 (77.2906)  Acc@5: 100.0000 (95.4188)  time: 0.6562  data: 0.0017  max mem: 2372\n",
            "Train: Epoch[1/5]  [200/313]  eta: 0:01:14  Lr: 0.001875  Loss: 0.4676  Acc@1: 81.2500 (77.3321)  Acc@5: 100.0000 (95.4913)  time: 0.6580  data: 0.0035  max mem: 2372\n",
            "Train: Epoch[1/5]  [210/313]  eta: 0:01:07  Lr: 0.001875  Loss: 0.3510  Acc@1: 81.2500 (77.6955)  Acc@5: 100.0000 (95.6161)  time: 0.6590  data: 0.0032  max mem: 2372\n",
            "Train: Epoch[1/5]  [220/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.4478  Acc@1: 81.2500 (77.9977)  Acc@5: 100.0000 (95.6731)  time: 0.6578  data: 0.0025  max mem: 2372\n",
            "Train: Epoch[1/5]  [230/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.3539  Acc@1: 81.2500 (78.3009)  Acc@5: 93.7500 (95.6981)  time: 0.6574  data: 0.0026  max mem: 2372\n",
            "Train: Epoch[1/5]  [240/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.7610  Acc@1: 87.5000 (78.3973)  Acc@5: 100.0000 (95.7988)  time: 0.6585  data: 0.0033  max mem: 2372\n",
            "Train: Epoch[1/5]  [250/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.2159  Acc@1: 81.2500 (78.6106)  Acc@5: 100.0000 (95.8665)  time: 0.6586  data: 0.0033  max mem: 2372\n",
            "Train: Epoch[1/5]  [260/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.3579  Acc@1: 81.2500 (78.7596)  Acc@5: 100.0000 (95.9531)  time: 0.6580  data: 0.0023  max mem: 2372\n",
            "Train: Epoch[1/5]  [270/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.0388  Acc@1: 81.2500 (78.8745)  Acc@5: 100.0000 (95.9640)  time: 0.6582  data: 0.0030  max mem: 2372\n",
            "Train: Epoch[1/5]  [280/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.1989  Acc@1: 87.5000 (79.1815)  Acc@5: 100.0000 (96.0409)  time: 0.6580  data: 0.0021  max mem: 2372\n",
            "Train: Epoch[1/5]  [290/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.2538  Acc@1: 87.5000 (79.1667)  Acc@5: 100.0000 (96.0911)  time: 0.6580  data: 0.0023  max mem: 2372\n",
            "Train: Epoch[1/5]  [300/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.4960  Acc@1: 81.2500 (79.2566)  Acc@5: 100.0000 (96.1586)  time: 0.6574  data: 0.0017  max mem: 2372\n",
            "Train: Epoch[1/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.4481  Acc@1: 81.2500 (79.2805)  Acc@5: 100.0000 (96.1415)  time: 0.6576  data: 0.0019  max mem: 2372\n",
            "Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.2058  Acc@1: 81.2500 (79.3000)  Acc@5: 93.7500 (96.1400)  time: 0.6414  data: 0.0019  max mem: 2372\n",
            "Train: Epoch[1/5] Total time: 0:03:25 (0.6571 s / it)\n",
            "Averaged stats: Lr: 0.001875  Loss: 0.2058  Acc@1: 81.2500 (79.3000)  Acc@5: 93.7500 (96.1400)\n",
            "Train: Epoch[2/5]  [  0/313]  eta: 0:04:06  Lr: 0.001875  Loss: 0.6212  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)  time: 0.7885  data: 0.1751  max mem: 2372\n",
            "Train: Epoch[2/5]  [ 10/313]  eta: 0:03:23  Lr: 0.001875  Loss: 0.1469  Acc@1: 81.2500 (82.3864)  Acc@5: 100.0000 (95.4545)  time: 0.6707  data: 0.0168  max mem: 2372\n",
            "Train: Epoch[2/5]  [ 20/313]  eta: 0:03:14  Lr: 0.001875  Loss: 0.3552  Acc@1: 81.2500 (83.6310)  Acc@5: 100.0000 (96.7262)  time: 0.6581  data: 0.0016  max mem: 2372\n",
            "Train: Epoch[2/5]  [ 30/313]  eta: 0:03:07  Lr: 0.001875  Loss: 0.4811  Acc@1: 81.2500 (82.8629)  Acc@5: 100.0000 (96.5726)  time: 0.6576  data: 0.0017  max mem: 2372\n",
            "Train: Epoch[2/5]  [ 40/313]  eta: 0:03:00  Lr: 0.001875  Loss: 0.0403  Acc@1: 87.5000 (85.0610)  Acc@5: 100.0000 (97.1037)  time: 0.6580  data: 0.0032  max mem: 2372\n",
            "Train: Epoch[2/5]  [ 50/313]  eta: 0:02:53  Lr: 0.001875  Loss: 0.4186  Acc@1: 87.5000 (85.4167)  Acc@5: 100.0000 (97.3039)  time: 0.6575  data: 0.0027  max mem: 2372\n",
            "Train: Epoch[2/5]  [ 60/313]  eta: 0:02:46  Lr: 0.001875  Loss: 0.4643  Acc@1: 81.2500 (84.2213)  Acc@5: 100.0000 (97.5410)  time: 0.6574  data: 0.0024  max mem: 2372\n",
            "Train: Epoch[2/5]  [ 70/313]  eta: 0:02:40  Lr: 0.001875  Loss: 0.3525  Acc@1: 81.2500 (84.3310)  Acc@5: 100.0000 (97.4472)  time: 0.6571  data: 0.0025  max mem: 2372\n",
            "Train: Epoch[2/5]  [ 80/313]  eta: 0:02:33  Lr: 0.001875  Loss: 0.2703  Acc@1: 87.5000 (84.4136)  Acc@5: 100.0000 (97.3765)  time: 0.6568  data: 0.0025  max mem: 2372\n",
            "Train: Epoch[2/5]  [ 90/313]  eta: 0:02:26  Lr: 0.001875  Loss: 0.5611  Acc@1: 87.5000 (84.2720)  Acc@5: 100.0000 (97.4588)  time: 0.6571  data: 0.0040  max mem: 2372\n",
            "Train: Epoch[2/5]  [100/313]  eta: 0:02:20  Lr: 0.001875  Loss: 0.3797  Acc@1: 81.2500 (83.7871)  Acc@5: 100.0000 (97.5248)  time: 0.6572  data: 0.0032  max mem: 2372\n",
            "Train: Epoch[2/5]  [110/313]  eta: 0:02:13  Lr: 0.001875  Loss: 0.3900  Acc@1: 81.2500 (84.1216)  Acc@5: 100.0000 (97.5788)  time: 0.6577  data: 0.0028  max mem: 2372\n",
            "Train: Epoch[2/5]  [120/313]  eta: 0:02:07  Lr: 0.001875  Loss: 0.4221  Acc@1: 81.2500 (83.9360)  Acc@5: 100.0000 (97.6240)  time: 0.6572  data: 0.0028  max mem: 2372\n",
            "Train: Epoch[2/5]  [130/313]  eta: 0:02:00  Lr: 0.001875  Loss: 0.1932  Acc@1: 81.2500 (83.7786)  Acc@5: 100.0000 (97.4714)  time: 0.6575  data: 0.0028  max mem: 2372\n",
            "Train: Epoch[2/5]  [140/313]  eta: 0:01:53  Lr: 0.001875  Loss: 0.2035  Acc@1: 81.2500 (83.7323)  Acc@5: 100.0000 (97.5621)  time: 0.6584  data: 0.0018  max mem: 2372\n",
            "Train: Epoch[2/5]  [150/313]  eta: 0:01:47  Lr: 0.001875  Loss: 0.4623  Acc@1: 87.5000 (84.1474)  Acc@5: 100.0000 (97.6407)  time: 0.6574  data: 0.0016  max mem: 2372\n",
            "Train: Epoch[2/5]  [160/313]  eta: 0:01:40  Lr: 0.001875  Loss: -0.0311  Acc@1: 93.7500 (84.3168)  Acc@5: 100.0000 (97.7096)  time: 0.6572  data: 0.0013  max mem: 2372\n",
            "Train: Epoch[2/5]  [170/313]  eta: 0:01:34  Lr: 0.001875  Loss: 0.2164  Acc@1: 87.5000 (84.2836)  Acc@5: 100.0000 (97.7339)  time: 0.6576  data: 0.0020  max mem: 2372\n",
            "Train: Epoch[2/5]  [180/313]  eta: 0:01:27  Lr: 0.001875  Loss: 0.1899  Acc@1: 81.2500 (84.0470)  Acc@5: 100.0000 (97.8246)  time: 0.6570  data: 0.0021  max mem: 2372\n",
            "Train: Epoch[2/5]  [190/313]  eta: 0:01:20  Lr: 0.001875  Loss: -0.0707  Acc@1: 81.2500 (84.2277)  Acc@5: 100.0000 (97.8403)  time: 0.6579  data: 0.0021  max mem: 2372\n",
            "Train: Epoch[2/5]  [200/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.0481  Acc@1: 93.7500 (84.4527)  Acc@5: 100.0000 (97.8234)  time: 0.6587  data: 0.0020  max mem: 2372\n",
            "Train: Epoch[2/5]  [210/313]  eta: 0:01:07  Lr: 0.001875  Loss: 0.2503  Acc@1: 87.5000 (84.5379)  Acc@5: 100.0000 (97.8377)  time: 0.6582  data: 0.0016  max mem: 2372\n",
            "Train: Epoch[2/5]  [220/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.2086  Acc@1: 87.5000 (84.3891)  Acc@5: 100.0000 (97.7941)  time: 0.6581  data: 0.0016  max mem: 2372\n",
            "Train: Epoch[2/5]  [230/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.4295  Acc@1: 87.5000 (84.5779)  Acc@5: 100.0000 (97.8355)  time: 0.6582  data: 0.0016  max mem: 2372\n",
            "Train: Epoch[2/5]  [240/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.4372  Acc@1: 87.5000 (84.4917)  Acc@5: 100.0000 (97.7697)  time: 0.6583  data: 0.0023  max mem: 2372\n",
            "Train: Epoch[2/5]  [250/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.6359  Acc@1: 81.2500 (84.4373)  Acc@5: 100.0000 (97.7839)  time: 0.6582  data: 0.0016  max mem: 2372\n",
            "Train: Epoch[2/5]  [260/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.5360  Acc@1: 87.5000 (84.5785)  Acc@5: 100.0000 (97.7730)  time: 0.6582  data: 0.0025  max mem: 2372\n",
            "Train: Epoch[2/5]  [270/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.1240  Acc@1: 87.5000 (84.5018)  Acc@5: 100.0000 (97.7860)  time: 0.6575  data: 0.0019  max mem: 2372\n",
            "Train: Epoch[2/5]  [280/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.3295  Acc@1: 81.2500 (84.4973)  Acc@5: 100.0000 (97.7091)  time: 0.6581  data: 0.0030  max mem: 2372\n",
            "Train: Epoch[2/5]  [290/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.4834  Acc@1: 87.5000 (84.5146)  Acc@5: 100.0000 (97.7019)  time: 0.6583  data: 0.0031  max mem: 2372\n",
            "Train: Epoch[2/5]  [300/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.4566  Acc@1: 87.5000 (84.5723)  Acc@5: 100.0000 (97.7575)  time: 0.6580  data: 0.0020  max mem: 2372\n",
            "Train: Epoch[2/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.1388  Acc@1: 87.5000 (84.6061)  Acc@5: 100.0000 (97.7894)  time: 0.6582  data: 0.0017  max mem: 2372\n",
            "Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1369  Acc@1: 87.5000 (84.6400)  Acc@5: 100.0000 (97.8000)  time: 0.6421  data: 0.0012  max mem: 2372\n",
            "Train: Epoch[2/5] Total time: 0:03:25 (0.6574 s / it)\n",
            "Averaged stats: Lr: 0.001875  Loss: -0.1369  Acc@1: 87.5000 (84.6400)  Acc@5: 100.0000 (97.8000)\n",
            "Train: Epoch[3/5]  [  0/313]  eta: 0:03:58  Lr: 0.001875  Loss: 0.2703  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.7610  data: 0.1464  max mem: 2372\n",
            "Train: Epoch[3/5]  [ 10/313]  eta: 0:03:22  Lr: 0.001875  Loss: 0.3564  Acc@1: 87.5000 (85.7955)  Acc@5: 100.0000 (99.4318)  time: 0.6684  data: 0.0163  max mem: 2372\n",
            "Train: Epoch[3/5]  [ 20/313]  eta: 0:03:14  Lr: 0.001875  Loss: 0.2945  Acc@1: 87.5000 (86.0119)  Acc@5: 100.0000 (99.1071)  time: 0.6586  data: 0.0018  max mem: 2372\n",
            "Train: Epoch[3/5]  [ 30/313]  eta: 0:03:07  Lr: 0.001875  Loss: 0.0834  Acc@1: 87.5000 (86.2903)  Acc@5: 100.0000 (98.5887)  time: 0.6583  data: 0.0019  max mem: 2372\n",
            "Train: Epoch[3/5]  [ 40/313]  eta: 0:03:00  Lr: 0.001875  Loss: -0.0398  Acc@1: 87.5000 (86.2805)  Acc@5: 100.0000 (98.6280)  time: 0.6585  data: 0.0018  max mem: 2372\n",
            "Train: Epoch[3/5]  [ 50/313]  eta: 0:02:53  Lr: 0.001875  Loss: 0.1138  Acc@1: 87.5000 (86.2745)  Acc@5: 100.0000 (98.1618)  time: 0.6584  data: 0.0022  max mem: 2372\n",
            "Train: Epoch[3/5]  [ 60/313]  eta: 0:02:47  Lr: 0.001875  Loss: 0.2285  Acc@1: 87.5000 (86.4754)  Acc@5: 100.0000 (98.3607)  time: 0.6582  data: 0.0024  max mem: 2372\n",
            "Train: Epoch[3/5]  [ 70/313]  eta: 0:02:40  Lr: 0.001875  Loss: 0.3387  Acc@1: 87.5000 (86.3556)  Acc@5: 100.0000 (97.9754)  time: 0.6582  data: 0.0017  max mem: 2372\n",
            "Train: Epoch[3/5]  [ 80/313]  eta: 0:02:33  Lr: 0.001875  Loss: 0.1232  Acc@1: 87.5000 (86.0340)  Acc@5: 100.0000 (98.0710)  time: 0.6590  data: 0.0023  max mem: 2372\n",
            "Train: Epoch[3/5]  [ 90/313]  eta: 0:02:27  Lr: 0.001875  Loss: 0.2534  Acc@1: 87.5000 (86.8819)  Acc@5: 100.0000 (98.2143)  time: 0.6587  data: 0.0020  max mem: 2372\n",
            "Train: Epoch[3/5]  [100/313]  eta: 0:02:20  Lr: 0.001875  Loss: 0.2549  Acc@1: 87.5000 (87.1906)  Acc@5: 100.0000 (98.2673)  time: 0.6579  data: 0.0027  max mem: 2372\n",
            "Train: Epoch[3/5]  [110/313]  eta: 0:02:13  Lr: 0.001875  Loss: 0.0318  Acc@1: 87.5000 (87.0495)  Acc@5: 100.0000 (98.3671)  time: 0.6577  data: 0.0023  max mem: 2372\n",
            "Train: Epoch[3/5]  [120/313]  eta: 0:02:07  Lr: 0.001875  Loss: 0.3331  Acc@1: 87.5000 (87.1384)  Acc@5: 100.0000 (98.1921)  time: 0.6578  data: 0.0031  max mem: 2372\n",
            "Train: Epoch[3/5]  [130/313]  eta: 0:02:00  Lr: 0.001875  Loss: 0.6471  Acc@1: 87.5000 (86.9275)  Acc@5: 100.0000 (98.1870)  time: 0.6579  data: 0.0026  max mem: 2372\n",
            "Train: Epoch[3/5]  [140/313]  eta: 0:01:54  Lr: 0.001875  Loss: 0.2232  Acc@1: 81.2500 (86.5691)  Acc@5: 100.0000 (98.1826)  time: 0.6581  data: 0.0024  max mem: 2372\n",
            "Train: Epoch[3/5]  [150/313]  eta: 0:01:47  Lr: 0.001875  Loss: -0.1089  Acc@1: 81.2500 (86.7136)  Acc@5: 100.0000 (98.2616)  time: 0.6584  data: 0.0024  max mem: 2372\n",
            "Train: Epoch[3/5]  [160/313]  eta: 0:01:40  Lr: 0.001875  Loss: 0.3647  Acc@1: 87.5000 (86.6460)  Acc@5: 100.0000 (98.3307)  time: 0.6580  data: 0.0020  max mem: 2372\n",
            "Train: Epoch[3/5]  [170/313]  eta: 0:01:34  Lr: 0.001875  Loss: 0.0370  Acc@1: 87.5000 (86.7690)  Acc@5: 100.0000 (98.3918)  time: 0.6580  data: 0.0019  max mem: 2372\n",
            "Train: Epoch[3/5]  [180/313]  eta: 0:01:27  Lr: 0.001875  Loss: -0.1539  Acc@1: 87.5000 (86.4986)  Acc@5: 100.0000 (98.3080)  time: 0.6586  data: 0.0013  max mem: 2372\n",
            "Train: Epoch[3/5]  [190/313]  eta: 0:01:21  Lr: 0.001875  Loss: 0.0054  Acc@1: 81.2500 (86.3547)  Acc@5: 100.0000 (98.3639)  time: 0.6587  data: 0.0017  max mem: 2372\n",
            "Train: Epoch[3/5]  [200/313]  eta: 0:01:14  Lr: 0.001875  Loss: 0.5184  Acc@1: 87.5000 (86.2251)  Acc@5: 100.0000 (98.2898)  time: 0.6580  data: 0.0021  max mem: 2372\n",
            "Train: Epoch[3/5]  [210/313]  eta: 0:01:07  Lr: 0.001875  Loss: 0.2427  Acc@1: 87.5000 (86.2559)  Acc@5: 100.0000 (98.2524)  time: 0.6574  data: 0.0025  max mem: 2372\n",
            "Train: Epoch[3/5]  [220/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.2772  Acc@1: 81.2500 (86.0860)  Acc@5: 100.0000 (98.2466)  time: 0.6571  data: 0.0015  max mem: 2372\n",
            "Train: Epoch[3/5]  [230/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.7552  Acc@1: 81.2500 (86.1201)  Acc@5: 100.0000 (98.2955)  time: 0.6581  data: 0.0039  max mem: 2372\n",
            "Train: Epoch[3/5]  [240/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.1800  Acc@1: 87.5000 (86.0737)  Acc@5: 100.0000 (98.2884)  time: 0.6590  data: 0.0039  max mem: 2372\n",
            "Train: Epoch[3/5]  [250/313]  eta: 0:00:41  Lr: 0.001875  Loss: -0.0069  Acc@1: 87.5000 (86.0309)  Acc@5: 100.0000 (98.3317)  time: 0.6590  data: 0.0025  max mem: 2372\n",
            "Train: Epoch[3/5]  [260/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.3213  Acc@1: 81.2500 (85.8956)  Acc@5: 100.0000 (98.2519)  time: 0.6587  data: 0.0027  max mem: 2372\n",
            "Train: Epoch[3/5]  [270/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.2247  Acc@1: 81.2500 (85.8625)  Acc@5: 100.0000 (98.2472)  time: 0.6581  data: 0.0018  max mem: 2372\n",
            "Train: Epoch[3/5]  [280/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.1178  Acc@1: 87.5000 (85.8096)  Acc@5: 100.0000 (98.2429)  time: 0.6581  data: 0.0022  max mem: 2372\n",
            "Train: Epoch[3/5]  [290/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.0521  Acc@1: 87.5000 (85.9536)  Acc@5: 100.0000 (98.2388)  time: 0.6587  data: 0.0014  max mem: 2372\n",
            "Train: Epoch[3/5]  [300/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.2433  Acc@1: 87.5000 (85.7973)  Acc@5: 100.0000 (98.1728)  time: 0.6581  data: 0.0022  max mem: 2372\n",
            "Train: Epoch[3/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.1535  Acc@1: 81.2500 (85.7315)  Acc@5: 100.0000 (98.1712)  time: 0.6578  data: 0.0022  max mem: 2372\n",
            "Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.7061  Acc@1: 81.2500 (85.7400)  Acc@5: 100.0000 (98.1600)  time: 0.6416  data: 0.0015  max mem: 2372\n",
            "Train: Epoch[3/5] Total time: 0:03:25 (0.6579 s / it)\n",
            "Averaged stats: Lr: 0.001875  Loss: 0.7061  Acc@1: 81.2500 (85.7400)  Acc@5: 100.0000 (98.1600)\n",
            "Train: Epoch[4/5]  [  0/313]  eta: 0:05:08  Lr: 0.001875  Loss: 0.3591  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.9849  data: 0.3684  max mem: 2372\n",
            "Train: Epoch[4/5]  [ 10/313]  eta: 0:03:28  Lr: 0.001875  Loss: -0.0037  Acc@1: 93.7500 (90.3409)  Acc@5: 100.0000 (98.8636)  time: 0.6893  data: 0.0343  max mem: 2372\n",
            "Train: Epoch[4/5]  [ 20/313]  eta: 0:03:17  Lr: 0.001875  Loss: 0.3596  Acc@1: 87.5000 (85.7143)  Acc@5: 100.0000 (98.5119)  time: 0.6588  data: 0.0007  max mem: 2372\n",
            "Train: Epoch[4/5]  [ 30/313]  eta: 0:03:09  Lr: 0.001875  Loss: 0.1810  Acc@1: 81.2500 (86.4919)  Acc@5: 100.0000 (98.5887)  time: 0.6580  data: 0.0013  max mem: 2372\n",
            "Train: Epoch[4/5]  [ 40/313]  eta: 0:03:01  Lr: 0.001875  Loss: 0.0909  Acc@1: 87.5000 (86.7378)  Acc@5: 100.0000 (98.1707)  time: 0.6581  data: 0.0013  max mem: 2372\n",
            "Train: Epoch[4/5]  [ 50/313]  eta: 0:02:54  Lr: 0.001875  Loss: 0.1852  Acc@1: 87.5000 (86.6422)  Acc@5: 100.0000 (98.2843)  time: 0.6579  data: 0.0022  max mem: 2372\n",
            "Train: Epoch[4/5]  [ 60/313]  eta: 0:02:47  Lr: 0.001875  Loss: -0.0826  Acc@1: 87.5000 (86.4754)  Acc@5: 100.0000 (98.4631)  time: 0.6579  data: 0.0022  max mem: 2372\n",
            "Train: Epoch[4/5]  [ 70/313]  eta: 0:02:41  Lr: 0.001875  Loss: 0.1817  Acc@1: 87.5000 (86.5317)  Acc@5: 100.0000 (98.2394)  time: 0.6579  data: 0.0023  max mem: 2372\n",
            "Train: Epoch[4/5]  [ 80/313]  eta: 0:02:34  Lr: 0.001875  Loss: 0.0872  Acc@1: 87.5000 (86.4198)  Acc@5: 100.0000 (97.9938)  time: 0.6578  data: 0.0024  max mem: 2372\n",
            "Train: Epoch[4/5]  [ 90/313]  eta: 0:02:27  Lr: 0.001875  Loss: -0.1240  Acc@1: 87.5000 (87.0192)  Acc@5: 100.0000 (98.0769)  time: 0.6577  data: 0.0026  max mem: 2372\n",
            "Train: Epoch[4/5]  [100/313]  eta: 0:02:20  Lr: 0.001875  Loss: 0.0928  Acc@1: 93.7500 (87.1287)  Acc@5: 100.0000 (98.1436)  time: 0.6578  data: 0.0033  max mem: 2372\n",
            "Train: Epoch[4/5]  [110/313]  eta: 0:02:14  Lr: 0.001875  Loss: -0.0135  Acc@1: 87.5000 (86.8806)  Acc@5: 100.0000 (98.0856)  time: 0.6583  data: 0.0023  max mem: 2372\n",
            "Train: Epoch[4/5]  [120/313]  eta: 0:02:07  Lr: 0.001875  Loss: 0.4288  Acc@1: 87.5000 (86.9835)  Acc@5: 100.0000 (98.0888)  time: 0.6585  data: 0.0022  max mem: 2372\n",
            "Train: Epoch[4/5]  [130/313]  eta: 0:02:00  Lr: 0.001875  Loss: 0.4885  Acc@1: 87.5000 (86.7844)  Acc@5: 100.0000 (98.1393)  time: 0.6581  data: 0.0021  max mem: 2372\n",
            "Train: Epoch[4/5]  [140/313]  eta: 0:01:54  Lr: 0.001875  Loss: 0.0643  Acc@1: 81.2500 (86.7021)  Acc@5: 100.0000 (98.2270)  time: 0.6577  data: 0.0030  max mem: 2372\n",
            "Train: Epoch[4/5]  [150/313]  eta: 0:01:47  Lr: 0.001875  Loss: 0.1081  Acc@1: 87.5000 (86.6722)  Acc@5: 100.0000 (98.1788)  time: 0.6582  data: 0.0024  max mem: 2372\n",
            "Train: Epoch[4/5]  [160/313]  eta: 0:01:41  Lr: 0.001875  Loss: 0.0623  Acc@1: 87.5000 (86.4130)  Acc@5: 100.0000 (98.1755)  time: 0.6582  data: 0.0026  max mem: 2372\n",
            "Train: Epoch[4/5]  [170/313]  eta: 0:01:34  Lr: 0.001875  Loss: -0.1584  Acc@1: 87.5000 (86.3670)  Acc@5: 100.0000 (98.1725)  time: 0.6581  data: 0.0023  max mem: 2372\n",
            "Train: Epoch[4/5]  [180/313]  eta: 0:01:27  Lr: 0.001875  Loss: 0.2972  Acc@1: 87.5000 (86.2914)  Acc@5: 100.0000 (98.2044)  time: 0.6581  data: 0.0010  max mem: 2372\n",
            "Train: Epoch[4/5]  [190/313]  eta: 0:01:21  Lr: 0.001875  Loss: 0.2240  Acc@1: 87.5000 (86.3547)  Acc@5: 100.0000 (98.2657)  time: 0.6577  data: 0.0014  max mem: 2372\n",
            "Train: Epoch[4/5]  [200/313]  eta: 0:01:14  Lr: 0.001875  Loss: 0.7494  Acc@1: 87.5000 (86.4739)  Acc@5: 100.0000 (98.2276)  time: 0.6577  data: 0.0022  max mem: 2372\n",
            "Train: Epoch[4/5]  [210/313]  eta: 0:01:07  Lr: 0.001875  Loss: 0.1819  Acc@1: 87.5000 (86.6410)  Acc@5: 100.0000 (98.1931)  time: 0.6577  data: 0.0018  max mem: 2372\n",
            "Train: Epoch[4/5]  [220/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.1645  Acc@1: 87.5000 (86.7364)  Acc@5: 100.0000 (98.2749)  time: 0.6568  data: 0.0018  max mem: 2372\n",
            "Train: Epoch[4/5]  [230/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.1064  Acc@1: 87.5000 (86.7424)  Acc@5: 100.0000 (98.2955)  time: 0.6571  data: 0.0021  max mem: 2372\n",
            "Train: Epoch[4/5]  [240/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.1299  Acc@1: 87.5000 (86.7479)  Acc@5: 100.0000 (98.3143)  time: 0.6569  data: 0.0021  max mem: 2372\n",
            "Train: Epoch[4/5]  [250/313]  eta: 0:00:41  Lr: 0.001875  Loss: -0.0607  Acc@1: 87.5000 (86.6783)  Acc@5: 100.0000 (98.3566)  time: 0.6564  data: 0.0026  max mem: 2372\n",
            "Train: Epoch[4/5]  [260/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.3555  Acc@1: 87.5000 (86.8056)  Acc@5: 100.0000 (98.3956)  time: 0.6564  data: 0.0013  max mem: 2372\n",
            "Train: Epoch[4/5]  [270/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.0880  Acc@1: 93.7500 (86.9004)  Acc@5: 100.0000 (98.3856)  time: 0.6567  data: 0.0021  max mem: 2372\n",
            "Train: Epoch[4/5]  [280/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.0506  Acc@1: 87.5000 (86.9217)  Acc@5: 100.0000 (98.3986)  time: 0.6569  data: 0.0021  max mem: 2372\n",
            "Train: Epoch[4/5]  [290/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.0562  Acc@1: 87.5000 (87.0275)  Acc@5: 100.0000 (98.4107)  time: 0.6562  data: 0.0027  max mem: 2372\n",
            "Train: Epoch[4/5]  [300/313]  eta: 0:00:08  Lr: 0.001875  Loss: -0.0121  Acc@1: 87.5000 (87.0640)  Acc@5: 100.0000 (98.4427)  time: 0.6563  data: 0.0026  max mem: 2372\n",
            "Train: Epoch[4/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.1309  Acc@1: 87.5000 (87.2186)  Acc@5: 100.0000 (98.4526)  time: 0.6567  data: 0.0011  max mem: 2372\n",
            "Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.0042  Acc@1: 87.5000 (87.2400)  Acc@5: 100.0000 (98.4600)  time: 0.6406  data: 0.0011  max mem: 2372\n",
            "Train: Epoch[4/5] Total time: 0:03:25 (0.6578 s / it)\n",
            "Averaged stats: Lr: 0.001875  Loss: 0.0042  Acc@1: 87.5000 (87.2400)  Acc@5: 100.0000 (98.4600)\n",
            "Train: Epoch[5/5]  [  0/313]  eta: 0:04:23  Lr: 0.001875  Loss: -0.0153  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.8410  data: 0.2251  max mem: 2372\n",
            "Train: Epoch[5/5]  [ 10/313]  eta: 0:03:24  Lr: 0.001875  Loss: 0.0565  Acc@1: 87.5000 (86.9318)  Acc@5: 100.0000 (98.8636)  time: 0.6746  data: 0.0209  max mem: 2372\n",
            "Train: Epoch[5/5]  [ 20/313]  eta: 0:03:15  Lr: 0.001875  Loss: 0.0678  Acc@1: 87.5000 (89.5833)  Acc@5: 100.0000 (99.4048)  time: 0.6569  data: 0.0022  max mem: 2372\n",
            "Train: Epoch[5/5]  [ 30/313]  eta: 0:03:07  Lr: 0.001875  Loss: 0.2116  Acc@1: 93.7500 (89.1129)  Acc@5: 100.0000 (99.1935)  time: 0.6558  data: 0.0024  max mem: 2372\n",
            "Train: Epoch[5/5]  [ 40/313]  eta: 0:03:00  Lr: 0.001875  Loss: 0.0677  Acc@1: 87.5000 (88.2622)  Acc@5: 100.0000 (98.7805)  time: 0.6557  data: 0.0030  max mem: 2372\n",
            "Train: Epoch[5/5]  [ 50/313]  eta: 0:02:53  Lr: 0.001875  Loss: 0.0554  Acc@1: 87.5000 (88.1127)  Acc@5: 100.0000 (98.6520)  time: 0.6560  data: 0.0049  max mem: 2372\n",
            "Train: Epoch[5/5]  [ 60/313]  eta: 0:02:46  Lr: 0.001875  Loss: 0.0590  Acc@1: 87.5000 (87.7049)  Acc@5: 100.0000 (98.4631)  time: 0.6567  data: 0.0044  max mem: 2372\n",
            "Train: Epoch[5/5]  [ 70/313]  eta: 0:02:40  Lr: 0.001875  Loss: 0.0272  Acc@1: 87.5000 (87.3239)  Acc@5: 100.0000 (98.5915)  time: 0.6561  data: 0.0023  max mem: 2372\n",
            "Train: Epoch[5/5]  [ 80/313]  eta: 0:02:33  Lr: 0.001875  Loss: 0.1100  Acc@1: 87.5000 (87.8086)  Acc@5: 100.0000 (98.6883)  time: 0.6557  data: 0.0012  max mem: 2372\n",
            "Train: Epoch[5/5]  [ 90/313]  eta: 0:02:26  Lr: 0.001875  Loss: 0.3797  Acc@1: 87.5000 (87.7060)  Acc@5: 100.0000 (98.5577)  time: 0.6561  data: 0.0024  max mem: 2372\n",
            "Train: Epoch[5/5]  [100/313]  eta: 0:02:20  Lr: 0.001875  Loss: -0.1899  Acc@1: 87.5000 (87.8094)  Acc@5: 100.0000 (98.5149)  time: 0.6564  data: 0.0025  max mem: 2372\n",
            "Train: Epoch[5/5]  [110/313]  eta: 0:02:13  Lr: 0.001875  Loss: 0.0920  Acc@1: 87.5000 (88.0068)  Acc@5: 100.0000 (98.4234)  time: 0.6561  data: 0.0025  max mem: 2372\n",
            "Train: Epoch[5/5]  [120/313]  eta: 0:02:06  Lr: 0.001875  Loss: -0.0440  Acc@1: 87.5000 (87.9649)  Acc@5: 100.0000 (98.4504)  time: 0.6557  data: 0.0016  max mem: 2372\n",
            "Train: Epoch[5/5]  [130/313]  eta: 0:02:00  Lr: 0.001875  Loss: -0.0640  Acc@1: 87.5000 (87.8340)  Acc@5: 100.0000 (98.3779)  time: 0.6558  data: 0.0018  max mem: 2372\n",
            "Train: Epoch[5/5]  [140/313]  eta: 0:01:53  Lr: 0.001875  Loss: -0.1239  Acc@1: 87.5000 (87.7216)  Acc@5: 100.0000 (98.3599)  time: 0.6559  data: 0.0018  max mem: 2372\n",
            "Train: Epoch[5/5]  [150/313]  eta: 0:01:47  Lr: 0.001875  Loss: -0.1645  Acc@1: 87.5000 (87.9967)  Acc@5: 100.0000 (98.3858)  time: 0.6564  data: 0.0031  max mem: 2372\n",
            "Train: Epoch[5/5]  [160/313]  eta: 0:01:40  Lr: 0.001875  Loss: -0.1359  Acc@1: 87.5000 (88.0047)  Acc@5: 100.0000 (98.3696)  time: 0.6563  data: 0.0031  max mem: 2372\n",
            "Train: Epoch[5/5]  [170/313]  eta: 0:01:33  Lr: 0.001875  Loss: 0.1795  Acc@1: 87.5000 (87.9020)  Acc@5: 100.0000 (98.3918)  time: 0.6560  data: 0.0017  max mem: 2372\n",
            "Train: Epoch[5/5]  [180/313]  eta: 0:01:27  Lr: 0.001875  Loss: 0.0665  Acc@1: 87.5000 (87.8453)  Acc@5: 100.0000 (98.3080)  time: 0.6559  data: 0.0017  max mem: 2372\n",
            "Train: Epoch[5/5]  [190/313]  eta: 0:01:20  Lr: 0.001875  Loss: 0.2475  Acc@1: 87.5000 (87.7618)  Acc@5: 100.0000 (98.2657)  time: 0.6556  data: 0.0014  max mem: 2372\n",
            "Train: Epoch[5/5]  [200/313]  eta: 0:01:14  Lr: 0.001875  Loss: 0.2032  Acc@1: 87.5000 (87.8420)  Acc@5: 100.0000 (98.2587)  time: 0.6556  data: 0.0025  max mem: 2372\n",
            "Train: Epoch[5/5]  [210/313]  eta: 0:01:07  Lr: 0.001875  Loss: 0.2687  Acc@1: 87.5000 (87.6777)  Acc@5: 100.0000 (98.2524)  time: 0.6559  data: 0.0021  max mem: 2372\n",
            "Train: Epoch[5/5]  [220/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.0136  Acc@1: 93.7500 (87.9525)  Acc@5: 100.0000 (98.3032)  time: 0.6561  data: 0.0025  max mem: 2372\n",
            "Train: Epoch[5/5]  [230/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.1042  Acc@1: 93.7500 (88.1223)  Acc@5: 100.0000 (98.2684)  time: 0.6559  data: 0.0021  max mem: 2372\n",
            "Train: Epoch[5/5]  [240/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.1057  Acc@1: 87.5000 (88.1483)  Acc@5: 100.0000 (98.2884)  time: 0.6559  data: 0.0015  max mem: 2372\n",
            "Train: Epoch[5/5]  [250/313]  eta: 0:00:41  Lr: 0.001875  Loss: -0.1212  Acc@1: 87.5000 (88.0727)  Acc@5: 100.0000 (98.2570)  time: 0.6561  data: 0.0014  max mem: 2372\n",
            "Train: Epoch[5/5]  [260/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.4213  Acc@1: 87.5000 (88.0508)  Acc@5: 100.0000 (98.2998)  time: 0.6559  data: 0.0030  max mem: 2372\n",
            "Train: Epoch[5/5]  [270/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.5078  Acc@1: 87.5000 (87.8921)  Acc@5: 100.0000 (98.2703)  time: 0.6559  data: 0.0029  max mem: 2372\n",
            "Train: Epoch[5/5]  [280/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.0365  Acc@1: 87.5000 (87.9004)  Acc@5: 100.0000 (98.3319)  time: 0.6554  data: 0.0033  max mem: 2372\n",
            "Train: Epoch[5/5]  [290/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.1212  Acc@1: 87.5000 (87.8007)  Acc@5: 100.0000 (98.3677)  time: 0.6556  data: 0.0032  max mem: 2372\n",
            "Train: Epoch[5/5]  [300/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.1200  Acc@1: 87.5000 (87.7492)  Acc@5: 100.0000 (98.3389)  time: 0.6561  data: 0.0023  max mem: 2372\n",
            "Train: Epoch[5/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.3206  Acc@1: 87.5000 (87.7814)  Acc@5: 100.0000 (98.2918)  time: 0.6560  data: 0.0026  max mem: 2372\n",
            "Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.5748  Acc@1: 87.5000 (87.7800)  Acc@5: 100.0000 (98.2600)  time: 0.6397  data: 0.0026  max mem: 2372\n",
            "Train: Epoch[5/5] Total time: 0:03:25 (0.6558 s / it)\n",
            "Averaged stats: Lr: 0.001875  Loss: 0.5748  Acc@1: 87.5000 (87.7800)  Acc@5: 100.0000 (98.2600)\n",
            "Test: [Task 1]  [ 0/63]  eta: 0:00:37  Loss: 0.5565 (0.5565)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.5911  data: 0.2030  max mem: 2372\n",
            "Test: [Task 1]  [10/63]  eta: 0:00:23  Loss: 0.5089 (0.4841)  Acc@1: 93.7500 (92.0455)  Acc@5: 100.0000 (100.0000)  time: 0.4415  data: 0.0189  max mem: 2372\n",
            "Test: [Task 1]  [20/63]  eta: 0:00:18  Loss: 0.5089 (0.5326)  Acc@1: 93.7500 (90.4762)  Acc@5: 100.0000 (100.0000)  time: 0.4266  data: 0.0017  max mem: 2372\n",
            "Test: [Task 1]  [30/63]  eta: 0:00:14  Loss: 0.4271 (0.5053)  Acc@1: 93.7500 (91.3306)  Acc@5: 100.0000 (100.0000)  time: 0.4255  data: 0.0017  max mem: 2372\n",
            "Test: [Task 1]  [40/63]  eta: 0:00:09  Loss: 0.4271 (0.4990)  Acc@1: 93.7500 (91.3110)  Acc@5: 100.0000 (100.0000)  time: 0.4246  data: 0.0005  max mem: 2372\n",
            "Test: [Task 1]  [50/63]  eta: 0:00:05  Loss: 0.3878 (0.4723)  Acc@1: 93.7500 (92.1569)  Acc@5: 100.0000 (100.0000)  time: 0.4243  data: 0.0037  max mem: 2372\n",
            "Test: [Task 1]  [60/63]  eta: 0:00:01  Loss: 0.3878 (0.4665)  Acc@1: 93.7500 (92.5205)  Acc@5: 100.0000 (100.0000)  time: 0.4251  data: 0.0035  max mem: 2372\n",
            "Test: [Task 1]  [62/63]  eta: 0:00:00  Loss: 0.3878 (0.4631)  Acc@1: 100.0000 (92.7000)  Acc@5: 100.0000 (100.0000)  time: 0.4148  data: 0.0032  max mem: 2372\n",
            "Test: [Task 1] Total time: 0:00:26 (0.4255 s / it)\n",
            "* Acc@1 92.700 Acc@5 100.000 loss 0.463\n",
            "Test: [Task 2]  [ 0/63]  eta: 0:00:37  Loss: 0.5596 (0.5596)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.5995  data: 0.2080  max mem: 2372\n",
            "Test: [Task 2]  [10/63]  eta: 0:00:23  Loss: 0.5499 (0.5059)  Acc@1: 100.0000 (98.2955)  Acc@5: 100.0000 (99.4318)  time: 0.4422  data: 0.0194  max mem: 2372\n",
            "Test: [Task 2]  [20/63]  eta: 0:00:18  Loss: 0.5499 (0.5859)  Acc@1: 100.0000 (95.8333)  Acc@5: 100.0000 (99.4048)  time: 0.4263  data: 0.0024  max mem: 2372\n",
            "Test: [Task 2]  [30/63]  eta: 0:00:14  Loss: 0.5888 (0.5866)  Acc@1: 93.7500 (94.9597)  Acc@5: 100.0000 (99.1935)  time: 0.4260  data: 0.0024  max mem: 2372\n",
            "Test: [Task 2]  [40/63]  eta: 0:00:09  Loss: 0.5164 (0.5661)  Acc@1: 93.7500 (94.9695)  Acc@5: 100.0000 (99.2378)  time: 0.4253  data: 0.0010  max mem: 2372\n",
            "Test: [Task 2]  [50/63]  eta: 0:00:05  Loss: 0.4803 (0.5611)  Acc@1: 93.7500 (94.6078)  Acc@5: 100.0000 (99.1422)  time: 0.4241  data: 0.0021  max mem: 2372\n",
            "Test: [Task 2]  [60/63]  eta: 0:00:01  Loss: 0.4483 (0.5375)  Acc@1: 93.7500 (94.9795)  Acc@5: 100.0000 (99.2828)  time: 0.4247  data: 0.0033  max mem: 2372\n",
            "Test: [Task 2]  [62/63]  eta: 0:00:00  Loss: 0.4400 (0.5294)  Acc@1: 93.7500 (95.1000)  Acc@5: 100.0000 (99.3000)  time: 0.4141  data: 0.0032  max mem: 2372\n",
            "Test: [Task 2] Total time: 0:00:26 (0.4256 s / it)\n",
            "* Acc@1 95.100 Acc@5 99.300 loss 0.529\n",
            "[Average accuracy till task2]\tAcc@1: 93.9000\tAcc@5: 99.6500\tLoss: 0.4962\tForgetting: 4.8000\tBackward: -4.8000\n",
            "Train: Epoch[1/5]  [  0/313]  eta: 0:04:02  Lr: 0.001875  Loss: 2.0649  Acc@1: 6.2500 (6.2500)  Acc@5: 56.2500 (56.2500)  time: 0.7760  data: 0.1550  max mem: 2372\n",
            "Train: Epoch[1/5]  [ 10/313]  eta: 0:03:22  Lr: 0.001875  Loss: 1.7629  Acc@1: 43.7500 (42.0455)  Acc@5: 87.5000 (84.0909)  time: 0.6669  data: 0.0150  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 20/313]  eta: 0:03:13  Lr: 0.001875  Loss: 1.6019  Acc@1: 62.5000 (56.8452)  Acc@5: 87.5000 (87.2024)  time: 0.6548  data: 0.0025  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 30/313]  eta: 0:03:06  Lr: 0.001875  Loss: 1.4703  Acc@1: 81.2500 (63.7097)  Acc@5: 93.7500 (90.5242)  time: 0.6550  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 40/313]  eta: 0:02:59  Lr: 0.001875  Loss: 1.3069  Acc@1: 81.2500 (68.1402)  Acc@5: 100.0000 (91.9207)  time: 0.6558  data: 0.0014  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 50/313]  eta: 0:02:53  Lr: 0.001875  Loss: 0.8055  Acc@1: 81.2500 (71.2010)  Acc@5: 93.7500 (92.2794)  time: 0.6556  data: 0.0013  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 60/313]  eta: 0:02:46  Lr: 0.001875  Loss: 0.7621  Acc@1: 81.2500 (72.5410)  Acc@5: 93.7500 (92.9303)  time: 0.6563  data: 0.0031  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 70/313]  eta: 0:02:39  Lr: 0.001875  Loss: 0.6849  Acc@1: 81.2500 (73.4155)  Acc@5: 93.7500 (93.0458)  time: 0.6565  data: 0.0035  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 80/313]  eta: 0:02:33  Lr: 0.001875  Loss: 0.5077  Acc@1: 81.2500 (74.3827)  Acc@5: 100.0000 (93.7500)  time: 0.6559  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 90/313]  eta: 0:02:26  Lr: 0.001875  Loss: 0.8705  Acc@1: 81.2500 (75.0000)  Acc@5: 100.0000 (94.1621)  time: 0.6565  data: 0.0028  max mem: 2373\n",
            "Train: Epoch[1/5]  [100/313]  eta: 0:02:19  Lr: 0.001875  Loss: 0.5230  Acc@1: 81.2500 (76.2995)  Acc@5: 100.0000 (94.4926)  time: 0.6574  data: 0.0038  max mem: 2373\n",
            "Train: Epoch[1/5]  [110/313]  eta: 0:02:13  Lr: 0.001875  Loss: 0.4213  Acc@1: 87.5000 (77.0833)  Acc@5: 100.0000 (94.7072)  time: 0.6568  data: 0.0039  max mem: 2373\n",
            "Train: Epoch[1/5]  [120/313]  eta: 0:02:06  Lr: 0.001875  Loss: 0.4045  Acc@1: 87.5000 (77.6343)  Acc@5: 100.0000 (95.0413)  time: 0.6562  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[1/5]  [130/313]  eta: 0:02:00  Lr: 0.001875  Loss: 0.4383  Acc@1: 81.2500 (78.1489)  Acc@5: 100.0000 (95.1813)  time: 0.6561  data: 0.0026  max mem: 2373\n",
            "Train: Epoch[1/5]  [140/313]  eta: 0:01:53  Lr: 0.001875  Loss: 0.4688  Acc@1: 81.2500 (78.3688)  Acc@5: 100.0000 (95.3014)  time: 0.6569  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[1/5]  [150/313]  eta: 0:01:47  Lr: 0.001875  Loss: 0.6679  Acc@1: 81.2500 (78.7666)  Acc@5: 100.0000 (95.3228)  time: 0.6575  data: 0.0027  max mem: 2373\n",
            "Train: Epoch[1/5]  [160/313]  eta: 0:01:40  Lr: 0.001875  Loss: 0.1118  Acc@1: 87.5000 (79.1149)  Acc@5: 100.0000 (95.4193)  time: 0.6571  data: 0.0025  max mem: 2373\n",
            "Train: Epoch[1/5]  [170/313]  eta: 0:01:33  Lr: 0.001875  Loss: 0.5935  Acc@1: 81.2500 (79.2763)  Acc@5: 100.0000 (95.6506)  time: 0.6567  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[1/5]  [180/313]  eta: 0:01:27  Lr: 0.001875  Loss: 0.3301  Acc@1: 81.2500 (79.5925)  Acc@5: 100.0000 (95.7528)  time: 0.6567  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[1/5]  [190/313]  eta: 0:01:20  Lr: 0.001875  Loss: 0.1058  Acc@1: 81.2500 (79.7120)  Acc@5: 100.0000 (95.8442)  time: 0.6570  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[1/5]  [200/313]  eta: 0:01:14  Lr: 0.001875  Loss: 0.2975  Acc@1: 81.2500 (80.0062)  Acc@5: 100.0000 (95.9577)  time: 0.6574  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[1/5]  [210/313]  eta: 0:01:07  Lr: 0.001875  Loss: 0.1760  Acc@1: 87.5000 (80.3021)  Acc@5: 100.0000 (96.0604)  time: 0.6573  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[1/5]  [220/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.2174  Acc@1: 87.5000 (80.6278)  Acc@5: 100.0000 (96.1256)  time: 0.6568  data: 0.0025  max mem: 2373\n",
            "Train: Epoch[1/5]  [230/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.3769  Acc@1: 87.5000 (80.7359)  Acc@5: 100.0000 (96.1580)  time: 0.6571  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[1/5]  [240/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.6268  Acc@1: 87.5000 (81.1203)  Acc@5: 100.0000 (96.2915)  time: 0.6575  data: 0.0030  max mem: 2373\n",
            "Train: Epoch[1/5]  [250/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.6705  Acc@1: 87.5000 (81.2998)  Acc@5: 100.0000 (96.3894)  time: 0.6584  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[1/5]  [260/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.0895  Acc@1: 81.2500 (81.3937)  Acc@5: 100.0000 (96.5038)  time: 0.6587  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[1/5]  [270/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.2000  Acc@1: 81.2500 (81.5268)  Acc@5: 100.0000 (96.4945)  time: 0.6577  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[1/5]  [280/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.3784  Acc@1: 87.5000 (81.6948)  Acc@5: 100.0000 (96.5747)  time: 0.6571  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[1/5]  [290/313]  eta: 0:00:15  Lr: 0.001875  Loss: -0.0055  Acc@1: 87.5000 (81.8514)  Acc@5: 100.0000 (96.6065)  time: 0.6574  data: 0.0026  max mem: 2373\n",
            "Train: Epoch[1/5]  [300/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.1001  Acc@1: 87.5000 (82.0598)  Acc@5: 100.0000 (96.6777)  time: 0.6579  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[1/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.3411  Acc@1: 87.5000 (82.2749)  Acc@5: 100.0000 (96.6841)  time: 0.6577  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.0056  Acc@1: 87.5000 (82.3400)  Acc@5: 100.0000 (96.6800)  time: 0.6416  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[1/5] Total time: 0:03:25 (0.6564 s / it)\n",
            "Averaged stats: Lr: 0.001875  Loss: 0.0056  Acc@1: 87.5000 (82.3400)  Acc@5: 100.0000 (96.6800)\n",
            "Train: Epoch[2/5]  [  0/313]  eta: 0:03:55  Lr: 0.001875  Loss: 0.0170  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.7538  data: 0.1358  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 10/313]  eta: 0:03:21  Lr: 0.001875  Loss: -0.0169  Acc@1: 93.7500 (89.2045)  Acc@5: 100.0000 (98.2955)  time: 0.6663  data: 0.0165  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 20/313]  eta: 0:03:13  Lr: 0.001875  Loss: 0.1567  Acc@1: 87.5000 (85.4167)  Acc@5: 100.0000 (98.8095)  time: 0.6575  data: 0.0025  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 30/313]  eta: 0:03:06  Lr: 0.001875  Loss: 0.3910  Acc@1: 87.5000 (85.8871)  Acc@5: 100.0000 (98.3871)  time: 0.6576  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 40/313]  eta: 0:03:00  Lr: 0.001875  Loss: 0.2093  Acc@1: 87.5000 (85.3659)  Acc@5: 100.0000 (98.6280)  time: 0.6576  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 50/313]  eta: 0:02:53  Lr: 0.001875  Loss: -0.0513  Acc@1: 87.5000 (86.1520)  Acc@5: 100.0000 (98.7745)  time: 0.6572  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 60/313]  eta: 0:02:46  Lr: 0.001875  Loss: 0.1257  Acc@1: 87.5000 (86.1680)  Acc@5: 100.0000 (98.7705)  time: 0.6568  data: 0.0025  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 70/313]  eta: 0:02:40  Lr: 0.001875  Loss: 0.1399  Acc@1: 87.5000 (86.7077)  Acc@5: 100.0000 (98.7676)  time: 0.6567  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 80/313]  eta: 0:02:33  Lr: 0.001875  Loss: 0.2108  Acc@1: 87.5000 (87.0370)  Acc@5: 100.0000 (98.8426)  time: 0.6573  data: 0.0028  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 90/313]  eta: 0:02:26  Lr: 0.001875  Loss: 0.1702  Acc@1: 87.5000 (87.0192)  Acc@5: 100.0000 (98.8324)  time: 0.6573  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[2/5]  [100/313]  eta: 0:02:20  Lr: 0.001875  Loss: 0.2897  Acc@1: 87.5000 (87.0050)  Acc@5: 100.0000 (98.7005)  time: 0.6573  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[2/5]  [110/313]  eta: 0:02:13  Lr: 0.001875  Loss: 0.0823  Acc@1: 93.7500 (87.1622)  Acc@5: 100.0000 (98.5923)  time: 0.6576  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[2/5]  [120/313]  eta: 0:02:07  Lr: 0.001875  Loss: 0.3305  Acc@1: 93.7500 (87.2934)  Acc@5: 100.0000 (98.6570)  time: 0.6572  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[2/5]  [130/313]  eta: 0:02:00  Lr: 0.001875  Loss: 0.1285  Acc@1: 87.5000 (86.9752)  Acc@5: 100.0000 (98.6164)  time: 0.6577  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[2/5]  [140/313]  eta: 0:01:53  Lr: 0.001875  Loss: 0.4495  Acc@1: 87.5000 (87.0567)  Acc@5: 100.0000 (98.6259)  time: 0.6579  data: 0.0025  max mem: 2373\n",
            "Train: Epoch[2/5]  [150/313]  eta: 0:01:47  Lr: 0.001875  Loss: 0.1930  Acc@1: 87.5000 (86.7550)  Acc@5: 100.0000 (98.6341)  time: 0.6575  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[2/5]  [160/313]  eta: 0:01:40  Lr: 0.001875  Loss: 0.0350  Acc@1: 87.5000 (87.0730)  Acc@5: 100.0000 (98.6025)  time: 0.6576  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[2/5]  [170/313]  eta: 0:01:34  Lr: 0.001875  Loss: 0.2016  Acc@1: 93.7500 (87.1711)  Acc@5: 100.0000 (98.5380)  time: 0.6573  data: 0.0025  max mem: 2373\n",
            "Train: Epoch[2/5]  [180/313]  eta: 0:01:27  Lr: 0.001875  Loss: 0.1665  Acc@1: 87.5000 (86.9820)  Acc@5: 100.0000 (98.4116)  time: 0.6567  data: 0.0028  max mem: 2373\n",
            "Train: Epoch[2/5]  [190/313]  eta: 0:01:20  Lr: 0.001875  Loss: 0.3227  Acc@1: 87.5000 (86.9764)  Acc@5: 100.0000 (98.4948)  time: 0.6571  data: 0.0032  max mem: 2373\n",
            "Train: Epoch[2/5]  [200/313]  eta: 0:01:14  Lr: 0.001875  Loss: 0.2480  Acc@1: 87.5000 (86.9403)  Acc@5: 100.0000 (98.5075)  time: 0.6571  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[2/5]  [210/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.0770  Acc@1: 87.5000 (86.9668)  Acc@5: 100.0000 (98.5190)  time: 0.6565  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[2/5]  [220/313]  eta: 0:01:01  Lr: 0.001875  Loss: -0.1164  Acc@1: 87.5000 (86.9910)  Acc@5: 100.0000 (98.4446)  time: 0.6573  data: 0.0011  max mem: 2373\n",
            "Train: Epoch[2/5]  [230/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.3013  Acc@1: 87.5000 (86.9318)  Acc@5: 100.0000 (98.3766)  time: 0.6579  data: 0.0033  max mem: 2373\n",
            "Train: Epoch[2/5]  [240/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.0558  Acc@1: 87.5000 (87.0851)  Acc@5: 100.0000 (98.4180)  time: 0.6574  data: 0.0029  max mem: 2373\n",
            "Train: Epoch[2/5]  [250/313]  eta: 0:00:41  Lr: 0.001875  Loss: -0.0239  Acc@1: 87.5000 (87.1763)  Acc@5: 100.0000 (98.4811)  time: 0.6571  data: 0.0025  max mem: 2373\n",
            "Train: Epoch[2/5]  [260/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.4215  Acc@1: 87.5000 (87.1169)  Acc@5: 100.0000 (98.4435)  time: 0.6574  data: 0.0027  max mem: 2373\n",
            "Train: Epoch[2/5]  [270/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.1212  Acc@1: 87.5000 (87.2232)  Acc@5: 100.0000 (98.4087)  time: 0.6578  data: 0.0025  max mem: 2373\n",
            "Train: Epoch[2/5]  [280/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.5330  Acc@1: 87.5000 (87.2553)  Acc@5: 100.0000 (98.4208)  time: 0.6578  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[2/5]  [290/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.2792  Acc@1: 87.5000 (87.1993)  Acc@5: 100.0000 (98.3892)  time: 0.6580  data: 0.0025  max mem: 2373\n",
            "Train: Epoch[2/5]  [300/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.0552  Acc@1: 81.2500 (87.1470)  Acc@5: 100.0000 (98.4219)  time: 0.6582  data: 0.0034  max mem: 2373\n",
            "Train: Epoch[2/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.5339  Acc@1: 81.2500 (87.0780)  Acc@5: 100.0000 (98.3722)  time: 0.6577  data: 0.0011  max mem: 2373\n",
            "Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1358  Acc@1: 81.2500 (87.0800)  Acc@5: 100.0000 (98.3800)  time: 0.6415  data: 0.0003  max mem: 2373\n",
            "Train: Epoch[2/5] Total time: 0:03:25 (0.6571 s / it)\n",
            "Averaged stats: Lr: 0.001875  Loss: -0.1358  Acc@1: 81.2500 (87.0800)  Acc@5: 100.0000 (98.3800)\n",
            "Train: Epoch[3/5]  [  0/313]  eta: 0:04:53  Lr: 0.001875  Loss: -0.0099  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.9367  data: 0.3225  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 10/313]  eta: 0:03:27  Lr: 0.001875  Loss: 0.1990  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (99.4318)  time: 0.6849  data: 0.0297  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 20/313]  eta: 0:03:17  Lr: 0.001875  Loss: 0.2967  Acc@1: 87.5000 (85.1190)  Acc@5: 100.0000 (97.6190)  time: 0.6594  data: 0.0010  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 30/313]  eta: 0:03:08  Lr: 0.001875  Loss: -0.0745  Acc@1: 87.5000 (87.0968)  Acc@5: 100.0000 (98.3871)  time: 0.6576  data: 0.0014  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 40/313]  eta: 0:03:01  Lr: 0.001875  Loss: 0.1234  Acc@1: 93.7500 (87.5000)  Acc@5: 100.0000 (98.6280)  time: 0.6562  data: 0.0009  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 50/313]  eta: 0:02:54  Lr: 0.001875  Loss: 0.0064  Acc@1: 87.5000 (87.6225)  Acc@5: 100.0000 (98.4069)  time: 0.6566  data: 0.0027  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 60/313]  eta: 0:02:47  Lr: 0.001875  Loss: 0.4646  Acc@1: 87.5000 (87.0902)  Acc@5: 100.0000 (98.2582)  time: 0.6569  data: 0.0025  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 70/313]  eta: 0:02:40  Lr: 0.001875  Loss: -0.0116  Acc@1: 87.5000 (87.8521)  Acc@5: 100.0000 (98.3275)  time: 0.6568  data: 0.0029  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 80/313]  eta: 0:02:33  Lr: 0.001875  Loss: 0.2055  Acc@1: 87.5000 (87.9630)  Acc@5: 100.0000 (98.3796)  time: 0.6574  data: 0.0029  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 90/313]  eta: 0:02:27  Lr: 0.001875  Loss: 0.3862  Acc@1: 87.5000 (87.5687)  Acc@5: 100.0000 (98.2830)  time: 0.6574  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[3/5]  [100/313]  eta: 0:02:20  Lr: 0.001875  Loss: 0.0759  Acc@1: 87.5000 (87.1287)  Acc@5: 100.0000 (98.1436)  time: 0.6570  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[3/5]  [110/313]  eta: 0:02:13  Lr: 0.001875  Loss: 0.0136  Acc@1: 87.5000 (87.7252)  Acc@5: 100.0000 (98.2545)  time: 0.6568  data: 0.0025  max mem: 2373\n",
            "Train: Epoch[3/5]  [120/313]  eta: 0:02:07  Lr: 0.001875  Loss: -0.0506  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.0888)  time: 0.6569  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[3/5]  [130/313]  eta: 0:02:00  Lr: 0.001875  Loss: 0.5657  Acc@1: 87.5000 (87.1660)  Acc@5: 100.0000 (98.1393)  time: 0.6576  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[3/5]  [140/313]  eta: 0:01:54  Lr: 0.001875  Loss: 0.2695  Acc@1: 87.5000 (87.2784)  Acc@5: 100.0000 (98.2270)  time: 0.6574  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[3/5]  [150/313]  eta: 0:01:47  Lr: 0.001875  Loss: 0.0989  Acc@1: 87.5000 (87.0861)  Acc@5: 100.0000 (98.2616)  time: 0.6571  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[3/5]  [160/313]  eta: 0:01:40  Lr: 0.001875  Loss: 0.3246  Acc@1: 87.5000 (86.8012)  Acc@5: 100.0000 (98.3696)  time: 0.6571  data: 0.0029  max mem: 2373\n",
            "Train: Epoch[3/5]  [170/313]  eta: 0:01:34  Lr: 0.001875  Loss: 0.1522  Acc@1: 87.5000 (86.9152)  Acc@5: 100.0000 (98.4284)  time: 0.6570  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[3/5]  [180/313]  eta: 0:01:27  Lr: 0.001875  Loss: 0.1560  Acc@1: 87.5000 (86.9820)  Acc@5: 100.0000 (98.5152)  time: 0.6575  data: 0.0028  max mem: 2373\n",
            "Train: Epoch[3/5]  [190/313]  eta: 0:01:21  Lr: 0.001875  Loss: 0.0534  Acc@1: 87.5000 (87.0746)  Acc@5: 100.0000 (98.5929)  time: 0.6571  data: 0.0026  max mem: 2373\n",
            "Train: Epoch[3/5]  [200/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.0565  Acc@1: 87.5000 (87.2823)  Acc@5: 100.0000 (98.6629)  time: 0.6568  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[3/5]  [210/313]  eta: 0:01:07  Lr: 0.001875  Loss: 0.9292  Acc@1: 87.5000 (87.1445)  Acc@5: 100.0000 (98.6374)  time: 0.6572  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[3/5]  [220/313]  eta: 0:01:01  Lr: 0.001875  Loss: -0.0144  Acc@1: 87.5000 (87.3586)  Acc@5: 100.0000 (98.6708)  time: 0.6575  data: 0.0026  max mem: 2373\n",
            "Train: Epoch[3/5]  [230/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.4385  Acc@1: 87.5000 (86.9589)  Acc@5: 100.0000 (98.5660)  time: 0.6572  data: 0.0027  max mem: 2373\n",
            "Train: Epoch[3/5]  [240/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.0420  Acc@1: 87.5000 (87.0332)  Acc@5: 100.0000 (98.5737)  time: 0.6571  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[3/5]  [250/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.3914  Acc@1: 87.5000 (87.1016)  Acc@5: 100.0000 (98.6305)  time: 0.6575  data: 0.0025  max mem: 2373\n",
            "Train: Epoch[3/5]  [260/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.1872  Acc@1: 87.5000 (87.1169)  Acc@5: 100.0000 (98.6830)  time: 0.6571  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[3/5]  [270/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.1161  Acc@1: 87.5000 (87.1079)  Acc@5: 100.0000 (98.7315)  time: 0.6565  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[3/5]  [280/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.2974  Acc@1: 87.5000 (87.2109)  Acc@5: 100.0000 (98.7322)  time: 0.6571  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[3/5]  [290/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.2332  Acc@1: 87.5000 (87.2208)  Acc@5: 100.0000 (98.7328)  time: 0.6571  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[3/5]  [300/313]  eta: 0:00:08  Lr: 0.001875  Loss: -0.0241  Acc@1: 87.5000 (87.3131)  Acc@5: 100.0000 (98.7749)  time: 0.6565  data: 0.0015  max mem: 2373\n",
            "Train: Epoch[3/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.0665  Acc@1: 87.5000 (87.3593)  Acc@5: 100.0000 (98.7540)  time: 0.6569  data: 0.0012  max mem: 2373\n",
            "Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1516  Acc@1: 87.5000 (87.3800)  Acc@5: 100.0000 (98.7600)  time: 0.6407  data: 0.0012  max mem: 2373\n",
            "Train: Epoch[3/5] Total time: 0:03:25 (0.6573 s / it)\n",
            "Averaged stats: Lr: 0.001875  Loss: -0.1516  Acc@1: 87.5000 (87.3800)  Acc@5: 100.0000 (98.7600)\n",
            "Train: Epoch[4/5]  [  0/313]  eta: 0:04:10  Lr: 0.001875  Loss: -0.1275  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.7987  data: 0.1864  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 10/313]  eta: 0:03:23  Lr: 0.001875  Loss: 0.2548  Acc@1: 81.2500 (86.3636)  Acc@5: 100.0000 (98.8636)  time: 0.6715  data: 0.0177  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 20/313]  eta: 0:03:14  Lr: 0.001875  Loss: 0.1593  Acc@1: 87.5000 (88.9881)  Acc@5: 100.0000 (99.1071)  time: 0.6574  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 30/313]  eta: 0:03:07  Lr: 0.001875  Loss: 0.1625  Acc@1: 87.5000 (88.1048)  Acc@5: 100.0000 (98.9919)  time: 0.6562  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 40/313]  eta: 0:03:00  Lr: 0.001875  Loss: 0.1914  Acc@1: 87.5000 (88.1098)  Acc@5: 100.0000 (98.7805)  time: 0.6568  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 50/313]  eta: 0:02:53  Lr: 0.001875  Loss: 0.4737  Acc@1: 87.5000 (88.3578)  Acc@5: 100.0000 (99.0196)  time: 0.6570  data: 0.0039  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 60/313]  eta: 0:02:46  Lr: 0.001875  Loss: 0.3176  Acc@1: 87.5000 (88.4221)  Acc@5: 100.0000 (99.0779)  time: 0.6571  data: 0.0043  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 70/313]  eta: 0:02:40  Lr: 0.001875  Loss: 0.3992  Acc@1: 87.5000 (88.6444)  Acc@5: 100.0000 (99.0317)  time: 0.6569  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 80/313]  eta: 0:02:33  Lr: 0.001875  Loss: 0.0398  Acc@1: 87.5000 (88.6574)  Acc@5: 100.0000 (98.9969)  time: 0.6569  data: 0.0027  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 90/313]  eta: 0:02:26  Lr: 0.001875  Loss: 0.0985  Acc@1: 87.5000 (88.9423)  Acc@5: 100.0000 (99.1071)  time: 0.6570  data: 0.0030  max mem: 2373\n",
            "Train: Epoch[4/5]  [100/313]  eta: 0:02:20  Lr: 0.001875  Loss: 0.0220  Acc@1: 93.7500 (88.8614)  Acc@5: 100.0000 (99.0099)  time: 0.6567  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[4/5]  [110/313]  eta: 0:02:13  Lr: 0.001875  Loss: -0.0554  Acc@1: 87.5000 (88.7950)  Acc@5: 100.0000 (98.9865)  time: 0.6569  data: 0.0026  max mem: 2373\n",
            "Train: Epoch[4/5]  [120/313]  eta: 0:02:07  Lr: 0.001875  Loss: 0.1362  Acc@1: 87.5000 (88.5331)  Acc@5: 100.0000 (98.9153)  time: 0.6564  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[4/5]  [130/313]  eta: 0:02:00  Lr: 0.001875  Loss: 0.0755  Acc@1: 87.5000 (88.5973)  Acc@5: 100.0000 (98.9027)  time: 0.6570  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[4/5]  [140/313]  eta: 0:01:53  Lr: 0.001875  Loss: 0.1538  Acc@1: 87.5000 (88.6082)  Acc@5: 100.0000 (98.9362)  time: 0.6570  data: 0.0015  max mem: 2373\n",
            "Train: Epoch[4/5]  [150/313]  eta: 0:01:47  Lr: 0.001875  Loss: 0.3492  Acc@1: 87.5000 (88.5348)  Acc@5: 100.0000 (98.9238)  time: 0.6571  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[4/5]  [160/313]  eta: 0:01:40  Lr: 0.001875  Loss: 0.4689  Acc@1: 87.5000 (88.7034)  Acc@5: 100.0000 (98.9130)  time: 0.6581  data: 0.0025  max mem: 2373\n",
            "Train: Epoch[4/5]  [170/313]  eta: 0:01:34  Lr: 0.001875  Loss: 0.5967  Acc@1: 93.7500 (88.7061)  Acc@5: 100.0000 (98.8304)  time: 0.6580  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[4/5]  [180/313]  eta: 0:01:27  Lr: 0.001875  Loss: -0.0411  Acc@1: 87.5000 (88.7776)  Acc@5: 100.0000 (98.7224)  time: 0.6570  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[4/5]  [190/313]  eta: 0:01:20  Lr: 0.001875  Loss: 0.0059  Acc@1: 87.5000 (88.8416)  Acc@5: 100.0000 (98.7565)  time: 0.6564  data: 0.0029  max mem: 2373\n",
            "Train: Epoch[4/5]  [200/313]  eta: 0:01:14  Lr: 0.001875  Loss: 0.3361  Acc@1: 93.7500 (88.8060)  Acc@5: 100.0000 (98.7562)  time: 0.6569  data: 0.0030  max mem: 2373\n",
            "Train: Epoch[4/5]  [210/313]  eta: 0:01:07  Lr: 0.001875  Loss: 0.5509  Acc@1: 93.7500 (88.7145)  Acc@5: 100.0000 (98.7559)  time: 0.6572  data: 0.0026  max mem: 2373\n",
            "Train: Epoch[4/5]  [220/313]  eta: 0:01:01  Lr: 0.001875  Loss: -0.0368  Acc@1: 87.5000 (88.6595)  Acc@5: 100.0000 (98.8122)  time: 0.6577  data: 0.0028  max mem: 2373\n",
            "Train: Epoch[4/5]  [230/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.0001  Acc@1: 87.5000 (88.5552)  Acc@5: 100.0000 (98.8366)  time: 0.6576  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[4/5]  [240/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.0539  Acc@1: 87.5000 (88.5114)  Acc@5: 100.0000 (98.8589)  time: 0.6571  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[4/5]  [250/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.3829  Acc@1: 87.5000 (88.5458)  Acc@5: 100.0000 (98.8546)  time: 0.6575  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[4/5]  [260/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.0285  Acc@1: 87.5000 (88.5776)  Acc@5: 100.0000 (98.8745)  time: 0.6574  data: 0.0032  max mem: 2373\n",
            "Train: Epoch[4/5]  [270/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.0283  Acc@1: 87.5000 (88.5609)  Acc@5: 100.0000 (98.8699)  time: 0.6573  data: 0.0025  max mem: 2373\n",
            "Train: Epoch[4/5]  [280/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.1771  Acc@1: 87.5000 (88.5231)  Acc@5: 100.0000 (98.8879)  time: 0.6569  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[4/5]  [290/313]  eta: 0:00:15  Lr: 0.001875  Loss: -0.0156  Acc@1: 87.5000 (88.5524)  Acc@5: 100.0000 (98.8617)  time: 0.6564  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[4/5]  [300/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.4946  Acc@1: 87.5000 (88.4551)  Acc@5: 100.0000 (98.8580)  time: 0.6571  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[4/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.1627  Acc@1: 87.5000 (88.3039)  Acc@5: 100.0000 (98.8545)  time: 0.6580  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.0716  Acc@1: 87.5000 (88.2600)  Acc@5: 100.0000 (98.8600)  time: 0.6415  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[4/5] Total time: 0:03:25 (0.6568 s / it)\n",
            "Averaged stats: Lr: 0.001875  Loss: -0.0716  Acc@1: 87.5000 (88.2600)  Acc@5: 100.0000 (98.8600)\n",
            "Train: Epoch[5/5]  [  0/313]  eta: 0:03:56  Lr: 0.001875  Loss: 0.1765  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.7571  data: 0.1394  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 10/313]  eta: 0:03:22  Lr: 0.001875  Loss: 0.1268  Acc@1: 93.7500 (91.4773)  Acc@5: 100.0000 (98.8636)  time: 0.6684  data: 0.0154  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 20/313]  eta: 0:03:14  Lr: 0.001875  Loss: 0.2093  Acc@1: 93.7500 (91.9643)  Acc@5: 100.0000 (99.4048)  time: 0.6578  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 30/313]  eta: 0:03:07  Lr: 0.001875  Loss: 0.2920  Acc@1: 87.5000 (89.5161)  Acc@5: 100.0000 (99.1935)  time: 0.6572  data: 0.0031  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 40/313]  eta: 0:03:00  Lr: 0.001875  Loss: 0.0609  Acc@1: 87.5000 (88.8720)  Acc@5: 100.0000 (98.6280)  time: 0.6574  data: 0.0029  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 50/313]  eta: 0:02:53  Lr: 0.001875  Loss: -0.0718  Acc@1: 87.5000 (89.5833)  Acc@5: 100.0000 (98.7745)  time: 0.6571  data: 0.0011  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 60/313]  eta: 0:02:46  Lr: 0.001875  Loss: 0.3193  Acc@1: 87.5000 (89.0369)  Acc@5: 100.0000 (98.8730)  time: 0.6571  data: 0.0015  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 70/313]  eta: 0:02:40  Lr: 0.001875  Loss: 0.4737  Acc@1: 87.5000 (89.0845)  Acc@5: 100.0000 (98.7676)  time: 0.6562  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 80/313]  eta: 0:02:33  Lr: 0.001875  Loss: 0.1081  Acc@1: 87.5000 (88.7346)  Acc@5: 100.0000 (98.5340)  time: 0.6568  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 90/313]  eta: 0:02:26  Lr: 0.001875  Loss: 0.1332  Acc@1: 87.5000 (88.5989)  Acc@5: 100.0000 (98.5577)  time: 0.6573  data: 0.0025  max mem: 2373\n",
            "Train: Epoch[5/5]  [100/313]  eta: 0:02:20  Lr: 0.001875  Loss: 0.0366  Acc@1: 87.5000 (88.4901)  Acc@5: 100.0000 (98.3911)  time: 0.6578  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[5/5]  [110/313]  eta: 0:02:13  Lr: 0.001875  Loss: 0.0945  Acc@1: 87.5000 (88.3446)  Acc@5: 100.0000 (98.4234)  time: 0.6576  data: 0.0013  max mem: 2373\n",
            "Train: Epoch[5/5]  [120/313]  eta: 0:02:07  Lr: 0.001875  Loss: 0.2492  Acc@1: 87.5000 (88.4814)  Acc@5: 100.0000 (98.3988)  time: 0.6575  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[5/5]  [130/313]  eta: 0:02:00  Lr: 0.001875  Loss: 0.3349  Acc@1: 93.7500 (88.7405)  Acc@5: 100.0000 (98.4256)  time: 0.6578  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[5/5]  [140/313]  eta: 0:01:53  Lr: 0.001875  Loss: 0.3227  Acc@1: 87.5000 (88.5195)  Acc@5: 100.0000 (98.5372)  time: 0.6577  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[5/5]  [150/313]  eta: 0:01:47  Lr: 0.001875  Loss: 0.2675  Acc@1: 87.5000 (88.6589)  Acc@5: 100.0000 (98.5513)  time: 0.6574  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[5/5]  [160/313]  eta: 0:01:40  Lr: 0.001875  Loss: -0.0996  Acc@1: 87.5000 (88.6258)  Acc@5: 100.0000 (98.5637)  time: 0.6571  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[5/5]  [170/313]  eta: 0:01:34  Lr: 0.001875  Loss: -0.0145  Acc@1: 87.5000 (88.7427)  Acc@5: 100.0000 (98.6111)  time: 0.6574  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[5/5]  [180/313]  eta: 0:01:27  Lr: 0.001875  Loss: -0.0032  Acc@1: 87.5000 (88.7086)  Acc@5: 100.0000 (98.6878)  time: 0.6571  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[5/5]  [190/313]  eta: 0:01:20  Lr: 0.001875  Loss: -0.0381  Acc@1: 87.5000 (88.7435)  Acc@5: 100.0000 (98.7238)  time: 0.6573  data: 0.0027  max mem: 2373\n",
            "Train: Epoch[5/5]  [200/313]  eta: 0:01:14  Lr: 0.001875  Loss: 0.3528  Acc@1: 87.5000 (88.6816)  Acc@5: 100.0000 (98.6629)  time: 0.6576  data: 0.0033  max mem: 2373\n",
            "Train: Epoch[5/5]  [210/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.0600  Acc@1: 87.5000 (88.4775)  Acc@5: 100.0000 (98.6374)  time: 0.6576  data: 0.0037  max mem: 2373\n",
            "Train: Epoch[5/5]  [220/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.5298  Acc@1: 87.5000 (88.4615)  Acc@5: 100.0000 (98.6425)  time: 0.6573  data: 0.0025  max mem: 2373\n",
            "Train: Epoch[5/5]  [230/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.0019  Acc@1: 87.5000 (88.4740)  Acc@5: 100.0000 (98.6472)  time: 0.6565  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[5/5]  [240/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.1932  Acc@1: 93.7500 (88.6151)  Acc@5: 100.0000 (98.6515)  time: 0.6570  data: 0.0015  max mem: 2373\n",
            "Train: Epoch[5/5]  [250/313]  eta: 0:00:41  Lr: 0.001875  Loss: -0.0926  Acc@1: 93.7500 (88.7450)  Acc@5: 100.0000 (98.6554)  time: 0.6579  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[5/5]  [260/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.0652  Acc@1: 87.5000 (88.7692)  Acc@5: 100.0000 (98.6351)  time: 0.6579  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[5/5]  [270/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.1835  Acc@1: 87.5000 (88.7915)  Acc@5: 100.0000 (98.6854)  time: 0.6573  data: 0.0025  max mem: 2373\n",
            "Train: Epoch[5/5]  [280/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.2765  Acc@1: 87.5000 (88.7900)  Acc@5: 100.0000 (98.6877)  time: 0.6571  data: 0.0025  max mem: 2373\n",
            "Train: Epoch[5/5]  [290/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.0002  Acc@1: 87.5000 (88.7887)  Acc@5: 100.0000 (98.7328)  time: 0.6572  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[5/5]  [300/313]  eta: 0:00:08  Lr: 0.001875  Loss: -0.0410  Acc@1: 87.5000 (88.7874)  Acc@5: 100.0000 (98.7334)  time: 0.6569  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[5/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.2912  Acc@1: 87.5000 (88.7259)  Acc@5: 100.0000 (98.7339)  time: 0.6569  data: 0.0003  max mem: 2373\n",
            "Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.0245  Acc@1: 87.5000 (88.7200)  Acc@5: 100.0000 (98.7400)  time: 0.6405  data: 0.0003  max mem: 2373\n",
            "Train: Epoch[5/5] Total time: 0:03:25 (0.6568 s / it)\n",
            "Averaged stats: Lr: 0.001875  Loss: -0.0245  Acc@1: 87.5000 (88.7200)  Acc@5: 100.0000 (98.7400)\n",
            "Test: [Task 1]  [ 0/63]  eta: 0:00:37  Loss: 0.5769 (0.5769)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.5981  data: 0.2022  max mem: 2373\n",
            "Test: [Task 1]  [10/63]  eta: 0:00:23  Loss: 0.5445 (0.5064)  Acc@1: 93.7500 (88.6364)  Acc@5: 100.0000 (100.0000)  time: 0.4435  data: 0.0188  max mem: 2373\n",
            "Test: [Task 1]  [20/63]  eta: 0:00:18  Loss: 0.5417 (0.5556)  Acc@1: 87.5000 (88.3929)  Acc@5: 100.0000 (99.7024)  time: 0.4278  data: 0.0005  max mem: 2373\n",
            "Test: [Task 1]  [30/63]  eta: 0:00:14  Loss: 0.4876 (0.5435)  Acc@1: 87.5000 (88.9113)  Acc@5: 100.0000 (99.7984)  time: 0.4266  data: 0.0027  max mem: 2373\n",
            "Test: [Task 1]  [40/63]  eta: 0:00:09  Loss: 0.4551 (0.5286)  Acc@1: 93.7500 (89.3293)  Acc@5: 100.0000 (99.8476)  time: 0.4265  data: 0.0038  max mem: 2373\n",
            "Test: [Task 1]  [50/63]  eta: 0:00:05  Loss: 0.4254 (0.5032)  Acc@1: 93.7500 (90.3186)  Acc@5: 100.0000 (99.7549)  time: 0.4265  data: 0.0016  max mem: 2373\n",
            "Test: [Task 1]  [60/63]  eta: 0:00:01  Loss: 0.4094 (0.4914)  Acc@1: 93.7500 (90.6762)  Acc@5: 100.0000 (99.6926)  time: 0.4258  data: 0.0003  max mem: 2373\n",
            "Test: [Task 1]  [62/63]  eta: 0:00:00  Loss: 0.4007 (0.4889)  Acc@1: 93.7500 (90.8000)  Acc@5: 100.0000 (99.7000)  time: 0.4153  data: 0.0003  max mem: 2373\n",
            "Test: [Task 1] Total time: 0:00:26 (0.4273 s / it)\n",
            "* Acc@1 90.800 Acc@5 99.700 loss 0.489\n",
            "Test: [Task 2]  [ 0/63]  eta: 0:00:40  Loss: 0.6200 (0.6200)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.6425  data: 0.2435  max mem: 2373\n",
            "Test: [Task 2]  [10/63]  eta: 0:00:23  Loss: 0.5573 (0.5992)  Acc@1: 93.7500 (94.8864)  Acc@5: 100.0000 (98.2955)  time: 0.4462  data: 0.0243  max mem: 2373\n",
            "Test: [Task 2]  [20/63]  eta: 0:00:18  Loss: 0.5785 (0.6813)  Acc@1: 93.7500 (92.2619)  Acc@5: 100.0000 (98.8095)  time: 0.4269  data: 0.0014  max mem: 2373\n",
            "Test: [Task 2]  [30/63]  eta: 0:00:14  Loss: 0.6411 (0.6599)  Acc@1: 93.7500 (92.3387)  Acc@5: 100.0000 (98.3871)  time: 0.4270  data: 0.0014  max mem: 2373\n",
            "Test: [Task 2]  [40/63]  eta: 0:00:09  Loss: 0.6135 (0.6412)  Acc@1: 93.7500 (92.3780)  Acc@5: 100.0000 (98.6280)  time: 0.4263  data: 0.0029  max mem: 2373\n",
            "Test: [Task 2]  [50/63]  eta: 0:00:05  Loss: 0.5286 (0.6336)  Acc@1: 93.7500 (92.2794)  Acc@5: 100.0000 (98.6520)  time: 0.4260  data: 0.0018  max mem: 2373\n",
            "Test: [Task 2]  [60/63]  eta: 0:00:01  Loss: 0.5286 (0.6146)  Acc@1: 93.7500 (92.2131)  Acc@5: 100.0000 (98.8730)  time: 0.4264  data: 0.0005  max mem: 2373\n",
            "Test: [Task 2]  [62/63]  eta: 0:00:00  Loss: 0.5086 (0.6055)  Acc@1: 93.7500 (92.3000)  Acc@5: 100.0000 (98.9000)  time: 0.4160  data: 0.0004  max mem: 2373\n",
            "Test: [Task 2] Total time: 0:00:26 (0.4279 s / it)\n",
            "* Acc@1 92.300 Acc@5 98.900 loss 0.606\n",
            "Test: [Task 3]  [ 0/63]  eta: 0:00:48  Loss: 0.2661 (0.2661)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.7684  data: 0.3700  max mem: 2373\n",
            "Test: [Task 3]  [10/63]  eta: 0:00:24  Loss: 0.4616 (0.4745)  Acc@1: 87.5000 (89.2045)  Acc@5: 100.0000 (98.8636)  time: 0.4573  data: 0.0373  max mem: 2373\n",
            "Test: [Task 3]  [20/63]  eta: 0:00:19  Loss: 0.4914 (0.4960)  Acc@1: 87.5000 (89.5833)  Acc@5: 100.0000 (98.8095)  time: 0.4270  data: 0.0023  max mem: 2373\n",
            "Test: [Task 3]  [30/63]  eta: 0:00:14  Loss: 0.5654 (0.4790)  Acc@1: 93.7500 (90.3226)  Acc@5: 100.0000 (98.9919)  time: 0.4268  data: 0.0005  max mem: 2373\n",
            "Test: [Task 3]  [40/63]  eta: 0:00:10  Loss: 0.3778 (0.4795)  Acc@1: 93.7500 (90.8537)  Acc@5: 100.0000 (99.0854)  time: 0.4265  data: 0.0033  max mem: 2373\n",
            "Test: [Task 3]  [50/63]  eta: 0:00:05  Loss: 0.3778 (0.4763)  Acc@1: 93.7500 (91.0539)  Acc@5: 100.0000 (99.0196)  time: 0.4275  data: 0.0034  max mem: 2373\n",
            "Test: [Task 3]  [60/63]  eta: 0:00:01  Loss: 0.4568 (0.4831)  Acc@1: 93.7500 (90.9836)  Acc@5: 100.0000 (99.1803)  time: 0.4275  data: 0.0005  max mem: 2373\n",
            "Test: [Task 3]  [62/63]  eta: 0:00:00  Loss: 0.4795 (0.4846)  Acc@1: 87.5000 (90.9000)  Acc@5: 100.0000 (99.2000)  time: 0.4166  data: 0.0005  max mem: 2373\n",
            "Test: [Task 3] Total time: 0:00:27 (0.4299 s / it)\n",
            "* Acc@1 90.900 Acc@5 99.200 loss 0.485\n",
            "[Average accuracy till task3]\tAcc@1: 91.3333\tAcc@5: 99.2667\tLoss: 0.5263\tForgetting: 4.7500\tBackward: -4.7500\n",
            "Train: Epoch[1/5]  [  0/313]  eta: 0:05:11  Lr: 0.001875  Loss: 2.0563  Acc@1: 12.5000 (12.5000)  Acc@5: 43.7500 (43.7500)  time: 0.9962  data: 0.3786  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 10/313]  eta: 0:03:28  Lr: 0.001875  Loss: 1.7959  Acc@1: 50.0000 (52.2727)  Acc@5: 81.2500 (80.6818)  time: 0.6887  data: 0.0358  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 20/313]  eta: 0:03:17  Lr: 0.001875  Loss: 1.4539  Acc@1: 62.5000 (64.2857)  Acc@5: 93.7500 (86.6071)  time: 0.6570  data: 0.0015  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 30/313]  eta: 0:03:09  Lr: 0.001875  Loss: 1.0128  Acc@1: 81.2500 (69.7581)  Acc@5: 100.0000 (90.3226)  time: 0.6571  data: 0.0028  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 40/313]  eta: 0:03:01  Lr: 0.001875  Loss: 0.7789  Acc@1: 81.2500 (72.5610)  Acc@5: 100.0000 (91.7683)  time: 0.6591  data: 0.0025  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 50/313]  eta: 0:02:54  Lr: 0.001875  Loss: 0.7940  Acc@1: 81.2500 (74.2647)  Acc@5: 100.0000 (93.1373)  time: 0.6601  data: 0.0028  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 60/313]  eta: 0:02:47  Lr: 0.001875  Loss: 0.4136  Acc@1: 81.2500 (76.2295)  Acc@5: 100.0000 (93.7500)  time: 0.6590  data: 0.0028  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 70/313]  eta: 0:02:41  Lr: 0.001875  Loss: 0.7378  Acc@1: 87.5000 (78.0810)  Acc@5: 100.0000 (94.1901)  time: 0.6576  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 80/313]  eta: 0:02:34  Lr: 0.001875  Loss: 0.7876  Acc@1: 93.7500 (79.0895)  Acc@5: 100.0000 (94.8302)  time: 0.6572  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 90/313]  eta: 0:02:27  Lr: 0.001875  Loss: 0.1024  Acc@1: 87.5000 (79.9451)  Acc@5: 100.0000 (95.3297)  time: 0.6574  data: 0.0013  max mem: 2373\n",
            "Train: Epoch[1/5]  [100/313]  eta: 0:02:20  Lr: 0.001875  Loss: 0.4803  Acc@1: 87.5000 (80.5693)  Acc@5: 100.0000 (95.4208)  time: 0.6572  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[1/5]  [110/313]  eta: 0:02:14  Lr: 0.001875  Loss: 0.5310  Acc@1: 87.5000 (81.0248)  Acc@5: 100.0000 (95.5518)  time: 0.6563  data: 0.0013  max mem: 2373\n",
            "Train: Epoch[1/5]  [120/313]  eta: 0:02:07  Lr: 0.001875  Loss: 0.6049  Acc@1: 87.5000 (81.5083)  Acc@5: 100.0000 (95.7645)  time: 0.6560  data: 0.0014  max mem: 2373\n",
            "Train: Epoch[1/5]  [130/313]  eta: 0:02:00  Lr: 0.001875  Loss: 0.3381  Acc@1: 81.2500 (81.5840)  Acc@5: 100.0000 (95.8969)  time: 0.6560  data: 0.0014  max mem: 2373\n",
            "Train: Epoch[1/5]  [140/313]  eta: 0:01:54  Lr: 0.001875  Loss: 0.1678  Acc@1: 87.5000 (81.8706)  Acc@5: 100.0000 (96.0106)  time: 0.6561  data: 0.0032  max mem: 2373\n",
            "Train: Epoch[1/5]  [150/313]  eta: 0:01:47  Lr: 0.001875  Loss: 0.0612  Acc@1: 87.5000 (82.2020)  Acc@5: 100.0000 (96.1921)  time: 0.6558  data: 0.0029  max mem: 2373\n",
            "Train: Epoch[1/5]  [160/313]  eta: 0:01:40  Lr: 0.001875  Loss: 0.4218  Acc@1: 87.5000 (82.5311)  Acc@5: 100.0000 (96.3509)  time: 0.6557  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[1/5]  [170/313]  eta: 0:01:34  Lr: 0.001875  Loss: 0.0967  Acc@1: 81.2500 (82.7120)  Acc@5: 100.0000 (96.4181)  time: 0.6562  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[1/5]  [180/313]  eta: 0:01:27  Lr: 0.001875  Loss: 0.0245  Acc@1: 87.5000 (83.1146)  Acc@5: 100.0000 (96.5815)  time: 0.6553  data: 0.0026  max mem: 2373\n",
            "Train: Epoch[1/5]  [190/313]  eta: 0:01:21  Lr: 0.001875  Loss: 0.1900  Acc@1: 87.5000 (83.4424)  Acc@5: 100.0000 (96.5969)  time: 0.6552  data: 0.0025  max mem: 2373\n",
            "Train: Epoch[1/5]  [200/313]  eta: 0:01:14  Lr: 0.001875  Loss: 0.4612  Acc@1: 87.5000 (83.7687)  Acc@5: 100.0000 (96.7351)  time: 0.6558  data: 0.0029  max mem: 2373\n",
            "Train: Epoch[1/5]  [210/313]  eta: 0:01:07  Lr: 0.001875  Loss: 0.1247  Acc@1: 87.5000 (84.0047)  Acc@5: 100.0000 (96.8306)  time: 0.6553  data: 0.0029  max mem: 2373\n",
            "Train: Epoch[1/5]  [220/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.0550  Acc@1: 87.5000 (84.3043)  Acc@5: 100.0000 (96.8609)  time: 0.6547  data: 0.0013  max mem: 2373\n",
            "Train: Epoch[1/5]  [230/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.1902  Acc@1: 87.5000 (84.3074)  Acc@5: 100.0000 (96.8885)  time: 0.6540  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[1/5]  [240/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.0403  Acc@1: 81.2500 (84.2583)  Acc@5: 100.0000 (96.9139)  time: 0.6534  data: 0.0009  max mem: 2373\n",
            "Train: Epoch[1/5]  [250/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.2476  Acc@1: 81.2500 (84.2131)  Acc@5: 100.0000 (96.9622)  time: 0.6541  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[1/5]  [260/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.0101  Acc@1: 87.5000 (84.5067)  Acc@5: 100.0000 (96.9828)  time: 0.6541  data: 0.0031  max mem: 2373\n",
            "Train: Epoch[1/5]  [270/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.2323  Acc@1: 87.5000 (84.5710)  Acc@5: 100.0000 (97.0480)  time: 0.6540  data: 0.0051  max mem: 2373\n",
            "Train: Epoch[1/5]  [280/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.4446  Acc@1: 87.5000 (84.7198)  Acc@5: 100.0000 (97.1308)  time: 0.6541  data: 0.0035  max mem: 2373\n",
            "Train: Epoch[1/5]  [290/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.1416  Acc@1: 87.5000 (84.7938)  Acc@5: 100.0000 (97.2294)  time: 0.6528  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[1/5]  [300/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.3397  Acc@1: 87.5000 (84.8214)  Acc@5: 100.0000 (97.2384)  time: 0.6533  data: 0.0028  max mem: 2373\n",
            "Train: Epoch[1/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.5613  Acc@1: 87.5000 (84.9076)  Acc@5: 100.0000 (97.3272)  time: 0.6533  data: 0.0006  max mem: 2373\n",
            "Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.0647  Acc@1: 87.5000 (84.9200)  Acc@5: 100.0000 (97.3400)  time: 0.6370  data: 0.0002  max mem: 2373\n",
            "Train: Epoch[1/5] Total time: 0:03:25 (0.6561 s / it)\n",
            "Averaged stats: Lr: 0.001875  Loss: -0.0647  Acc@1: 87.5000 (84.9200)  Acc@5: 100.0000 (97.3400)\n",
            "Train: Epoch[2/5]  [  0/313]  eta: 0:04:11  Lr: 0.001875  Loss: -0.0793  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.8021  data: 0.1886  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 10/313]  eta: 0:03:22  Lr: 0.001875  Loss: 0.0853  Acc@1: 87.5000 (92.0455)  Acc@5: 100.0000 (98.2955)  time: 0.6668  data: 0.0174  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 20/313]  eta: 0:03:13  Lr: 0.001875  Loss: 0.3623  Acc@1: 87.5000 (90.1786)  Acc@5: 100.0000 (97.6190)  time: 0.6528  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 30/313]  eta: 0:03:06  Lr: 0.001875  Loss: 0.6534  Acc@1: 93.7500 (90.5242)  Acc@5: 100.0000 (98.1855)  time: 0.6521  data: 0.0025  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 40/313]  eta: 0:02:59  Lr: 0.001875  Loss: 0.4894  Acc@1: 93.7500 (90.5488)  Acc@5: 100.0000 (98.3232)  time: 0.6529  data: 0.0014  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 50/313]  eta: 0:02:52  Lr: 0.001875  Loss: 0.0871  Acc@1: 93.7500 (90.0735)  Acc@5: 100.0000 (98.4069)  time: 0.6531  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 60/313]  eta: 0:02:45  Lr: 0.001875  Loss: 0.2152  Acc@1: 87.5000 (89.6516)  Acc@5: 100.0000 (98.3607)  time: 0.6526  data: 0.0014  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 70/313]  eta: 0:02:39  Lr: 0.001875  Loss: 0.0863  Acc@1: 87.5000 (88.9965)  Acc@5: 100.0000 (98.3275)  time: 0.6529  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 80/313]  eta: 0:02:32  Lr: 0.001875  Loss: -0.0562  Acc@1: 87.5000 (89.0432)  Acc@5: 100.0000 (98.4568)  time: 0.6543  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 90/313]  eta: 0:02:26  Lr: 0.001875  Loss: 0.2230  Acc@1: 93.7500 (88.9423)  Acc@5: 100.0000 (98.0769)  time: 0.6556  data: 0.0026  max mem: 2373\n",
            "Train: Epoch[2/5]  [100/313]  eta: 0:02:19  Lr: 0.001875  Loss: -0.1316  Acc@1: 87.5000 (88.9233)  Acc@5: 93.7500 (98.0817)  time: 0.6551  data: 0.0026  max mem: 2373\n",
            "Train: Epoch[2/5]  [110/313]  eta: 0:02:12  Lr: 0.001875  Loss: -0.1058  Acc@1: 87.5000 (88.9640)  Acc@5: 100.0000 (98.1419)  time: 0.6554  data: 0.0025  max mem: 2373\n",
            "Train: Epoch[2/5]  [120/313]  eta: 0:02:06  Lr: 0.001875  Loss: 0.2143  Acc@1: 87.5000 (88.6364)  Acc@5: 100.0000 (98.2438)  time: 0.6560  data: 0.0025  max mem: 2373\n",
            "Train: Epoch[2/5]  [130/313]  eta: 0:01:59  Lr: 0.001875  Loss: 0.2736  Acc@1: 87.5000 (88.5973)  Acc@5: 100.0000 (98.2824)  time: 0.6560  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[2/5]  [140/313]  eta: 0:01:53  Lr: 0.001875  Loss: 0.2573  Acc@1: 87.5000 (88.2092)  Acc@5: 100.0000 (98.3156)  time: 0.6560  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[2/5]  [150/313]  eta: 0:01:46  Lr: 0.001875  Loss: -0.0499  Acc@1: 87.5000 (88.2036)  Acc@5: 100.0000 (98.3030)  time: 0.6557  data: 0.0015  max mem: 2373\n",
            "Train: Epoch[2/5]  [160/313]  eta: 0:01:40  Lr: 0.001875  Loss: -0.1202  Acc@1: 87.5000 (88.2764)  Acc@5: 100.0000 (98.3307)  time: 0.6561  data: 0.0027  max mem: 2373\n",
            "Train: Epoch[2/5]  [170/313]  eta: 0:01:33  Lr: 0.001875  Loss: 0.2436  Acc@1: 87.5000 (88.3041)  Acc@5: 100.0000 (98.3553)  time: 0.6564  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[2/5]  [180/313]  eta: 0:01:27  Lr: 0.001875  Loss: 0.1050  Acc@1: 93.7500 (88.6050)  Acc@5: 100.0000 (98.4116)  time: 0.6564  data: 0.0025  max mem: 2373\n",
            "Train: Epoch[2/5]  [190/313]  eta: 0:01:20  Lr: 0.001875  Loss: 0.2394  Acc@1: 93.7500 (88.5471)  Acc@5: 100.0000 (98.4293)  time: 0.6563  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[2/5]  [200/313]  eta: 0:01:14  Lr: 0.001875  Loss: 0.3111  Acc@1: 87.5000 (88.3396)  Acc@5: 100.0000 (98.3831)  time: 0.6559  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[2/5]  [210/313]  eta: 0:01:07  Lr: 0.001875  Loss: 0.5045  Acc@1: 87.5000 (88.3886)  Acc@5: 100.0000 (98.4005)  time: 0.6564  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[2/5]  [220/313]  eta: 0:01:00  Lr: 0.001875  Loss: 0.1332  Acc@1: 87.5000 (88.4050)  Acc@5: 100.0000 (98.3597)  time: 0.6569  data: 0.0025  max mem: 2373\n",
            "Train: Epoch[2/5]  [230/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.2408  Acc@1: 87.5000 (88.2576)  Acc@5: 100.0000 (98.3766)  time: 0.6565  data: 0.0025  max mem: 2373\n",
            "Train: Epoch[2/5]  [240/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.2931  Acc@1: 87.5000 (88.3299)  Acc@5: 100.0000 (98.4180)  time: 0.6568  data: 0.0014  max mem: 2373\n",
            "Train: Epoch[2/5]  [250/313]  eta: 0:00:41  Lr: 0.001875  Loss: -0.1507  Acc@1: 87.5000 (88.3217)  Acc@5: 100.0000 (98.4562)  time: 0.6576  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[2/5]  [260/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.1308  Acc@1: 87.5000 (88.4339)  Acc@5: 100.0000 (98.4195)  time: 0.6568  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[2/5]  [270/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.2698  Acc@1: 87.5000 (88.4225)  Acc@5: 100.0000 (98.3856)  time: 0.6567  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[2/5]  [280/313]  eta: 0:00:21  Lr: 0.001875  Loss: -0.0984  Acc@1: 87.5000 (88.3674)  Acc@5: 100.0000 (98.3763)  time: 0.6571  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[2/5]  [290/313]  eta: 0:00:15  Lr: 0.001875  Loss: -0.1019  Acc@1: 93.7500 (88.5309)  Acc@5: 100.0000 (98.4107)  time: 0.6565  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[2/5]  [300/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.3604  Acc@1: 87.5000 (88.5174)  Acc@5: 100.0000 (98.3596)  time: 0.6570  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[2/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.1971  Acc@1: 87.5000 (88.5651)  Acc@5: 100.0000 (98.3722)  time: 0.6575  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.5296  Acc@1: 87.5000 (88.5400)  Acc@5: 100.0000 (98.3600)  time: 0.6412  data: 0.0015  max mem: 2373\n",
            "Train: Epoch[2/5] Total time: 0:03:25 (0.6552 s / it)\n",
            "Averaged stats: Lr: 0.001875  Loss: 0.5296  Acc@1: 87.5000 (88.5400)  Acc@5: 100.0000 (98.3600)\n",
            "Train: Epoch[3/5]  [  0/313]  eta: 0:04:12  Lr: 0.001875  Loss: 0.0964  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.8056  data: 0.1901  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 10/313]  eta: 0:03:23  Lr: 0.001875  Loss: 0.0190  Acc@1: 93.7500 (89.7727)  Acc@5: 100.0000 (98.2955)  time: 0.6719  data: 0.0178  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 20/313]  eta: 0:03:14  Lr: 0.001875  Loss: 0.0631  Acc@1: 87.5000 (89.2857)  Acc@5: 100.0000 (97.9167)  time: 0.6578  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 30/313]  eta: 0:03:07  Lr: 0.001875  Loss: -0.0963  Acc@1: 87.5000 (89.5161)  Acc@5: 100.0000 (97.9839)  time: 0.6578  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 40/313]  eta: 0:03:00  Lr: 0.001875  Loss: 0.4005  Acc@1: 87.5000 (88.8720)  Acc@5: 100.0000 (98.0183)  time: 0.6579  data: 0.0027  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 50/313]  eta: 0:02:53  Lr: 0.001875  Loss: 0.2864  Acc@1: 87.5000 (88.6029)  Acc@5: 100.0000 (98.0392)  time: 0.6575  data: 0.0026  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 60/313]  eta: 0:02:47  Lr: 0.001875  Loss: 0.0080  Acc@1: 87.5000 (88.4221)  Acc@5: 100.0000 (98.2582)  time: 0.6584  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 70/313]  eta: 0:02:40  Lr: 0.001875  Loss: 0.1224  Acc@1: 87.5000 (87.9401)  Acc@5: 100.0000 (98.1514)  time: 0.6593  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 80/313]  eta: 0:02:33  Lr: 0.001875  Loss: 0.2073  Acc@1: 87.5000 (88.5031)  Acc@5: 100.0000 (98.3796)  time: 0.6589  data: 0.0028  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 90/313]  eta: 0:02:27  Lr: 0.001875  Loss: 0.2793  Acc@1: 87.5000 (88.3242)  Acc@5: 100.0000 (98.3516)  time: 0.6580  data: 0.0057  max mem: 2373\n",
            "Train: Epoch[3/5]  [100/313]  eta: 0:02:20  Lr: 0.001875  Loss: -0.0244  Acc@1: 87.5000 (88.3045)  Acc@5: 100.0000 (98.3911)  time: 0.6570  data: 0.0044  max mem: 2373\n",
            "Train: Epoch[3/5]  [110/313]  eta: 0:02:13  Lr: 0.001875  Loss: 0.1083  Acc@1: 87.5000 (88.5135)  Acc@5: 100.0000 (98.4234)  time: 0.6559  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[3/5]  [120/313]  eta: 0:02:07  Lr: 0.001875  Loss: 0.4416  Acc@1: 87.5000 (88.4814)  Acc@5: 100.0000 (98.5021)  time: 0.6555  data: 0.0012  max mem: 2373\n",
            "Train: Epoch[3/5]  [130/313]  eta: 0:02:00  Lr: 0.001875  Loss: 0.0836  Acc@1: 87.5000 (88.7882)  Acc@5: 100.0000 (98.5687)  time: 0.6558  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[3/5]  [140/313]  eta: 0:01:53  Lr: 0.001875  Loss: 0.3006  Acc@1: 87.5000 (88.4752)  Acc@5: 100.0000 (98.4929)  time: 0.6559  data: 0.0014  max mem: 2373\n",
            "Train: Epoch[3/5]  [150/313]  eta: 0:01:47  Lr: 0.001875  Loss: 0.0889  Acc@1: 87.5000 (88.5762)  Acc@5: 100.0000 (98.4685)  time: 0.6556  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[3/5]  [160/313]  eta: 0:01:40  Lr: 0.001875  Loss: 0.0316  Acc@1: 87.5000 (88.6258)  Acc@5: 100.0000 (98.4084)  time: 0.6545  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[3/5]  [170/313]  eta: 0:01:34  Lr: 0.001875  Loss: 0.1328  Acc@1: 93.7500 (88.8889)  Acc@5: 100.0000 (98.4284)  time: 0.6545  data: 0.0032  max mem: 2373\n",
            "Train: Epoch[3/5]  [180/313]  eta: 0:01:27  Lr: 0.001875  Loss: 0.1466  Acc@1: 87.5000 (88.7086)  Acc@5: 100.0000 (98.4116)  time: 0.6556  data: 0.0033  max mem: 2373\n",
            "Train: Epoch[3/5]  [190/313]  eta: 0:01:20  Lr: 0.001875  Loss: 0.0141  Acc@1: 87.5000 (88.4817)  Acc@5: 100.0000 (98.3639)  time: 0.6541  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[3/5]  [200/313]  eta: 0:01:14  Lr: 0.001875  Loss: 0.2246  Acc@1: 87.5000 (88.5883)  Acc@5: 100.0000 (98.3831)  time: 0.6540  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[3/5]  [210/313]  eta: 0:01:07  Lr: 0.001875  Loss: 0.3431  Acc@1: 93.7500 (88.6256)  Acc@5: 100.0000 (98.4301)  time: 0.6547  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[3/5]  [220/313]  eta: 0:01:01  Lr: 0.001875  Loss: -0.1147  Acc@1: 87.5000 (88.6312)  Acc@5: 100.0000 (98.4446)  time: 0.6539  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[3/5]  [230/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.1189  Acc@1: 87.5000 (88.6364)  Acc@5: 100.0000 (98.4848)  time: 0.6547  data: 0.0010  max mem: 2373\n",
            "Train: Epoch[3/5]  [240/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.0263  Acc@1: 87.5000 (88.7189)  Acc@5: 100.0000 (98.5218)  time: 0.6553  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[3/5]  [250/313]  eta: 0:00:41  Lr: 0.001875  Loss: -0.0368  Acc@1: 87.5000 (88.6454)  Acc@5: 100.0000 (98.5309)  time: 0.6556  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[3/5]  [260/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.2324  Acc@1: 87.5000 (88.5536)  Acc@5: 100.0000 (98.4674)  time: 0.6562  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[3/5]  [270/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.5434  Acc@1: 87.5000 (88.6070)  Acc@5: 100.0000 (98.4779)  time: 0.6559  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[3/5]  [280/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.0919  Acc@1: 93.7500 (88.6343)  Acc@5: 100.0000 (98.4653)  time: 0.6558  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[3/5]  [290/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.0639  Acc@1: 87.5000 (88.5954)  Acc@5: 100.0000 (98.4321)  time: 0.6558  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[3/5]  [300/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.0533  Acc@1: 87.5000 (88.5590)  Acc@5: 100.0000 (98.4427)  time: 0.6554  data: 0.0030  max mem: 2373\n",
            "Train: Epoch[3/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: -0.0836  Acc@1: 87.5000 (88.4646)  Acc@5: 100.0000 (98.4727)  time: 0.6561  data: 0.0028  max mem: 2373\n",
            "Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.2966  Acc@1: 87.5000 (88.5000)  Acc@5: 100.0000 (98.4800)  time: 0.6399  data: 0.0028  max mem: 2373\n",
            "Train: Epoch[3/5] Total time: 0:03:25 (0.6559 s / it)\n",
            "Averaged stats: Lr: 0.001875  Loss: 0.2966  Acc@1: 87.5000 (88.5000)  Acc@5: 100.0000 (98.4800)\n",
            "Train: Epoch[4/5]  [  0/313]  eta: 0:04:03  Lr: 0.001875  Loss: -0.1802  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.7778  data: 0.1647  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 10/313]  eta: 0:03:22  Lr: 0.001875  Loss: -0.1763  Acc@1: 93.7500 (93.1818)  Acc@5: 100.0000 (99.4318)  time: 0.6691  data: 0.0176  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 20/313]  eta: 0:03:14  Lr: 0.001875  Loss: 0.1614  Acc@1: 93.7500 (91.0714)  Acc@5: 100.0000 (99.1071)  time: 0.6571  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 30/313]  eta: 0:03:06  Lr: 0.001875  Loss: 0.1719  Acc@1: 93.7500 (89.5161)  Acc@5: 100.0000 (99.1935)  time: 0.6558  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 40/313]  eta: 0:03:00  Lr: 0.001875  Loss: 0.3033  Acc@1: 87.5000 (89.1768)  Acc@5: 100.0000 (99.3902)  time: 0.6561  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 50/313]  eta: 0:02:53  Lr: 0.001875  Loss: -0.0717  Acc@1: 87.5000 (89.3382)  Acc@5: 100.0000 (99.5098)  time: 0.6563  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 60/313]  eta: 0:02:46  Lr: 0.001875  Loss: 0.0857  Acc@1: 87.5000 (88.3197)  Acc@5: 100.0000 (99.2828)  time: 0.6563  data: 0.0027  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 70/313]  eta: 0:02:39  Lr: 0.001875  Loss: 0.1839  Acc@1: 87.5000 (88.6444)  Acc@5: 100.0000 (99.2958)  time: 0.6562  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 80/313]  eta: 0:02:33  Lr: 0.001875  Loss: 0.1315  Acc@1: 93.7500 (89.2747)  Acc@5: 100.0000 (99.3827)  time: 0.6560  data: 0.0029  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 90/313]  eta: 0:02:26  Lr: 0.001875  Loss: -0.1310  Acc@1: 93.7500 (89.5604)  Acc@5: 100.0000 (99.3819)  time: 0.6559  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[4/5]  [100/313]  eta: 0:02:20  Lr: 0.001875  Loss: 0.0629  Acc@1: 93.7500 (89.6658)  Acc@5: 100.0000 (99.4431)  time: 0.6563  data: 0.0026  max mem: 2373\n",
            "Train: Epoch[4/5]  [110/313]  eta: 0:02:13  Lr: 0.001875  Loss: 0.3599  Acc@1: 93.7500 (89.5833)  Acc@5: 100.0000 (99.4369)  time: 0.6565  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[4/5]  [120/313]  eta: 0:02:06  Lr: 0.001875  Loss: 0.1265  Acc@1: 87.5000 (89.7727)  Acc@5: 100.0000 (99.4318)  time: 0.6560  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[4/5]  [130/313]  eta: 0:02:00  Lr: 0.001875  Loss: 0.4023  Acc@1: 87.5000 (89.5515)  Acc@5: 100.0000 (99.2366)  time: 0.6561  data: 0.0025  max mem: 2373\n",
            "Train: Epoch[4/5]  [140/313]  eta: 0:01:53  Lr: 0.001875  Loss: 0.3657  Acc@1: 87.5000 (89.5390)  Acc@5: 100.0000 (99.2465)  time: 0.6565  data: 0.0027  max mem: 2373\n",
            "Train: Epoch[4/5]  [150/313]  eta: 0:01:47  Lr: 0.001875  Loss: 0.3285  Acc@1: 87.5000 (89.1142)  Acc@5: 100.0000 (99.2136)  time: 0.6563  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[4/5]  [160/313]  eta: 0:01:40  Lr: 0.001875  Loss: 0.3870  Acc@1: 87.5000 (89.1304)  Acc@5: 100.0000 (99.1848)  time: 0.6563  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[4/5]  [170/313]  eta: 0:01:33  Lr: 0.001875  Loss: -0.0964  Acc@1: 87.5000 (89.3275)  Acc@5: 100.0000 (99.1959)  time: 0.6565  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[4/5]  [180/313]  eta: 0:01:27  Lr: 0.001875  Loss: -0.0156  Acc@1: 93.7500 (89.3646)  Acc@5: 100.0000 (99.2058)  time: 0.6561  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[4/5]  [190/313]  eta: 0:01:20  Lr: 0.001875  Loss: 0.0814  Acc@1: 87.5000 (89.4306)  Acc@5: 100.0000 (99.2147)  time: 0.6561  data: 0.0031  max mem: 2373\n",
            "Train: Epoch[4/5]  [200/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.1617  Acc@1: 87.5000 (89.4590)  Acc@5: 100.0000 (99.2226)  time: 0.6562  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[4/5]  [210/313]  eta: 0:01:07  Lr: 0.001875  Loss: 0.1852  Acc@1: 87.5000 (89.5735)  Acc@5: 100.0000 (99.2002)  time: 0.6569  data: 0.0035  max mem: 2373\n",
            "Train: Epoch[4/5]  [220/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.1840  Acc@1: 87.5000 (89.4514)  Acc@5: 100.0000 (99.1233)  time: 0.6568  data: 0.0029  max mem: 2373\n",
            "Train: Epoch[4/5]  [230/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.1203  Acc@1: 87.5000 (89.4210)  Acc@5: 100.0000 (99.1071)  time: 0.6561  data: 0.0049  max mem: 2373\n",
            "Train: Epoch[4/5]  [240/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.0656  Acc@1: 93.7500 (89.3413)  Acc@5: 100.0000 (99.0923)  time: 0.6562  data: 0.0046  max mem: 2373\n",
            "Train: Epoch[4/5]  [250/313]  eta: 0:00:41  Lr: 0.001875  Loss: -0.0288  Acc@1: 87.5000 (89.2430)  Acc@5: 100.0000 (99.0538)  time: 0.6564  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[4/5]  [260/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.0082  Acc@1: 87.5000 (89.2481)  Acc@5: 100.0000 (99.0421)  time: 0.6566  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[4/5]  [270/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.2574  Acc@1: 93.7500 (89.3681)  Acc@5: 100.0000 (99.0544)  time: 0.6561  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[4/5]  [280/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.2014  Acc@1: 87.5000 (89.2349)  Acc@5: 100.0000 (99.0214)  time: 0.6558  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[4/5]  [290/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.2171  Acc@1: 87.5000 (89.2826)  Acc@5: 100.0000 (99.0550)  time: 0.6559  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[4/5]  [300/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.3577  Acc@1: 93.7500 (89.3065)  Acc@5: 100.0000 (99.0241)  time: 0.6560  data: 0.0032  max mem: 2373\n",
            "Train: Epoch[4/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: -0.1228  Acc@1: 93.7500 (89.4695)  Acc@5: 100.0000 (99.0354)  time: 0.6565  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.0609  Acc@1: 93.7500 (89.5000)  Acc@5: 100.0000 (99.0400)  time: 0.6398  data: 0.0012  max mem: 2373\n",
            "Train: Epoch[4/5] Total time: 0:03:25 (0.6560 s / it)\n",
            "Averaged stats: Lr: 0.001875  Loss: -0.0609  Acc@1: 93.7500 (89.5000)  Acc@5: 100.0000 (99.0400)\n",
            "Train: Epoch[5/5]  [  0/313]  eta: 0:04:39  Lr: 0.001875  Loss: 0.0203  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.8929  data: 0.2796  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 10/313]  eta: 0:03:25  Lr: 0.001875  Loss: 0.1312  Acc@1: 93.7500 (89.7727)  Acc@5: 100.0000 (97.7273)  time: 0.6782  data: 0.0264  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 20/313]  eta: 0:03:15  Lr: 0.001875  Loss: 0.1943  Acc@1: 87.5000 (88.6905)  Acc@5: 100.0000 (97.9167)  time: 0.6559  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 30/313]  eta: 0:03:07  Lr: 0.001875  Loss: 0.4055  Acc@1: 87.5000 (88.9113)  Acc@5: 100.0000 (97.9839)  time: 0.6558  data: 0.0032  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 40/313]  eta: 0:03:00  Lr: 0.001875  Loss: 0.2129  Acc@1: 87.5000 (88.5671)  Acc@5: 100.0000 (98.0183)  time: 0.6565  data: 0.0025  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 50/313]  eta: 0:02:53  Lr: 0.001875  Loss: 0.2066  Acc@1: 87.5000 (88.8480)  Acc@5: 100.0000 (98.2843)  time: 0.6563  data: 0.0013  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 60/313]  eta: 0:02:47  Lr: 0.001875  Loss: -0.0723  Acc@1: 93.7500 (89.5492)  Acc@5: 100.0000 (98.5656)  time: 0.6562  data: 0.0011  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 70/313]  eta: 0:02:40  Lr: 0.001875  Loss: -0.0469  Acc@1: 93.7500 (89.7887)  Acc@5: 100.0000 (98.5035)  time: 0.6564  data: 0.0034  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 80/313]  eta: 0:02:33  Lr: 0.001875  Loss: -0.0937  Acc@1: 87.5000 (89.8148)  Acc@5: 100.0000 (98.3025)  time: 0.6564  data: 0.0034  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 90/313]  eta: 0:02:26  Lr: 0.001875  Loss: -0.1982  Acc@1: 87.5000 (90.2473)  Acc@5: 100.0000 (98.4203)  time: 0.6563  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[5/5]  [100/313]  eta: 0:02:20  Lr: 0.001875  Loss: 0.0197  Acc@1: 93.7500 (90.3465)  Acc@5: 100.0000 (98.5149)  time: 0.6562  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[5/5]  [110/313]  eta: 0:02:13  Lr: 0.001875  Loss: 0.1957  Acc@1: 93.7500 (90.1464)  Acc@5: 100.0000 (98.4234)  time: 0.6559  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[5/5]  [120/313]  eta: 0:02:07  Lr: 0.001875  Loss: 0.0027  Acc@1: 93.7500 (90.2893)  Acc@5: 100.0000 (98.3988)  time: 0.6561  data: 0.0025  max mem: 2373\n",
            "Train: Epoch[5/5]  [130/313]  eta: 0:02:00  Lr: 0.001875  Loss: -0.0052  Acc@1: 93.7500 (90.3626)  Acc@5: 100.0000 (98.5210)  time: 0.6564  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[5/5]  [140/313]  eta: 0:01:53  Lr: 0.001875  Loss: -0.0746  Acc@1: 93.7500 (90.7358)  Acc@5: 100.0000 (98.5372)  time: 0.6561  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[5/5]  [150/313]  eta: 0:01:47  Lr: 0.001875  Loss: -0.0678  Acc@1: 93.7500 (90.9354)  Acc@5: 100.0000 (98.5513)  time: 0.6561  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[5/5]  [160/313]  eta: 0:01:40  Lr: 0.001875  Loss: 0.3202  Acc@1: 93.7500 (90.9938)  Acc@5: 100.0000 (98.5637)  time: 0.6562  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[5/5]  [170/313]  eta: 0:01:34  Lr: 0.001875  Loss: -0.0533  Acc@1: 93.7500 (91.0819)  Acc@5: 100.0000 (98.6111)  time: 0.6560  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[5/5]  [180/313]  eta: 0:01:27  Lr: 0.001875  Loss: 0.3870  Acc@1: 93.7500 (91.1602)  Acc@5: 100.0000 (98.5843)  time: 0.6571  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[5/5]  [190/313]  eta: 0:01:20  Lr: 0.001875  Loss: 0.5795  Acc@1: 87.5000 (90.9686)  Acc@5: 100.0000 (98.6257)  time: 0.6570  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[5/5]  [200/313]  eta: 0:01:14  Lr: 0.001875  Loss: 0.0152  Acc@1: 87.5000 (90.7649)  Acc@5: 100.0000 (98.6940)  time: 0.6567  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[5/5]  [210/313]  eta: 0:01:07  Lr: 0.001875  Loss: 0.4136  Acc@1: 87.5000 (90.7583)  Acc@5: 100.0000 (98.7263)  time: 0.6569  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[5/5]  [220/313]  eta: 0:01:01  Lr: 0.001875  Loss: -0.1422  Acc@1: 93.7500 (90.7805)  Acc@5: 100.0000 (98.7274)  time: 0.6572  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[5/5]  [230/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.0206  Acc@1: 87.5000 (90.5844)  Acc@5: 100.0000 (98.7013)  time: 0.6578  data: 0.0026  max mem: 2373\n",
            "Train: Epoch[5/5]  [240/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.3093  Acc@1: 87.5000 (90.5861)  Acc@5: 100.0000 (98.7293)  time: 0.6574  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[5/5]  [250/313]  eta: 0:00:41  Lr: 0.001875  Loss: -0.1913  Acc@1: 93.7500 (90.6873)  Acc@5: 100.0000 (98.7550)  time: 0.6575  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[5/5]  [260/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.0259  Acc@1: 93.7500 (90.6849)  Acc@5: 100.0000 (98.7548)  time: 0.6582  data: 0.0009  max mem: 2373\n",
            "Train: Epoch[5/5]  [270/313]  eta: 0:00:28  Lr: 0.001875  Loss: -0.1550  Acc@1: 87.5000 (90.5212)  Acc@5: 100.0000 (98.7546)  time: 0.6589  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[5/5]  [280/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.0037  Acc@1: 93.7500 (90.6139)  Acc@5: 100.0000 (98.7767)  time: 0.6589  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[5/5]  [290/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.4399  Acc@1: 93.7500 (90.6572)  Acc@5: 100.0000 (98.7973)  time: 0.6581  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[5/5]  [300/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.1578  Acc@1: 87.5000 (90.5523)  Acc@5: 100.0000 (98.7957)  time: 0.6572  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[5/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.2799  Acc@1: 87.5000 (90.4944)  Acc@5: 100.0000 (98.7339)  time: 0.6571  data: 0.0013  max mem: 2373\n",
            "Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.0605  Acc@1: 87.5000 (90.4800)  Acc@5: 100.0000 (98.7400)  time: 0.6408  data: 0.0012  max mem: 2373\n",
            "Train: Epoch[5/5] Total time: 0:03:25 (0.6568 s / it)\n",
            "Averaged stats: Lr: 0.001875  Loss: 0.0605  Acc@1: 87.5000 (90.4800)  Acc@5: 100.0000 (98.7400)\n",
            "Test: [Task 1]  [ 0/63]  eta: 0:00:39  Loss: 0.6645 (0.6645)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.6245  data: 0.2342  max mem: 2373\n",
            "Test: [Task 1]  [10/63]  eta: 0:00:23  Loss: 0.4877 (0.5266)  Acc@1: 87.5000 (89.2045)  Acc@5: 100.0000 (99.4318)  time: 0.4456  data: 0.0217  max mem: 2373\n",
            "Test: [Task 1]  [20/63]  eta: 0:00:18  Loss: 0.5238 (0.5756)  Acc@1: 87.5000 (88.9881)  Acc@5: 100.0000 (99.1071)  time: 0.4281  data: 0.0016  max mem: 2373\n",
            "Test: [Task 1]  [30/63]  eta: 0:00:14  Loss: 0.5312 (0.5715)  Acc@1: 87.5000 (88.7097)  Acc@5: 100.0000 (99.1935)  time: 0.4273  data: 0.0035  max mem: 2373\n",
            "Test: [Task 1]  [40/63]  eta: 0:00:09  Loss: 0.4865 (0.5634)  Acc@1: 87.5000 (88.8720)  Acc@5: 100.0000 (99.3902)  time: 0.4266  data: 0.0024  max mem: 2373\n",
            "Test: [Task 1]  [50/63]  eta: 0:00:05  Loss: 0.4727 (0.5406)  Acc@1: 87.5000 (89.3382)  Acc@5: 100.0000 (99.5098)  time: 0.4265  data: 0.0007  max mem: 2373\n",
            "Test: [Task 1]  [60/63]  eta: 0:00:01  Loss: 0.4688 (0.5322)  Acc@1: 93.7500 (89.4467)  Acc@5: 100.0000 (99.2828)  time: 0.4262  data: 0.0024  max mem: 2373\n",
            "Test: [Task 1]  [62/63]  eta: 0:00:00  Loss: 0.4615 (0.5320)  Acc@1: 93.7500 (89.6000)  Acc@5: 100.0000 (99.3000)  time: 0.4154  data: 0.0023  max mem: 2373\n",
            "Test: [Task 1] Total time: 0:00:26 (0.4276 s / it)\n",
            "* Acc@1 89.600 Acc@5 99.300 loss 0.532\n",
            "Test: [Task 2]  [ 0/63]  eta: 0:00:36  Loss: 0.7674 (0.7674)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.5862  data: 0.1934  max mem: 2373\n",
            "Test: [Task 2]  [10/63]  eta: 0:00:23  Loss: 0.6293 (0.6542)  Acc@1: 87.5000 (90.3409)  Acc@5: 100.0000 (98.2955)  time: 0.4416  data: 0.0181  max mem: 2373\n",
            "Test: [Task 2]  [20/63]  eta: 0:00:18  Loss: 0.6496 (0.7237)  Acc@1: 87.5000 (88.9881)  Acc@5: 100.0000 (97.9167)  time: 0.4278  data: 0.0010  max mem: 2373\n",
            "Test: [Task 2]  [30/63]  eta: 0:00:14  Loss: 0.6496 (0.7138)  Acc@1: 93.7500 (90.1210)  Acc@5: 100.0000 (97.7823)  time: 0.4278  data: 0.0033  max mem: 2373\n",
            "Test: [Task 2]  [40/63]  eta: 0:00:09  Loss: 0.6273 (0.6947)  Acc@1: 93.7500 (90.0915)  Acc@5: 100.0000 (98.0183)  time: 0.4267  data: 0.0053  max mem: 2373\n",
            "Test: [Task 2]  [50/63]  eta: 0:00:05  Loss: 0.6153 (0.6913)  Acc@1: 87.5000 (89.2157)  Acc@5: 100.0000 (98.1618)  time: 0.4267  data: 0.0030  max mem: 2373\n",
            "Test: [Task 2]  [60/63]  eta: 0:00:01  Loss: 0.5578 (0.6705)  Acc@1: 87.5000 (89.6516)  Acc@5: 100.0000 (98.3607)  time: 0.4275  data: 0.0004  max mem: 2373\n",
            "Test: [Task 2]  [62/63]  eta: 0:00:00  Loss: 0.5578 (0.6615)  Acc@1: 87.5000 (89.7000)  Acc@5: 100.0000 (98.4000)  time: 0.4165  data: 0.0004  max mem: 2373\n",
            "Test: [Task 2] Total time: 0:00:26 (0.4279 s / it)\n",
            "* Acc@1 89.700 Acc@5 98.400 loss 0.662\n",
            "Test: [Task 3]  [ 0/63]  eta: 0:00:50  Loss: 0.3662 (0.3662)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.8027  data: 0.4091  max mem: 2373\n",
            "Test: [Task 3]  [10/63]  eta: 0:00:24  Loss: 0.5109 (0.5167)  Acc@1: 87.5000 (90.3409)  Acc@5: 100.0000 (98.8636)  time: 0.4618  data: 0.0382  max mem: 2373\n",
            "Test: [Task 3]  [20/63]  eta: 0:00:19  Loss: 0.5497 (0.5291)  Acc@1: 87.5000 (89.5833)  Acc@5: 100.0000 (98.5119)  time: 0.4278  data: 0.0009  max mem: 2373\n",
            "Test: [Task 3]  [30/63]  eta: 0:00:14  Loss: 0.5421 (0.5235)  Acc@1: 87.5000 (88.7097)  Acc@5: 100.0000 (98.7903)  time: 0.4278  data: 0.0005  max mem: 2373\n",
            "Test: [Task 3]  [40/63]  eta: 0:00:10  Loss: 0.4206 (0.5143)  Acc@1: 87.5000 (89.3293)  Acc@5: 100.0000 (99.0854)  time: 0.4273  data: 0.0030  max mem: 2373\n",
            "Test: [Task 3]  [50/63]  eta: 0:00:05  Loss: 0.4624 (0.5206)  Acc@1: 93.7500 (89.3382)  Acc@5: 100.0000 (98.8971)  time: 0.4274  data: 0.0034  max mem: 2373\n",
            "Test: [Task 3]  [60/63]  eta: 0:00:01  Loss: 0.5319 (0.5327)  Acc@1: 87.5000 (88.4221)  Acc@5: 100.0000 (99.0779)  time: 0.4275  data: 0.0007  max mem: 2373\n",
            "Test: [Task 3]  [62/63]  eta: 0:00:00  Loss: 0.5565 (0.5330)  Acc@1: 87.5000 (88.5000)  Acc@5: 100.0000 (99.1000)  time: 0.4170  data: 0.0003  max mem: 2373\n",
            "Test: [Task 3] Total time: 0:00:27 (0.4310 s / it)\n",
            "* Acc@1 88.500 Acc@5 99.100 loss 0.533\n",
            "Test: [Task 4]  [ 0/63]  eta: 0:00:37  Loss: 0.6950 (0.6950)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.5981  data: 0.2026  max mem: 2373\n",
            "Test: [Task 4]  [10/63]  eta: 0:00:23  Loss: 0.5117 (0.5535)  Acc@1: 93.7500 (89.2045)  Acc@5: 100.0000 (99.4318)  time: 0.4449  data: 0.0242  max mem: 2373\n",
            "Test: [Task 4]  [20/63]  eta: 0:00:18  Loss: 0.5090 (0.5704)  Acc@1: 87.5000 (87.2024)  Acc@5: 100.0000 (98.5119)  time: 0.4292  data: 0.0034  max mem: 2373\n",
            "Test: [Task 4]  [30/63]  eta: 0:00:14  Loss: 0.5090 (0.5546)  Acc@1: 87.5000 (88.3065)  Acc@5: 100.0000 (98.5887)  time: 0.4279  data: 0.0004  max mem: 2373\n",
            "Test: [Task 4]  [40/63]  eta: 0:00:09  Loss: 0.3947 (0.5098)  Acc@1: 93.7500 (89.6341)  Acc@5: 100.0000 (98.7805)  time: 0.4271  data: 0.0010  max mem: 2373\n",
            "Test: [Task 4]  [50/63]  eta: 0:00:05  Loss: 0.4213 (0.5220)  Acc@1: 93.7500 (89.9510)  Acc@5: 100.0000 (98.8971)  time: 0.4274  data: 0.0026  max mem: 2373\n",
            "Test: [Task 4]  [60/63]  eta: 0:00:01  Loss: 0.4480 (0.5399)  Acc@1: 87.5000 (89.3443)  Acc@5: 100.0000 (98.4631)  time: 0.4277  data: 0.0020  max mem: 2373\n",
            "Test: [Task 4]  [62/63]  eta: 0:00:00  Loss: 0.4336 (0.5326)  Acc@1: 87.5000 (89.6000)  Acc@5: 100.0000 (98.5000)  time: 0.4172  data: 0.0016  max mem: 2373\n",
            "Test: [Task 4] Total time: 0:00:26 (0.4282 s / it)\n",
            "* Acc@1 89.600 Acc@5 98.500 loss 0.533\n",
            "[Average accuracy till task4]\tAcc@1: 89.3500\tAcc@5: 98.8250\tLoss: 0.5648\tForgetting: 5.2333\tBackward: -5.2333\n",
            "Train: Epoch[1/5]  [  0/313]  eta: 0:04:08  Lr: 0.001875  Loss: 2.0858  Acc@1: 6.2500 (6.2500)  Acc@5: 50.0000 (50.0000)  time: 0.7927  data: 0.1821  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 10/313]  eta: 0:03:23  Lr: 0.001875  Loss: 1.7094  Acc@1: 56.2500 (53.4091)  Acc@5: 87.5000 (83.5227)  time: 0.6702  data: 0.0174  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 20/313]  eta: 0:03:14  Lr: 0.001875  Loss: 1.5861  Acc@1: 62.5000 (61.9048)  Acc@5: 87.5000 (88.0952)  time: 0.6569  data: 0.0008  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 30/313]  eta: 0:03:07  Lr: 0.001875  Loss: 1.2603  Acc@1: 75.0000 (67.5403)  Acc@5: 93.7500 (90.7258)  time: 0.6560  data: 0.0027  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 40/313]  eta: 0:03:00  Lr: 0.001875  Loss: 0.9458  Acc@1: 81.2500 (71.3415)  Acc@5: 100.0000 (92.5305)  time: 0.6571  data: 0.0026  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 50/313]  eta: 0:02:53  Lr: 0.001875  Loss: 0.7843  Acc@1: 81.2500 (72.9167)  Acc@5: 100.0000 (93.5049)  time: 0.6581  data: 0.0015  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 60/313]  eta: 0:02:46  Lr: 0.001875  Loss: 0.5322  Acc@1: 81.2500 (74.5902)  Acc@5: 100.0000 (94.1598)  time: 0.6583  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 70/313]  eta: 0:02:40  Lr: 0.001875  Loss: 0.7214  Acc@1: 81.2500 (75.6162)  Acc@5: 93.7500 (94.2782)  time: 0.6591  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 80/313]  eta: 0:02:33  Lr: 0.001875  Loss: 0.5941  Acc@1: 81.2500 (76.3889)  Acc@5: 100.0000 (94.7531)  time: 0.6596  data: 0.0031  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 90/313]  eta: 0:02:27  Lr: 0.001875  Loss: 0.5914  Acc@1: 87.5000 (77.4725)  Acc@5: 100.0000 (95.1236)  time: 0.6594  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[1/5]  [100/313]  eta: 0:02:20  Lr: 0.001875  Loss: 0.5890  Acc@1: 87.5000 (78.4653)  Acc@5: 100.0000 (95.4827)  time: 0.6590  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[1/5]  [110/313]  eta: 0:02:13  Lr: 0.001875  Loss: 0.2530  Acc@1: 87.5000 (79.0541)  Acc@5: 100.0000 (95.7770)  time: 0.6576  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[1/5]  [120/313]  eta: 0:02:07  Lr: 0.001875  Loss: 0.5065  Acc@1: 87.5000 (79.7004)  Acc@5: 100.0000 (96.0227)  time: 0.6564  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[1/5]  [130/313]  eta: 0:02:00  Lr: 0.001875  Loss: 0.7869  Acc@1: 87.5000 (80.0095)  Acc@5: 100.0000 (96.1355)  time: 0.6559  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[1/5]  [140/313]  eta: 0:01:53  Lr: 0.001875  Loss: 0.2166  Acc@1: 87.5000 (80.4521)  Acc@5: 100.0000 (96.1436)  time: 0.6555  data: 0.0033  max mem: 2373\n",
            "Train: Epoch[1/5]  [150/313]  eta: 0:01:47  Lr: 0.001875  Loss: 0.6115  Acc@1: 87.5000 (80.8775)  Acc@5: 100.0000 (96.3162)  time: 0.6549  data: 0.0033  max mem: 2373\n",
            "Train: Epoch[1/5]  [160/313]  eta: 0:01:40  Lr: 0.001875  Loss: 0.4192  Acc@1: 87.5000 (80.9394)  Acc@5: 100.0000 (96.5450)  time: 0.6548  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[1/5]  [170/313]  eta: 0:01:34  Lr: 0.001875  Loss: 0.2216  Acc@1: 87.5000 (81.3596)  Acc@5: 100.0000 (96.7471)  time: 0.6540  data: 0.0026  max mem: 2373\n",
            "Train: Epoch[1/5]  [180/313]  eta: 0:01:27  Lr: 0.001875  Loss: 0.4928  Acc@1: 87.5000 (81.4572)  Acc@5: 100.0000 (96.8232)  time: 0.6533  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[1/5]  [190/313]  eta: 0:01:20  Lr: 0.001875  Loss: 0.3748  Acc@1: 87.5000 (81.8063)  Acc@5: 100.0000 (96.9895)  time: 0.6533  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[1/5]  [200/313]  eta: 0:01:14  Lr: 0.001875  Loss: 0.0204  Acc@1: 87.5000 (81.6853)  Acc@5: 100.0000 (97.0771)  time: 0.6526  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[1/5]  [210/313]  eta: 0:01:07  Lr: 0.001875  Loss: 0.1848  Acc@1: 87.5000 (81.9905)  Acc@5: 100.0000 (97.0675)  time: 0.6522  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[1/5]  [220/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.6593  Acc@1: 87.5000 (82.1833)  Acc@5: 100.0000 (97.1154)  time: 0.6529  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[1/5]  [230/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.4398  Acc@1: 87.5000 (82.4675)  Acc@5: 100.0000 (97.1320)  time: 0.6540  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[1/5]  [240/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.2048  Acc@1: 87.5000 (82.6504)  Acc@5: 100.0000 (97.1992)  time: 0.6542  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[1/5]  [250/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.2619  Acc@1: 87.5000 (82.9183)  Acc@5: 100.0000 (97.2610)  time: 0.6543  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[1/5]  [260/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.1079  Acc@1: 87.5000 (82.9981)  Acc@5: 100.0000 (97.3180)  time: 0.6545  data: 0.0025  max mem: 2373\n",
            "Train: Epoch[1/5]  [270/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.2977  Acc@1: 87.5000 (83.0489)  Acc@5: 100.0000 (97.3478)  time: 0.6544  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[1/5]  [280/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.1528  Acc@1: 81.2500 (83.1183)  Acc@5: 100.0000 (97.3977)  time: 0.6545  data: 0.0029  max mem: 2373\n",
            "Train: Epoch[1/5]  [290/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.3357  Acc@1: 87.5000 (83.3548)  Acc@5: 100.0000 (97.4656)  time: 0.6547  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[1/5]  [300/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.2758  Acc@1: 87.5000 (83.4510)  Acc@5: 100.0000 (97.5291)  time: 0.6552  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[1/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.4089  Acc@1: 87.5000 (83.5611)  Acc@5: 100.0000 (97.5482)  time: 0.6557  data: 0.0011  max mem: 2373\n",
            "Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.6838  Acc@1: 87.5000 (83.5400)  Acc@5: 100.0000 (97.5600)  time: 0.6397  data: 0.0006  max mem: 2373\n",
            "Train: Epoch[1/5] Total time: 0:03:25 (0.6554 s / it)\n",
            "Averaged stats: Lr: 0.001875  Loss: 0.6838  Acc@1: 87.5000 (83.5400)  Acc@5: 100.0000 (97.5600)\n",
            "Train: Epoch[2/5]  [  0/313]  eta: 0:04:34  Lr: 0.001875  Loss: 0.1154  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.8754  data: 0.2624  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 10/313]  eta: 0:03:24  Lr: 0.001875  Loss: 0.3014  Acc@1: 87.5000 (88.6364)  Acc@5: 100.0000 (98.2955)  time: 0.6743  data: 0.0245  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 20/313]  eta: 0:03:14  Lr: 0.001875  Loss: 0.2188  Acc@1: 87.5000 (88.6905)  Acc@5: 100.0000 (98.8095)  time: 0.6545  data: 0.0015  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 30/313]  eta: 0:03:07  Lr: 0.001875  Loss: 0.0860  Acc@1: 87.5000 (88.7097)  Acc@5: 100.0000 (98.7903)  time: 0.6554  data: 0.0013  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 40/313]  eta: 0:03:00  Lr: 0.001875  Loss: 0.1299  Acc@1: 87.5000 (88.8720)  Acc@5: 100.0000 (98.9329)  time: 0.6557  data: 0.0025  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 50/313]  eta: 0:02:53  Lr: 0.001875  Loss: 0.2156  Acc@1: 87.5000 (89.2157)  Acc@5: 100.0000 (99.1422)  time: 0.6556  data: 0.0035  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 60/313]  eta: 0:02:46  Lr: 0.001875  Loss: 0.2519  Acc@1: 87.5000 (89.4467)  Acc@5: 100.0000 (99.1803)  time: 0.6557  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 70/313]  eta: 0:02:39  Lr: 0.001875  Loss: 0.1124  Acc@1: 87.5000 (88.7324)  Acc@5: 100.0000 (99.1197)  time: 0.6545  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 80/313]  eta: 0:02:33  Lr: 0.001875  Loss: 0.1656  Acc@1: 87.5000 (88.9660)  Acc@5: 100.0000 (99.0741)  time: 0.6548  data: 0.0014  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 90/313]  eta: 0:02:26  Lr: 0.001875  Loss: -0.1090  Acc@1: 87.5000 (88.3242)  Acc@5: 100.0000 (98.8324)  time: 0.6562  data: 0.0026  max mem: 2373\n",
            "Train: Epoch[2/5]  [100/313]  eta: 0:02:20  Lr: 0.001875  Loss: -0.0853  Acc@1: 87.5000 (88.2426)  Acc@5: 100.0000 (98.7005)  time: 0.6557  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[2/5]  [110/313]  eta: 0:02:13  Lr: 0.001875  Loss: 0.1228  Acc@1: 87.5000 (88.3446)  Acc@5: 100.0000 (98.7613)  time: 0.6555  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[2/5]  [120/313]  eta: 0:02:06  Lr: 0.001875  Loss: 0.1169  Acc@1: 87.5000 (87.7583)  Acc@5: 100.0000 (98.7087)  time: 0.6559  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[2/5]  [130/313]  eta: 0:02:00  Lr: 0.001875  Loss: 0.3226  Acc@1: 81.2500 (87.6431)  Acc@5: 100.0000 (98.5687)  time: 0.6553  data: 0.0012  max mem: 2373\n",
            "Train: Epoch[2/5]  [140/313]  eta: 0:01:53  Lr: 0.001875  Loss: 0.1996  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.6259)  time: 0.6552  data: 0.0012  max mem: 2373\n",
            "Train: Epoch[2/5]  [150/313]  eta: 0:01:47  Lr: 0.001875  Loss: 0.1271  Acc@1: 81.2500 (87.2930)  Acc@5: 100.0000 (98.5513)  time: 0.6560  data: 0.0026  max mem: 2373\n",
            "Train: Epoch[2/5]  [160/313]  eta: 0:01:40  Lr: 0.001875  Loss: 0.3266  Acc@1: 87.5000 (87.3059)  Acc@5: 100.0000 (98.6025)  time: 0.6559  data: 0.0027  max mem: 2373\n",
            "Train: Epoch[2/5]  [170/313]  eta: 0:01:33  Lr: 0.001875  Loss: 0.3855  Acc@1: 87.5000 (87.1711)  Acc@5: 100.0000 (98.6111)  time: 0.6562  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[2/5]  [180/313]  eta: 0:01:27  Lr: 0.001875  Loss: 0.2234  Acc@1: 93.7500 (87.3619)  Acc@5: 100.0000 (98.6188)  time: 0.6566  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[2/5]  [190/313]  eta: 0:01:20  Lr: 0.001875  Loss: 0.0416  Acc@1: 93.7500 (87.4673)  Acc@5: 100.0000 (98.5929)  time: 0.6564  data: 0.0026  max mem: 2373\n",
            "Train: Epoch[2/5]  [200/313]  eta: 0:01:14  Lr: 0.001875  Loss: 0.3010  Acc@1: 87.5000 (87.4067)  Acc@5: 100.0000 (98.6007)  time: 0.6562  data: 0.0025  max mem: 2373\n",
            "Train: Epoch[2/5]  [210/313]  eta: 0:01:07  Lr: 0.001875  Loss: 0.0473  Acc@1: 87.5000 (87.3519)  Acc@5: 100.0000 (98.6671)  time: 0.6565  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[2/5]  [220/313]  eta: 0:01:01  Lr: 0.001875  Loss: -0.1863  Acc@1: 87.5000 (87.5283)  Acc@5: 100.0000 (98.7274)  time: 0.6566  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[2/5]  [230/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.6477  Acc@1: 87.5000 (87.4459)  Acc@5: 100.0000 (98.6742)  time: 0.6566  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[2/5]  [240/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.1474  Acc@1: 87.5000 (87.4741)  Acc@5: 100.0000 (98.6515)  time: 0.6565  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[2/5]  [250/313]  eta: 0:00:41  Lr: 0.001875  Loss: -0.1639  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.6305)  time: 0.6563  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[2/5]  [260/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.0521  Acc@1: 87.5000 (87.6676)  Acc@5: 100.0000 (98.6351)  time: 0.6563  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[2/5]  [270/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.0689  Acc@1: 87.5000 (87.6614)  Acc@5: 100.0000 (98.6393)  time: 0.6565  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[2/5]  [280/313]  eta: 0:00:21  Lr: 0.001875  Loss: -0.0444  Acc@1: 87.5000 (87.7669)  Acc@5: 100.0000 (98.6877)  time: 0.6569  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[2/5]  [290/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.1839  Acc@1: 87.5000 (87.8436)  Acc@5: 100.0000 (98.6469)  time: 0.6570  data: 0.0010  max mem: 2373\n",
            "Train: Epoch[2/5]  [300/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.1564  Acc@1: 87.5000 (88.0191)  Acc@5: 100.0000 (98.6711)  time: 0.6566  data: 0.0011  max mem: 2373\n",
            "Train: Epoch[2/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.0404  Acc@1: 93.7500 (87.9019)  Acc@5: 100.0000 (98.7138)  time: 0.6561  data: 0.0004  max mem: 2373\n",
            "Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.2550  Acc@1: 87.5000 (87.9000)  Acc@5: 100.0000 (98.7200)  time: 0.6400  data: 0.0004  max mem: 2373\n",
            "Train: Epoch[2/5] Total time: 0:03:25 (0.6559 s / it)\n",
            "Averaged stats: Lr: 0.001875  Loss: 0.2550  Acc@1: 87.5000 (87.9000)  Acc@5: 100.0000 (98.7200)\n",
            "Train: Epoch[3/5]  [  0/313]  eta: 0:04:19  Lr: 0.001875  Loss: 0.3374  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.8295  data: 0.2137  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 10/313]  eta: 0:03:24  Lr: 0.001875  Loss: -0.0552  Acc@1: 87.5000 (90.3409)  Acc@5: 100.0000 (98.8636)  time: 0.6736  data: 0.0199  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 20/313]  eta: 0:03:14  Lr: 0.001875  Loss: -0.1304  Acc@1: 87.5000 (90.4762)  Acc@5: 100.0000 (98.2143)  time: 0.6570  data: 0.0014  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 30/313]  eta: 0:03:07  Lr: 0.001875  Loss: 0.2111  Acc@1: 87.5000 (89.1129)  Acc@5: 100.0000 (98.1855)  time: 0.6564  data: 0.0014  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 40/313]  eta: 0:03:00  Lr: 0.001875  Loss: 0.1335  Acc@1: 87.5000 (89.0244)  Acc@5: 100.0000 (98.3232)  time: 0.6566  data: 0.0026  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 50/313]  eta: 0:02:53  Lr: 0.001875  Loss: 0.0119  Acc@1: 87.5000 (88.1127)  Acc@5: 100.0000 (98.4069)  time: 0.6563  data: 0.0027  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 60/313]  eta: 0:02:46  Lr: 0.001875  Loss: 0.1879  Acc@1: 87.5000 (88.2172)  Acc@5: 100.0000 (98.1557)  time: 0.6563  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 70/313]  eta: 0:02:40  Lr: 0.001875  Loss: 0.0514  Acc@1: 87.5000 (88.2923)  Acc@5: 100.0000 (98.2394)  time: 0.6568  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 80/313]  eta: 0:02:33  Lr: 0.001875  Loss: 0.4285  Acc@1: 87.5000 (88.3488)  Acc@5: 100.0000 (98.3025)  time: 0.6573  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 90/313]  eta: 0:02:26  Lr: 0.001875  Loss: -0.1302  Acc@1: 93.7500 (88.6676)  Acc@5: 100.0000 (98.4203)  time: 0.6568  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[3/5]  [100/313]  eta: 0:02:20  Lr: 0.001875  Loss: -0.0784  Acc@1: 93.7500 (88.8614)  Acc@5: 100.0000 (98.5149)  time: 0.6563  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[3/5]  [110/313]  eta: 0:02:13  Lr: 0.001875  Loss: 0.5772  Acc@1: 87.5000 (88.2320)  Acc@5: 100.0000 (98.4797)  time: 0.6570  data: 0.0025  max mem: 2373\n",
            "Train: Epoch[3/5]  [120/313]  eta: 0:02:07  Lr: 0.001875  Loss: 0.1107  Acc@1: 87.5000 (88.1715)  Acc@5: 100.0000 (98.6054)  time: 0.6567  data: 0.0015  max mem: 2373\n",
            "Train: Epoch[3/5]  [130/313]  eta: 0:02:00  Lr: 0.001875  Loss: 0.0651  Acc@1: 87.5000 (88.1202)  Acc@5: 100.0000 (98.6641)  time: 0.6563  data: 0.0015  max mem: 2373\n",
            "Train: Epoch[3/5]  [140/313]  eta: 0:01:53  Lr: 0.001875  Loss: 0.1158  Acc@1: 87.5000 (87.9876)  Acc@5: 100.0000 (98.7145)  time: 0.6563  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[3/5]  [150/313]  eta: 0:01:47  Lr: 0.001875  Loss: 0.5015  Acc@1: 87.5000 (87.9553)  Acc@5: 100.0000 (98.5513)  time: 0.6568  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[3/5]  [160/313]  eta: 0:01:40  Lr: 0.001875  Loss: 0.0692  Acc@1: 87.5000 (88.1599)  Acc@5: 100.0000 (98.6025)  time: 0.6570  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[3/5]  [170/313]  eta: 0:01:34  Lr: 0.001875  Loss: 0.7054  Acc@1: 87.5000 (88.2675)  Acc@5: 100.0000 (98.5746)  time: 0.6565  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[3/5]  [180/313]  eta: 0:01:27  Lr: 0.001875  Loss: 0.2316  Acc@1: 87.5000 (88.1215)  Acc@5: 100.0000 (98.6533)  time: 0.6568  data: 0.0041  max mem: 2373\n",
            "Train: Epoch[3/5]  [190/313]  eta: 0:01:20  Lr: 0.001875  Loss: 0.0048  Acc@1: 87.5000 (87.9581)  Acc@5: 100.0000 (98.6911)  time: 0.6563  data: 0.0042  max mem: 2373\n",
            "Train: Epoch[3/5]  [200/313]  eta: 0:01:14  Lr: 0.001875  Loss: 0.1751  Acc@1: 81.2500 (87.9353)  Acc@5: 100.0000 (98.6629)  time: 0.6565  data: 0.0014  max mem: 2373\n",
            "Train: Epoch[3/5]  [210/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.1486  Acc@1: 87.5000 (87.8851)  Acc@5: 100.0000 (98.6967)  time: 0.6571  data: 0.0012  max mem: 2373\n",
            "Train: Epoch[3/5]  [220/313]  eta: 0:01:01  Lr: 0.001875  Loss: -0.0319  Acc@1: 87.5000 (88.0090)  Acc@5: 100.0000 (98.7557)  time: 0.6573  data: 0.0011  max mem: 2373\n",
            "Train: Epoch[3/5]  [230/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.0505  Acc@1: 87.5000 (88.0682)  Acc@5: 100.0000 (98.8095)  time: 0.6571  data: 0.0011  max mem: 2373\n",
            "Train: Epoch[3/5]  [240/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.5819  Acc@1: 87.5000 (88.0187)  Acc@5: 100.0000 (98.7811)  time: 0.6569  data: 0.0014  max mem: 2373\n",
            "Train: Epoch[3/5]  [250/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.2183  Acc@1: 93.7500 (88.0727)  Acc@5: 100.0000 (98.8048)  time: 0.6573  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[3/5]  [260/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.0078  Acc@1: 87.5000 (87.9550)  Acc@5: 100.0000 (98.8266)  time: 0.6572  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[3/5]  [270/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.1803  Acc@1: 87.5000 (87.8459)  Acc@5: 100.0000 (98.8469)  time: 0.6575  data: 0.0014  max mem: 2373\n",
            "Train: Epoch[3/5]  [280/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.0637  Acc@1: 87.5000 (87.7891)  Acc@5: 100.0000 (98.7767)  time: 0.6572  data: 0.0014  max mem: 2373\n",
            "Train: Epoch[3/5]  [290/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.0362  Acc@1: 87.5000 (87.8007)  Acc@5: 100.0000 (98.7758)  time: 0.6568  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[3/5]  [300/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.0045  Acc@1: 87.5000 (88.0191)  Acc@5: 100.0000 (98.8164)  time: 0.6564  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[3/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.2138  Acc@1: 87.5000 (87.9220)  Acc@5: 100.0000 (98.8143)  time: 0.6562  data: 0.0008  max mem: 2373\n",
            "Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1603  Acc@1: 87.5000 (87.8800)  Acc@5: 100.0000 (98.8000)  time: 0.6402  data: 0.0008  max mem: 2373\n",
            "Train: Epoch[3/5] Total time: 0:03:25 (0.6565 s / it)\n",
            "Averaged stats: Lr: 0.001875  Loss: -0.1603  Acc@1: 87.5000 (87.8800)  Acc@5: 100.0000 (98.8000)\n",
            "Train: Epoch[4/5]  [  0/313]  eta: 0:03:56  Lr: 0.001875  Loss: 0.1597  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.7556  data: 0.1397  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 10/313]  eta: 0:03:22  Lr: 0.001875  Loss: 0.0772  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (99.4318)  time: 0.6684  data: 0.0131  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 20/313]  eta: 0:03:14  Lr: 0.001875  Loss: 0.0925  Acc@1: 87.5000 (89.2857)  Acc@5: 100.0000 (99.4048)  time: 0.6586  data: 0.0012  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 30/313]  eta: 0:03:07  Lr: 0.001875  Loss: 0.1197  Acc@1: 93.7500 (89.5161)  Acc@5: 100.0000 (99.1935)  time: 0.6568  data: 0.0012  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 40/313]  eta: 0:03:00  Lr: 0.001875  Loss: 0.0092  Acc@1: 87.5000 (88.8720)  Acc@5: 100.0000 (98.7805)  time: 0.6569  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 50/313]  eta: 0:02:53  Lr: 0.001875  Loss: 0.2013  Acc@1: 87.5000 (88.3578)  Acc@5: 100.0000 (98.8971)  time: 0.6569  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 60/313]  eta: 0:02:46  Lr: 0.001875  Loss: 0.3421  Acc@1: 87.5000 (88.5246)  Acc@5: 100.0000 (99.0779)  time: 0.6562  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 70/313]  eta: 0:02:40  Lr: 0.001875  Loss: -0.1554  Acc@1: 87.5000 (88.6444)  Acc@5: 100.0000 (98.9437)  time: 0.6562  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 80/313]  eta: 0:02:33  Lr: 0.001875  Loss: 0.4811  Acc@1: 93.7500 (88.8889)  Acc@5: 100.0000 (98.9198)  time: 0.6566  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 90/313]  eta: 0:02:26  Lr: 0.001875  Loss: -0.0764  Acc@1: 93.7500 (88.9423)  Acc@5: 100.0000 (98.9011)  time: 0.6566  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[4/5]  [100/313]  eta: 0:02:20  Lr: 0.001875  Loss: 0.0610  Acc@1: 87.5000 (89.2946)  Acc@5: 100.0000 (98.9480)  time: 0.6568  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[4/5]  [110/313]  eta: 0:02:13  Lr: 0.001875  Loss: -0.1454  Acc@1: 87.5000 (89.3018)  Acc@5: 100.0000 (98.9302)  time: 0.6572  data: 0.0025  max mem: 2373\n",
            "Train: Epoch[4/5]  [120/313]  eta: 0:02:06  Lr: 0.001875  Loss: -0.0100  Acc@1: 87.5000 (89.4628)  Acc@5: 100.0000 (98.8120)  time: 0.6570  data: 0.0029  max mem: 2373\n",
            "Train: Epoch[4/5]  [130/313]  eta: 0:02:00  Lr: 0.001875  Loss: 0.1816  Acc@1: 93.7500 (89.4561)  Acc@5: 100.0000 (98.7118)  time: 0.6566  data: 0.0026  max mem: 2373\n",
            "Train: Epoch[4/5]  [140/313]  eta: 0:01:53  Lr: 0.001875  Loss: 0.3245  Acc@1: 87.5000 (89.3174)  Acc@5: 100.0000 (98.7145)  time: 0.6564  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[4/5]  [150/313]  eta: 0:01:47  Lr: 0.001875  Loss: 0.2770  Acc@1: 87.5000 (89.3212)  Acc@5: 100.0000 (98.7583)  time: 0.6563  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[4/5]  [160/313]  eta: 0:01:40  Lr: 0.001875  Loss: 0.1635  Acc@1: 93.7500 (89.4410)  Acc@5: 100.0000 (98.7189)  time: 0.6564  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[4/5]  [170/313]  eta: 0:01:34  Lr: 0.001875  Loss: 0.0092  Acc@1: 93.7500 (89.2909)  Acc@5: 100.0000 (98.7208)  time: 0.6567  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[4/5]  [180/313]  eta: 0:01:27  Lr: 0.001875  Loss: 0.1484  Acc@1: 87.5000 (88.9503)  Acc@5: 100.0000 (98.6878)  time: 0.6569  data: 0.0032  max mem: 2373\n",
            "Train: Epoch[4/5]  [190/313]  eta: 0:01:20  Lr: 0.001875  Loss: -0.0066  Acc@1: 87.5000 (88.9398)  Acc@5: 100.0000 (98.6911)  time: 0.6570  data: 0.0027  max mem: 2373\n",
            "Train: Epoch[4/5]  [200/313]  eta: 0:01:14  Lr: 0.001875  Loss: 0.2131  Acc@1: 87.5000 (88.8993)  Acc@5: 100.0000 (98.6629)  time: 0.6571  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[4/5]  [210/313]  eta: 0:01:07  Lr: 0.001875  Loss: 0.0226  Acc@1: 87.5000 (88.9218)  Acc@5: 100.0000 (98.6374)  time: 0.6572  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[4/5]  [220/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.2064  Acc@1: 87.5000 (88.9423)  Acc@5: 100.0000 (98.6425)  time: 0.6573  data: 0.0010  max mem: 2373\n",
            "Train: Epoch[4/5]  [230/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.0791  Acc@1: 93.7500 (89.0693)  Acc@5: 100.0000 (98.6742)  time: 0.6575  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[4/5]  [240/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.0373  Acc@1: 93.7500 (89.0820)  Acc@5: 100.0000 (98.7033)  time: 0.6571  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[4/5]  [250/313]  eta: 0:00:41  Lr: 0.001875  Loss: -0.1487  Acc@1: 93.7500 (89.1932)  Acc@5: 100.0000 (98.6554)  time: 0.6564  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[4/5]  [260/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.2176  Acc@1: 87.5000 (89.0805)  Acc@5: 100.0000 (98.6830)  time: 0.6569  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[4/5]  [270/313]  eta: 0:00:28  Lr: 0.001875  Loss: -0.1404  Acc@1: 87.5000 (89.2066)  Acc@5: 100.0000 (98.6854)  time: 0.6581  data: 0.0027  max mem: 2373\n",
            "Train: Epoch[4/5]  [280/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.1151  Acc@1: 93.7500 (89.2794)  Acc@5: 100.0000 (98.7100)  time: 0.6574  data: 0.0025  max mem: 2373\n",
            "Train: Epoch[4/5]  [290/313]  eta: 0:00:15  Lr: 0.001875  Loss: -0.0946  Acc@1: 93.7500 (89.4330)  Acc@5: 100.0000 (98.6899)  time: 0.6567  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[4/5]  [300/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.0909  Acc@1: 93.7500 (89.3272)  Acc@5: 100.0000 (98.6503)  time: 0.6574  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[4/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.1457  Acc@1: 87.5000 (89.3087)  Acc@5: 100.0000 (98.6736)  time: 0.6581  data: 0.0028  max mem: 2373\n",
            "Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.3881  Acc@1: 87.5000 (89.2600)  Acc@5: 100.0000 (98.6800)  time: 0.6419  data: 0.0028  max mem: 2373\n",
            "Train: Epoch[4/5] Total time: 0:03:25 (0.6566 s / it)\n",
            "Averaged stats: Lr: 0.001875  Loss: 0.3881  Acc@1: 87.5000 (89.2600)  Acc@5: 100.0000 (98.6800)\n",
            "Train: Epoch[5/5]  [  0/313]  eta: 0:03:57  Lr: 0.001875  Loss: -0.0592  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.7583  data: 0.1416  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 10/313]  eta: 0:03:22  Lr: 0.001875  Loss: -0.1223  Acc@1: 93.7500 (93.1818)  Acc@5: 100.0000 (99.4318)  time: 0.6669  data: 0.0162  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 20/313]  eta: 0:03:14  Lr: 0.001875  Loss: -0.0598  Acc@1: 93.7500 (93.1548)  Acc@5: 100.0000 (99.4048)  time: 0.6581  data: 0.0029  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 30/313]  eta: 0:03:07  Lr: 0.001875  Loss: 0.2058  Acc@1: 93.7500 (91.9355)  Acc@5: 100.0000 (98.7903)  time: 0.6577  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 40/313]  eta: 0:03:00  Lr: 0.001875  Loss: -0.1494  Acc@1: 93.7500 (91.7683)  Acc@5: 100.0000 (98.7805)  time: 0.6573  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 50/313]  eta: 0:02:53  Lr: 0.001875  Loss: 0.0656  Acc@1: 87.5000 (91.6667)  Acc@5: 100.0000 (98.8971)  time: 0.6572  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 60/313]  eta: 0:02:46  Lr: 0.001875  Loss: -0.0251  Acc@1: 93.7500 (91.4959)  Acc@5: 100.0000 (98.9754)  time: 0.6566  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 70/313]  eta: 0:02:40  Lr: 0.001875  Loss: -0.1269  Acc@1: 93.7500 (91.5493)  Acc@5: 100.0000 (98.9437)  time: 0.6570  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 80/313]  eta: 0:02:33  Lr: 0.001875  Loss: -0.0238  Acc@1: 93.7500 (91.5895)  Acc@5: 100.0000 (99.0741)  time: 0.6576  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 90/313]  eta: 0:02:26  Lr: 0.001875  Loss: -0.1030  Acc@1: 93.7500 (91.3462)  Acc@5: 100.0000 (98.9698)  time: 0.6571  data: 0.0013  max mem: 2373\n",
            "Train: Epoch[5/5]  [100/313]  eta: 0:02:20  Lr: 0.001875  Loss: 0.1282  Acc@1: 87.5000 (90.7797)  Acc@5: 100.0000 (98.9480)  time: 0.6573  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[5/5]  [110/313]  eta: 0:02:13  Lr: 0.001875  Loss: 0.0905  Acc@1: 87.5000 (90.8221)  Acc@5: 100.0000 (98.8176)  time: 0.6569  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[5/5]  [120/313]  eta: 0:02:07  Lr: 0.001875  Loss: 0.0280  Acc@1: 93.7500 (90.6508)  Acc@5: 100.0000 (98.9153)  time: 0.6569  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[5/5]  [130/313]  eta: 0:02:00  Lr: 0.001875  Loss: 0.1512  Acc@1: 93.7500 (90.5534)  Acc@5: 100.0000 (98.9027)  time: 0.6571  data: 0.0027  max mem: 2373\n",
            "Train: Epoch[5/5]  [140/313]  eta: 0:01:53  Lr: 0.001875  Loss: 0.1565  Acc@1: 87.5000 (90.3369)  Acc@5: 100.0000 (98.8032)  time: 0.6571  data: 0.0011  max mem: 2373\n",
            "Train: Epoch[5/5]  [150/313]  eta: 0:01:47  Lr: 0.001875  Loss: 0.0151  Acc@1: 87.5000 (90.3974)  Acc@5: 100.0000 (98.7997)  time: 0.6577  data: 0.0008  max mem: 2373\n",
            "Train: Epoch[5/5]  [160/313]  eta: 0:01:40  Lr: 0.001875  Loss: 0.0974  Acc@1: 93.7500 (90.3727)  Acc@5: 100.0000 (98.7578)  time: 0.6574  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[5/5]  [170/313]  eta: 0:01:34  Lr: 0.001875  Loss: 0.0406  Acc@1: 87.5000 (90.2778)  Acc@5: 100.0000 (98.7939)  time: 0.6574  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[5/5]  [180/313]  eta: 0:01:27  Lr: 0.001875  Loss: -0.1034  Acc@1: 87.5000 (90.0898)  Acc@5: 100.0000 (98.7914)  time: 0.6572  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[5/5]  [190/313]  eta: 0:01:20  Lr: 0.001875  Loss: 0.0318  Acc@1: 93.7500 (90.2160)  Acc@5: 100.0000 (98.8547)  time: 0.6572  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[5/5]  [200/313]  eta: 0:01:14  Lr: 0.001875  Loss: 0.1166  Acc@1: 93.7500 (90.1741)  Acc@5: 100.0000 (98.8495)  time: 0.6572  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[5/5]  [210/313]  eta: 0:01:07  Lr: 0.001875  Loss: 0.2081  Acc@1: 87.5000 (90.0474)  Acc@5: 100.0000 (98.9040)  time: 0.6573  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[5/5]  [220/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.0893  Acc@1: 87.5000 (90.1301)  Acc@5: 100.0000 (98.8688)  time: 0.6569  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[5/5]  [230/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.5058  Acc@1: 87.5000 (89.9892)  Acc@5: 100.0000 (98.9177)  time: 0.6572  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[5/5]  [240/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.4810  Acc@1: 87.5000 (90.0415)  Acc@5: 100.0000 (98.9367)  time: 0.6575  data: 0.0014  max mem: 2373\n",
            "Train: Epoch[5/5]  [250/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.2310  Acc@1: 87.5000 (89.9651)  Acc@5: 100.0000 (98.8795)  time: 0.6571  data: 0.0014  max mem: 2373\n",
            "Train: Epoch[5/5]  [260/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.5893  Acc@1: 87.5000 (89.8228)  Acc@5: 100.0000 (98.9224)  time: 0.6571  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[5/5]  [270/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.0761  Acc@1: 87.5000 (89.8524)  Acc@5: 100.0000 (98.8930)  time: 0.6570  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[5/5]  [280/313]  eta: 0:00:21  Lr: 0.001875  Loss: -0.1541  Acc@1: 87.5000 (89.8354)  Acc@5: 100.0000 (98.9101)  time: 0.6572  data: 0.0026  max mem: 2373\n",
            "Train: Epoch[5/5]  [290/313]  eta: 0:00:15  Lr: 0.001875  Loss: -0.0185  Acc@1: 87.5000 (89.6907)  Acc@5: 100.0000 (98.9046)  time: 0.6574  data: 0.0027  max mem: 2373\n",
            "Train: Epoch[5/5]  [300/313]  eta: 0:00:08  Lr: 0.001875  Loss: -0.0757  Acc@1: 87.5000 (89.7010)  Acc@5: 100.0000 (98.9203)  time: 0.6574  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[5/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.2123  Acc@1: 87.5000 (89.6101)  Acc@5: 100.0000 (98.9550)  time: 0.6568  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1616  Acc@1: 93.7500 (89.6400)  Acc@5: 100.0000 (98.9600)  time: 0.6406  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[5/5] Total time: 0:03:25 (0.6567 s / it)\n",
            "Averaged stats: Lr: 0.001875  Loss: -0.1616  Acc@1: 93.7500 (89.6400)  Acc@5: 100.0000 (98.9600)\n",
            "Test: [Task 1]  [ 0/63]  eta: 0:00:39  Loss: 0.7503 (0.7503)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.6228  data: 0.2308  max mem: 2373\n",
            "Test: [Task 1]  [10/63]  eta: 0:00:23  Loss: 0.5877 (0.5818)  Acc@1: 87.5000 (85.7955)  Acc@5: 100.0000 (99.4318)  time: 0.4452  data: 0.0237  max mem: 2373\n",
            "Test: [Task 1]  [20/63]  eta: 0:00:18  Loss: 0.5877 (0.6316)  Acc@1: 87.5000 (85.1190)  Acc@5: 100.0000 (98.8095)  time: 0.4274  data: 0.0023  max mem: 2373\n",
            "Test: [Task 1]  [30/63]  eta: 0:00:14  Loss: 0.6013 (0.6214)  Acc@1: 87.5000 (85.4839)  Acc@5: 100.0000 (98.9919)  time: 0.4271  data: 0.0010  max mem: 2373\n",
            "Test: [Task 1]  [40/63]  eta: 0:00:09  Loss: 0.5650 (0.6138)  Acc@1: 81.2500 (85.9756)  Acc@5: 100.0000 (98.9329)  time: 0.4257  data: 0.0011  max mem: 2373\n",
            "Test: [Task 1]  [50/63]  eta: 0:00:05  Loss: 0.4937 (0.5861)  Acc@1: 93.7500 (86.7647)  Acc@5: 100.0000 (99.0196)  time: 0.4257  data: 0.0023  max mem: 2373\n",
            "Test: [Task 1]  [60/63]  eta: 0:00:01  Loss: 0.4897 (0.5744)  Acc@1: 93.7500 (87.0902)  Acc@5: 100.0000 (98.9754)  time: 0.4265  data: 0.0017  max mem: 2373\n",
            "Test: [Task 1]  [62/63]  eta: 0:00:00  Loss: 0.4628 (0.5722)  Acc@1: 93.7500 (87.2000)  Acc@5: 100.0000 (99.0000)  time: 0.4156  data: 0.0011  max mem: 2373\n",
            "Test: [Task 1] Total time: 0:00:26 (0.4271 s / it)\n",
            "* Acc@1 87.200 Acc@5 99.000 loss 0.572\n",
            "Test: [Task 2]  [ 0/63]  eta: 0:00:34  Loss: 0.7777 (0.7777)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.5451  data: 0.1452  max mem: 2373\n",
            "Test: [Task 2]  [10/63]  eta: 0:00:23  Loss: 0.6821 (0.7217)  Acc@1: 87.5000 (88.0682)  Acc@5: 100.0000 (97.1591)  time: 0.4375  data: 0.0149  max mem: 2373\n",
            "Test: [Task 2]  [20/63]  eta: 0:00:18  Loss: 0.7135 (0.7628)  Acc@1: 87.5000 (85.7143)  Acc@5: 100.0000 (97.9167)  time: 0.4270  data: 0.0019  max mem: 2373\n",
            "Test: [Task 2]  [30/63]  eta: 0:00:14  Loss: 0.7374 (0.7516)  Acc@1: 87.5000 (86.4919)  Acc@5: 100.0000 (96.9758)  time: 0.4267  data: 0.0013  max mem: 2373\n",
            "Test: [Task 2]  [40/63]  eta: 0:00:09  Loss: 0.7374 (0.7364)  Acc@1: 87.5000 (86.8902)  Acc@5: 100.0000 (97.2561)  time: 0.4264  data: 0.0013  max mem: 2373\n",
            "Test: [Task 2]  [50/63]  eta: 0:00:05  Loss: 0.6470 (0.7321)  Acc@1: 87.5000 (86.2745)  Acc@5: 100.0000 (97.4265)  time: 0.4268  data: 0.0022  max mem: 2373\n",
            "Test: [Task 2]  [60/63]  eta: 0:00:01  Loss: 0.5891 (0.7054)  Acc@1: 87.5000 (86.7828)  Acc@5: 100.0000 (97.7459)  time: 0.4267  data: 0.0015  max mem: 2373\n",
            "Test: [Task 2]  [62/63]  eta: 0:00:00  Loss: 0.5881 (0.6963)  Acc@1: 87.5000 (86.9000)  Acc@5: 100.0000 (97.8000)  time: 0.4159  data: 0.0011  max mem: 2373\n",
            "Test: [Task 2] Total time: 0:00:26 (0.4261 s / it)\n",
            "* Acc@1 86.900 Acc@5 97.800 loss 0.696\n",
            "Test: [Task 3]  [ 0/63]  eta: 0:00:38  Loss: 0.4146 (0.4146)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.6078  data: 0.2160  max mem: 2373\n",
            "Test: [Task 3]  [10/63]  eta: 0:00:23  Loss: 0.5895 (0.5824)  Acc@1: 81.2500 (84.0909)  Acc@5: 100.0000 (98.8636)  time: 0.4428  data: 0.0201  max mem: 2373\n",
            "Test: [Task 3]  [20/63]  eta: 0:00:18  Loss: 0.5940 (0.6018)  Acc@1: 81.2500 (83.9286)  Acc@5: 100.0000 (97.9167)  time: 0.4265  data: 0.0008  max mem: 2373\n",
            "Test: [Task 3]  [30/63]  eta: 0:00:14  Loss: 0.5752 (0.5908)  Acc@1: 87.5000 (84.4758)  Acc@5: 100.0000 (98.3871)  time: 0.4270  data: 0.0009  max mem: 2373\n",
            "Test: [Task 3]  [40/63]  eta: 0:00:09  Loss: 0.4465 (0.5813)  Acc@1: 87.5000 (85.6707)  Acc@5: 100.0000 (98.6280)  time: 0.4262  data: 0.0010  max mem: 2373\n",
            "Test: [Task 3]  [50/63]  eta: 0:00:05  Loss: 0.5805 (0.5876)  Acc@1: 87.5000 (86.0294)  Acc@5: 100.0000 (98.2843)  time: 0.4252  data: 0.0025  max mem: 2373\n",
            "Test: [Task 3]  [60/63]  eta: 0:00:01  Loss: 0.5805 (0.5934)  Acc@1: 87.5000 (86.0656)  Acc@5: 100.0000 (98.3607)  time: 0.4257  data: 0.0021  max mem: 2373\n",
            "Test: [Task 3]  [62/63]  eta: 0:00:00  Loss: 0.5815 (0.5924)  Acc@1: 87.5000 (86.0000)  Acc@5: 100.0000 (98.4000)  time: 0.4152  data: 0.0017  max mem: 2373\n",
            "Test: [Task 3] Total time: 0:00:26 (0.4264 s / it)\n",
            "* Acc@1 86.000 Acc@5 98.400 loss 0.592\n",
            "Test: [Task 4]  [ 0/63]  eta: 0:00:33  Loss: 0.8205 (0.8205)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.5296  data: 0.1382  max mem: 2373\n",
            "Test: [Task 4]  [10/63]  eta: 0:00:23  Loss: 0.5514 (0.5958)  Acc@1: 87.5000 (86.3636)  Acc@5: 100.0000 (98.8636)  time: 0.4369  data: 0.0146  max mem: 2373\n",
            "Test: [Task 4]  [20/63]  eta: 0:00:18  Loss: 0.5422 (0.6171)  Acc@1: 81.2500 (83.9286)  Acc@5: 100.0000 (97.6190)  time: 0.4282  data: 0.0022  max mem: 2373\n",
            "Test: [Task 4]  [30/63]  eta: 0:00:14  Loss: 0.5584 (0.6035)  Acc@1: 87.5000 (85.6855)  Acc@5: 93.7500 (97.1774)  time: 0.4276  data: 0.0014  max mem: 2373\n",
            "Test: [Task 4]  [40/63]  eta: 0:00:09  Loss: 0.4335 (0.5564)  Acc@1: 93.7500 (87.5000)  Acc@5: 100.0000 (97.7134)  time: 0.4260  data: 0.0034  max mem: 2373\n",
            "Test: [Task 4]  [50/63]  eta: 0:00:05  Loss: 0.4229 (0.5715)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (97.6716)  time: 0.4252  data: 0.0059  max mem: 2373\n",
            "Test: [Task 4]  [60/63]  eta: 0:00:01  Loss: 0.5442 (0.5883)  Acc@1: 87.5000 (87.0902)  Acc@5: 100.0000 (97.4385)  time: 0.4261  data: 0.0030  max mem: 2373\n",
            "Test: [Task 4]  [62/63]  eta: 0:00:00  Loss: 0.4782 (0.5853)  Acc@1: 87.5000 (87.3000)  Acc@5: 100.0000 (97.5000)  time: 0.4157  data: 0.0020  max mem: 2373\n",
            "Test: [Task 4] Total time: 0:00:26 (0.4259 s / it)\n",
            "* Acc@1 87.300 Acc@5 97.500 loss 0.585\n",
            "Test: [Task 5]  [ 0/63]  eta: 0:00:33  Loss: 0.2273 (0.2273)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.5377  data: 0.1394  max mem: 2373\n",
            "Test: [Task 5]  [10/63]  eta: 0:00:23  Loss: 0.4662 (0.5839)  Acc@1: 87.5000 (89.2045)  Acc@5: 100.0000 (97.7273)  time: 0.4379  data: 0.0140  max mem: 2373\n",
            "Test: [Task 5]  [20/63]  eta: 0:00:18  Loss: 0.4662 (0.5364)  Acc@1: 93.7500 (90.4762)  Acc@5: 100.0000 (97.6190)  time: 0.4278  data: 0.0019  max mem: 2373\n",
            "Test: [Task 5]  [30/63]  eta: 0:00:14  Loss: 0.4013 (0.5155)  Acc@1: 93.7500 (90.3226)  Acc@5: 100.0000 (97.9839)  time: 0.4269  data: 0.0015  max mem: 2373\n",
            "Test: [Task 5]  [40/63]  eta: 0:00:09  Loss: 0.3784 (0.4897)  Acc@1: 93.7500 (90.5488)  Acc@5: 100.0000 (98.0183)  time: 0.4264  data: 0.0006  max mem: 2373\n",
            "Test: [Task 5]  [50/63]  eta: 0:00:05  Loss: 0.4565 (0.4885)  Acc@1: 93.7500 (91.0539)  Acc@5: 100.0000 (98.1618)  time: 0.4261  data: 0.0031  max mem: 2373\n",
            "Test: [Task 5]  [60/63]  eta: 0:00:01  Loss: 0.4768 (0.4925)  Acc@1: 93.7500 (90.7787)  Acc@5: 100.0000 (98.1557)  time: 0.4263  data: 0.0031  max mem: 2373\n",
            "Test: [Task 5]  [62/63]  eta: 0:00:00  Loss: 0.4816 (0.5123)  Acc@1: 87.5000 (90.4000)  Acc@5: 100.0000 (98.0000)  time: 0.4160  data: 0.0027  max mem: 2373\n",
            "Test: [Task 5] Total time: 0:00:26 (0.4260 s / it)\n",
            "* Acc@1 90.400 Acc@5 98.000 loss 0.512\n",
            "[Average accuracy till task5]\tAcc@1: 87.5600\tAcc@5: 98.1400\tLoss: 0.5917\tForgetting: 6.4250\tBackward: -6.4250\n",
            "Train: Epoch[1/5]  [  0/313]  eta: 0:04:04  Lr: 0.001875  Loss: 2.1432  Acc@1: 0.0000 (0.0000)  Acc@5: 43.7500 (43.7500)  time: 0.7803  data: 0.1646  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 10/313]  eta: 0:03:22  Lr: 0.001875  Loss: 1.7074  Acc@1: 56.2500 (48.2955)  Acc@5: 93.7500 (81.2500)  time: 0.6672  data: 0.0169  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 20/313]  eta: 0:03:13  Lr: 0.001875  Loss: 1.3547  Acc@1: 68.7500 (63.6905)  Acc@5: 93.7500 (88.3929)  time: 0.6558  data: 0.0013  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 30/313]  eta: 0:03:06  Lr: 0.001875  Loss: 0.9856  Acc@1: 81.2500 (68.7500)  Acc@5: 100.0000 (90.7258)  time: 0.6558  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 40/313]  eta: 0:02:59  Lr: 0.001875  Loss: 0.9757  Acc@1: 81.2500 (72.7134)  Acc@5: 100.0000 (92.6829)  time: 0.6562  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 50/313]  eta: 0:02:53  Lr: 0.001875  Loss: 0.6873  Acc@1: 81.2500 (75.3676)  Acc@5: 100.0000 (93.8725)  time: 0.6562  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 60/313]  eta: 0:02:46  Lr: 0.001875  Loss: 0.4563  Acc@1: 87.5000 (77.0492)  Acc@5: 100.0000 (94.6721)  time: 0.6565  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 70/313]  eta: 0:02:39  Lr: 0.001875  Loss: 0.3805  Acc@1: 87.5000 (78.2570)  Acc@5: 100.0000 (95.2465)  time: 0.6566  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 80/313]  eta: 0:02:33  Lr: 0.001875  Loss: 0.6345  Acc@1: 87.5000 (79.2438)  Acc@5: 100.0000 (95.6019)  time: 0.6562  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 90/313]  eta: 0:02:26  Lr: 0.001875  Loss: 0.5321  Acc@1: 87.5000 (80.1511)  Acc@5: 100.0000 (96.0852)  time: 0.6564  data: 0.0014  max mem: 2373\n",
            "Train: Epoch[1/5]  [100/313]  eta: 0:02:20  Lr: 0.001875  Loss: 0.4582  Acc@1: 87.5000 (80.3837)  Acc@5: 100.0000 (96.3490)  time: 0.6569  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[1/5]  [110/313]  eta: 0:02:13  Lr: 0.001875  Loss: 0.3596  Acc@1: 87.5000 (80.9685)  Acc@5: 100.0000 (96.6216)  time: 0.6569  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[1/5]  [120/313]  eta: 0:02:06  Lr: 0.001875  Loss: 0.3857  Acc@1: 87.5000 (81.2500)  Acc@5: 100.0000 (96.8492)  time: 0.6566  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[1/5]  [130/313]  eta: 0:02:00  Lr: 0.001875  Loss: 0.1864  Acc@1: 87.5000 (81.8702)  Acc@5: 100.0000 (96.9943)  time: 0.6563  data: 0.0014  max mem: 2373\n",
            "Train: Epoch[1/5]  [140/313]  eta: 0:01:53  Lr: 0.001875  Loss: 0.1247  Acc@1: 87.5000 (82.1365)  Acc@5: 100.0000 (97.1188)  time: 0.6565  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[1/5]  [150/313]  eta: 0:01:47  Lr: 0.001875  Loss: 0.0239  Acc@1: 87.5000 (82.6159)  Acc@5: 100.0000 (97.3096)  time: 0.6572  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[1/5]  [160/313]  eta: 0:01:40  Lr: 0.001875  Loss: 0.2526  Acc@1: 87.5000 (82.9969)  Acc@5: 100.0000 (97.4379)  time: 0.6570  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[1/5]  [170/313]  eta: 0:01:33  Lr: 0.001875  Loss: 0.2475  Acc@1: 87.5000 (83.1140)  Acc@5: 100.0000 (97.5877)  time: 0.6574  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[1/5]  [180/313]  eta: 0:01:27  Lr: 0.001875  Loss: -0.0035  Acc@1: 93.7500 (83.6326)  Acc@5: 100.0000 (97.6865)  time: 0.6578  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[1/5]  [190/313]  eta: 0:01:20  Lr: 0.001875  Loss: 0.2208  Acc@1: 93.7500 (83.9005)  Acc@5: 100.0000 (97.7749)  time: 0.6579  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[1/5]  [200/313]  eta: 0:01:14  Lr: 0.001875  Loss: 0.2328  Acc@1: 87.5000 (84.0796)  Acc@5: 100.0000 (97.8856)  time: 0.6581  data: 0.0015  max mem: 2373\n",
            "Train: Epoch[1/5]  [210/313]  eta: 0:01:07  Lr: 0.001875  Loss: 0.2670  Acc@1: 81.2500 (83.8863)  Acc@5: 100.0000 (97.8969)  time: 0.6587  data: 0.0015  max mem: 2373\n",
            "Train: Epoch[1/5]  [220/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.0092  Acc@1: 81.2500 (83.7952)  Acc@5: 100.0000 (97.9355)  time: 0.6585  data: 0.0013  max mem: 2373\n",
            "Train: Epoch[1/5]  [230/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.0726  Acc@1: 87.5000 (83.8203)  Acc@5: 100.0000 (98.0249)  time: 0.6574  data: 0.0013  max mem: 2373\n",
            "Train: Epoch[1/5]  [240/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.2241  Acc@1: 87.5000 (84.0768)  Acc@5: 100.0000 (98.0031)  time: 0.6575  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[1/5]  [250/313]  eta: 0:00:41  Lr: 0.001875  Loss: -0.0965  Acc@1: 87.5000 (84.2878)  Acc@5: 100.0000 (97.9831)  time: 0.6580  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[1/5]  [260/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.2126  Acc@1: 87.5000 (84.4349)  Acc@5: 100.0000 (98.0125)  time: 0.6583  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[1/5]  [270/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.0353  Acc@1: 87.5000 (84.5480)  Acc@5: 100.0000 (98.0627)  time: 0.6580  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[1/5]  [280/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.2947  Acc@1: 87.5000 (84.6975)  Acc@5: 100.0000 (98.1094)  time: 0.6571  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[1/5]  [290/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.4209  Acc@1: 87.5000 (84.7509)  Acc@5: 100.0000 (98.1529)  time: 0.6580  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[1/5]  [300/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.1212  Acc@1: 81.2500 (84.7591)  Acc@5: 100.0000 (98.1728)  time: 0.6585  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[1/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.2288  Acc@1: 87.5000 (84.7468)  Acc@5: 100.0000 (98.1109)  time: 0.6581  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.3528  Acc@1: 87.5000 (84.7800)  Acc@5: 100.0000 (98.1200)  time: 0.6417  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[1/5] Total time: 0:03:25 (0.6568 s / it)\n",
            "Averaged stats: Lr: 0.001875  Loss: 0.3528  Acc@1: 87.5000 (84.7800)  Acc@5: 100.0000 (98.1200)\n",
            "Train: Epoch[2/5]  [  0/313]  eta: 0:04:21  Lr: 0.001875  Loss: 0.3333  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.8366  data: 0.2212  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 10/313]  eta: 0:03:24  Lr: 0.001875  Loss: 0.0328  Acc@1: 93.7500 (92.0455)  Acc@5: 100.0000 (100.0000)  time: 0.6751  data: 0.0229  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 20/313]  eta: 0:03:15  Lr: 0.001875  Loss: 0.0100  Acc@1: 87.5000 (90.7738)  Acc@5: 100.0000 (99.7024)  time: 0.6577  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 30/313]  eta: 0:03:07  Lr: 0.001875  Loss: 0.0664  Acc@1: 87.5000 (89.3145)  Acc@5: 100.0000 (99.7984)  time: 0.6575  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 40/313]  eta: 0:03:00  Lr: 0.001875  Loss: 0.0492  Acc@1: 87.5000 (88.8720)  Acc@5: 100.0000 (99.6951)  time: 0.6574  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 50/313]  eta: 0:02:53  Lr: 0.001875  Loss: 0.0595  Acc@1: 87.5000 (87.9902)  Acc@5: 100.0000 (99.3873)  time: 0.6563  data: 0.0026  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 60/313]  eta: 0:02:47  Lr: 0.001875  Loss: 0.2330  Acc@1: 87.5000 (88.2172)  Acc@5: 100.0000 (99.2828)  time: 0.6565  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 70/313]  eta: 0:02:40  Lr: 0.001875  Loss: 0.5792  Acc@1: 87.5000 (87.5880)  Acc@5: 100.0000 (99.0317)  time: 0.6569  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 80/313]  eta: 0:02:33  Lr: 0.001875  Loss: -0.1405  Acc@1: 87.5000 (88.1173)  Acc@5: 100.0000 (99.1512)  time: 0.6574  data: 0.0032  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 90/313]  eta: 0:02:26  Lr: 0.001875  Loss: 0.0442  Acc@1: 87.5000 (88.2555)  Acc@5: 100.0000 (99.1758)  time: 0.6570  data: 0.0045  max mem: 2373\n",
            "Train: Epoch[2/5]  [100/313]  eta: 0:02:20  Lr: 0.001875  Loss: 0.2028  Acc@1: 87.5000 (88.0569)  Acc@5: 100.0000 (99.1955)  time: 0.6567  data: 0.0032  max mem: 2373\n",
            "Train: Epoch[2/5]  [110/313]  eta: 0:02:13  Lr: 0.001875  Loss: 0.1126  Acc@1: 87.5000 (87.9505)  Acc@5: 100.0000 (99.2680)  time: 0.6564  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[2/5]  [120/313]  eta: 0:02:07  Lr: 0.001875  Loss: 0.0796  Acc@1: 87.5000 (87.9649)  Acc@5: 100.0000 (99.2769)  time: 0.6561  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[2/5]  [130/313]  eta: 0:02:00  Lr: 0.001875  Loss: 0.1791  Acc@1: 87.5000 (87.9294)  Acc@5: 100.0000 (99.2844)  time: 0.6567  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[2/5]  [140/313]  eta: 0:01:53  Lr: 0.001875  Loss: 0.4046  Acc@1: 87.5000 (87.8546)  Acc@5: 100.0000 (99.3351)  time: 0.6568  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[2/5]  [150/313]  eta: 0:01:47  Lr: 0.001875  Loss: 0.2913  Acc@1: 87.5000 (87.8311)  Acc@5: 100.0000 (99.3791)  time: 0.6564  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[2/5]  [160/313]  eta: 0:01:40  Lr: 0.001875  Loss: 0.5974  Acc@1: 87.5000 (87.6941)  Acc@5: 100.0000 (99.3789)  time: 0.6568  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[2/5]  [170/313]  eta: 0:01:34  Lr: 0.001875  Loss: 0.0987  Acc@1: 87.5000 (87.6827)  Acc@5: 100.0000 (99.3421)  time: 0.6567  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[2/5]  [180/313]  eta: 0:01:27  Lr: 0.001875  Loss: -0.0138  Acc@1: 87.5000 (87.7072)  Acc@5: 100.0000 (99.3439)  time: 0.6566  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[2/5]  [190/313]  eta: 0:01:20  Lr: 0.001875  Loss: -0.0711  Acc@1: 87.5000 (87.7618)  Acc@5: 100.0000 (99.3455)  time: 0.6568  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[2/5]  [200/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.0534  Acc@1: 87.5000 (87.8731)  Acc@5: 100.0000 (99.3159)  time: 0.6565  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[2/5]  [210/313]  eta: 0:01:07  Lr: 0.001875  Loss: 0.1246  Acc@1: 87.5000 (87.6481)  Acc@5: 100.0000 (99.2891)  time: 0.6566  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[2/5]  [220/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.0217  Acc@1: 81.2500 (87.6697)  Acc@5: 100.0000 (99.2930)  time: 0.6564  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[2/5]  [230/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.2651  Acc@1: 87.5000 (87.6894)  Acc@5: 100.0000 (99.2424)  time: 0.6563  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[2/5]  [240/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.0940  Acc@1: 87.5000 (87.7593)  Acc@5: 100.0000 (99.2479)  time: 0.6565  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[2/5]  [250/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.2293  Acc@1: 93.7500 (87.8486)  Acc@5: 100.0000 (99.2779)  time: 0.6572  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[2/5]  [260/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.1285  Acc@1: 87.5000 (88.0029)  Acc@5: 100.0000 (99.2816)  time: 0.6573  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[2/5]  [270/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.0635  Acc@1: 87.5000 (88.0535)  Acc@5: 100.0000 (99.3081)  time: 0.6564  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[2/5]  [280/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.1925  Acc@1: 93.7500 (88.1228)  Acc@5: 100.0000 (99.2883)  time: 0.6563  data: 0.0026  max mem: 2373\n",
            "Train: Epoch[2/5]  [290/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.1370  Acc@1: 87.5000 (88.1658)  Acc@5: 100.0000 (99.2483)  time: 0.6569  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[2/5]  [300/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.1785  Acc@1: 93.7500 (88.4136)  Acc@5: 100.0000 (99.2733)  time: 0.6570  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[2/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.2008  Acc@1: 93.7500 (88.4646)  Acc@5: 100.0000 (99.2363)  time: 0.6564  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.3258  Acc@1: 93.7500 (88.4000)  Acc@5: 100.0000 (99.2400)  time: 0.6403  data: 0.0013  max mem: 2373\n",
            "Train: Epoch[2/5] Total time: 0:03:25 (0.6567 s / it)\n",
            "Averaged stats: Lr: 0.001875  Loss: 0.3258  Acc@1: 93.7500 (88.4000)  Acc@5: 100.0000 (99.2400)\n",
            "Train: Epoch[3/5]  [  0/313]  eta: 0:04:50  Lr: 0.001875  Loss: -0.1089  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.9274  data: 0.3039  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 10/313]  eta: 0:03:27  Lr: 0.001875  Loss: -0.0443  Acc@1: 87.5000 (86.9318)  Acc@5: 100.0000 (98.8636)  time: 0.6835  data: 0.0286  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 20/313]  eta: 0:03:16  Lr: 0.001875  Loss: 0.0309  Acc@1: 87.5000 (86.6071)  Acc@5: 100.0000 (98.8095)  time: 0.6575  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 30/313]  eta: 0:03:08  Lr: 0.001875  Loss: -0.0190  Acc@1: 87.5000 (86.4919)  Acc@5: 100.0000 (99.1935)  time: 0.6559  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 40/313]  eta: 0:03:01  Lr: 0.001875  Loss: 0.0496  Acc@1: 87.5000 (87.3476)  Acc@5: 100.0000 (99.2378)  time: 0.6561  data: 0.0011  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 50/313]  eta: 0:02:54  Lr: 0.001875  Loss: 0.3933  Acc@1: 93.7500 (87.7451)  Acc@5: 100.0000 (99.3873)  time: 0.6563  data: 0.0013  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 60/313]  eta: 0:02:47  Lr: 0.001875  Loss: -0.0014  Acc@1: 87.5000 (87.6025)  Acc@5: 100.0000 (99.1803)  time: 0.6563  data: 0.0011  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 70/313]  eta: 0:02:40  Lr: 0.001875  Loss: 0.1831  Acc@1: 87.5000 (87.7641)  Acc@5: 100.0000 (99.2958)  time: 0.6562  data: 0.0012  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 80/313]  eta: 0:02:33  Lr: 0.001875  Loss: -0.0400  Acc@1: 93.7500 (88.2716)  Acc@5: 100.0000 (99.3827)  time: 0.6561  data: 0.0015  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 90/313]  eta: 0:02:27  Lr: 0.001875  Loss: 0.0777  Acc@1: 93.7500 (88.5989)  Acc@5: 100.0000 (99.4505)  time: 0.6561  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[3/5]  [100/313]  eta: 0:02:20  Lr: 0.001875  Loss: 0.3680  Acc@1: 93.7500 (88.4901)  Acc@5: 100.0000 (99.5050)  time: 0.6565  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[3/5]  [110/313]  eta: 0:02:13  Lr: 0.001875  Loss: 0.2226  Acc@1: 93.7500 (88.5135)  Acc@5: 100.0000 (99.4932)  time: 0.6565  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[3/5]  [120/313]  eta: 0:02:07  Lr: 0.001875  Loss: -0.0559  Acc@1: 93.7500 (88.6880)  Acc@5: 100.0000 (99.4835)  time: 0.6561  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[3/5]  [130/313]  eta: 0:02:00  Lr: 0.001875  Loss: 0.0029  Acc@1: 87.5000 (88.7882)  Acc@5: 100.0000 (99.5229)  time: 0.6563  data: 0.0009  max mem: 2373\n",
            "Train: Epoch[3/5]  [140/313]  eta: 0:01:53  Lr: 0.001875  Loss: 0.2602  Acc@1: 87.5000 (88.8298)  Acc@5: 100.0000 (99.4681)  time: 0.6563  data: 0.0009  max mem: 2373\n",
            "Train: Epoch[3/5]  [150/313]  eta: 0:01:47  Lr: 0.001875  Loss: 0.1721  Acc@1: 87.5000 (88.9901)  Acc@5: 100.0000 (99.5033)  time: 0.6556  data: 0.0015  max mem: 2373\n",
            "Train: Epoch[3/5]  [160/313]  eta: 0:01:40  Lr: 0.001875  Loss: -0.0509  Acc@1: 93.7500 (89.2081)  Acc@5: 100.0000 (99.5342)  time: 0.6557  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[3/5]  [170/313]  eta: 0:01:34  Lr: 0.001875  Loss: 0.0252  Acc@1: 93.7500 (89.2178)  Acc@5: 100.0000 (99.5249)  time: 0.6565  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[3/5]  [180/313]  eta: 0:01:27  Lr: 0.001875  Loss: 0.2232  Acc@1: 87.5000 (89.0193)  Acc@5: 100.0000 (99.4820)  time: 0.6567  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[3/5]  [190/313]  eta: 0:01:20  Lr: 0.001875  Loss: 0.0017  Acc@1: 87.5000 (89.0380)  Acc@5: 100.0000 (99.4764)  time: 0.6563  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[3/5]  [200/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.0434  Acc@1: 87.5000 (88.8682)  Acc@5: 100.0000 (99.4403)  time: 0.6561  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[3/5]  [210/313]  eta: 0:01:07  Lr: 0.001875  Loss: 0.0079  Acc@1: 87.5000 (88.8626)  Acc@5: 100.0000 (99.3780)  time: 0.6562  data: 0.0031  max mem: 2373\n",
            "Train: Epoch[3/5]  [220/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.2141  Acc@1: 87.5000 (88.6312)  Acc@5: 100.0000 (99.3495)  time: 0.6560  data: 0.0035  max mem: 2373\n",
            "Train: Epoch[3/5]  [230/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.1868  Acc@1: 87.5000 (88.6093)  Acc@5: 100.0000 (99.3777)  time: 0.6561  data: 0.0029  max mem: 2373\n",
            "Train: Epoch[3/5]  [240/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.0102  Acc@1: 87.5000 (88.6929)  Acc@5: 100.0000 (99.3776)  time: 0.6564  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[3/5]  [250/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.1742  Acc@1: 93.7500 (88.7948)  Acc@5: 100.0000 (99.4024)  time: 0.6561  data: 0.0009  max mem: 2373\n",
            "Train: Epoch[3/5]  [260/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.3650  Acc@1: 87.5000 (88.6973)  Acc@5: 100.0000 (99.4013)  time: 0.6552  data: 0.0010  max mem: 2373\n",
            "Train: Epoch[3/5]  [270/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.2547  Acc@1: 87.5000 (88.5609)  Acc@5: 100.0000 (99.3542)  time: 0.6553  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[3/5]  [280/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.3298  Acc@1: 87.5000 (88.6343)  Acc@5: 100.0000 (99.3550)  time: 0.6559  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[3/5]  [290/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.2691  Acc@1: 93.7500 (88.5309)  Acc@5: 100.0000 (99.3771)  time: 0.6554  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[3/5]  [300/313]  eta: 0:00:08  Lr: 0.001875  Loss: -0.0153  Acc@1: 87.5000 (88.5174)  Acc@5: 100.0000 (99.3563)  time: 0.6553  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[3/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.0553  Acc@1: 87.5000 (88.5651)  Acc@5: 100.0000 (99.3770)  time: 0.6554  data: 0.0004  max mem: 2373\n",
            "Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1909  Acc@1: 87.5000 (88.6200)  Acc@5: 100.0000 (99.3800)  time: 0.6391  data: 0.0004  max mem: 2373\n",
            "Train: Epoch[3/5] Total time: 0:03:25 (0.6562 s / it)\n",
            "Averaged stats: Lr: 0.001875  Loss: -0.1909  Acc@1: 87.5000 (88.6200)  Acc@5: 100.0000 (99.3800)\n",
            "Train: Epoch[4/5]  [  0/313]  eta: 0:03:56  Lr: 0.001875  Loss: 0.2113  Acc@1: 87.5000 (87.5000)  Acc@5: 93.7500 (93.7500)  time: 0.7551  data: 0.1371  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 10/313]  eta: 0:03:22  Lr: 0.001875  Loss: -0.0141  Acc@1: 93.7500 (92.6136)  Acc@5: 100.0000 (98.8636)  time: 0.6671  data: 0.0140  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 20/313]  eta: 0:03:13  Lr: 0.001875  Loss: 0.0600  Acc@1: 93.7500 (90.1786)  Acc@5: 100.0000 (99.4048)  time: 0.6573  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 30/313]  eta: 0:03:06  Lr: 0.001875  Loss: -0.0226  Acc@1: 93.7500 (90.5242)  Acc@5: 100.0000 (99.3952)  time: 0.6562  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 40/313]  eta: 0:02:59  Lr: 0.001875  Loss: 0.1784  Acc@1: 87.5000 (90.3963)  Acc@5: 100.0000 (99.3902)  time: 0.6566  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 50/313]  eta: 0:02:53  Lr: 0.001875  Loss: 0.0601  Acc@1: 87.5000 (89.8284)  Acc@5: 100.0000 (99.2647)  time: 0.6565  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 60/313]  eta: 0:02:46  Lr: 0.001875  Loss: 0.0234  Acc@1: 87.5000 (89.2418)  Acc@5: 100.0000 (99.0779)  time: 0.6562  data: 0.0026  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 70/313]  eta: 0:02:39  Lr: 0.001875  Loss: 0.0762  Acc@1: 81.2500 (88.1162)  Acc@5: 100.0000 (99.1197)  time: 0.6565  data: 0.0025  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 80/313]  eta: 0:02:33  Lr: 0.001875  Loss: 0.0102  Acc@1: 87.5000 (88.2716)  Acc@5: 100.0000 (99.1512)  time: 0.6569  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 90/313]  eta: 0:02:26  Lr: 0.001875  Loss: -0.1436  Acc@1: 87.5000 (88.4615)  Acc@5: 100.0000 (99.1071)  time: 0.6566  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[4/5]  [100/313]  eta: 0:02:20  Lr: 0.001875  Loss: 0.2785  Acc@1: 87.5000 (88.3663)  Acc@5: 100.0000 (99.1337)  time: 0.6562  data: 0.0025  max mem: 2373\n",
            "Train: Epoch[4/5]  [110/313]  eta: 0:02:13  Lr: 0.001875  Loss: 0.1003  Acc@1: 81.2500 (87.8941)  Acc@5: 100.0000 (99.0991)  time: 0.6573  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[4/5]  [120/313]  eta: 0:02:06  Lr: 0.001875  Loss: 0.0224  Acc@1: 87.5000 (87.9132)  Acc@5: 100.0000 (99.0186)  time: 0.6580  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[4/5]  [130/313]  eta: 0:02:00  Lr: 0.001875  Loss: -0.1206  Acc@1: 87.5000 (88.0248)  Acc@5: 100.0000 (98.9981)  time: 0.6573  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[4/5]  [140/313]  eta: 0:01:53  Lr: 0.001875  Loss: -0.0640  Acc@1: 93.7500 (88.2092)  Acc@5: 100.0000 (99.0248)  time: 0.6574  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[4/5]  [150/313]  eta: 0:01:47  Lr: 0.001875  Loss: -0.0918  Acc@1: 93.7500 (88.3278)  Acc@5: 100.0000 (99.0480)  time: 0.6580  data: 0.0015  max mem: 2373\n",
            "Train: Epoch[4/5]  [160/313]  eta: 0:01:40  Lr: 0.001875  Loss: -0.1895  Acc@1: 87.5000 (88.4705)  Acc@5: 100.0000 (99.0683)  time: 0.6584  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[4/5]  [170/313]  eta: 0:01:34  Lr: 0.001875  Loss: 0.3104  Acc@1: 87.5000 (88.3772)  Acc@5: 100.0000 (99.0863)  time: 0.6578  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[4/5]  [180/313]  eta: 0:01:27  Lr: 0.001875  Loss: 0.3177  Acc@1: 87.5000 (88.2597)  Acc@5: 100.0000 (99.0677)  time: 0.6573  data: 0.0012  max mem: 2373\n",
            "Train: Epoch[4/5]  [190/313]  eta: 0:01:20  Lr: 0.001875  Loss: 0.1151  Acc@1: 87.5000 (88.4490)  Acc@5: 100.0000 (99.0838)  time: 0.6572  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[4/5]  [200/313]  eta: 0:01:14  Lr: 0.001875  Loss: 0.0535  Acc@1: 93.7500 (88.4328)  Acc@5: 100.0000 (99.1294)  time: 0.6568  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[4/5]  [210/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.0098  Acc@1: 87.5000 (88.5664)  Acc@5: 100.0000 (99.1114)  time: 0.6567  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[4/5]  [220/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.2170  Acc@1: 93.7500 (88.6029)  Acc@5: 100.0000 (99.1233)  time: 0.6573  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[4/5]  [230/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.2202  Acc@1: 93.7500 (88.7446)  Acc@5: 100.0000 (99.1342)  time: 0.6573  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[4/5]  [240/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.1470  Acc@1: 87.5000 (88.6929)  Acc@5: 100.0000 (99.1183)  time: 0.6563  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[4/5]  [250/313]  eta: 0:00:41  Lr: 0.001875  Loss: -0.1259  Acc@1: 93.7500 (88.7948)  Acc@5: 100.0000 (99.1534)  time: 0.6565  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[4/5]  [260/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.0968  Acc@1: 93.7500 (88.9128)  Acc@5: 100.0000 (99.1858)  time: 0.6573  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[4/5]  [270/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.3163  Acc@1: 93.7500 (88.9530)  Acc@5: 100.0000 (99.1697)  time: 0.6576  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[4/5]  [280/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.0568  Acc@1: 87.5000 (88.9457)  Acc@5: 100.0000 (99.1770)  time: 0.6566  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[4/5]  [290/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.2139  Acc@1: 87.5000 (88.8531)  Acc@5: 100.0000 (99.1838)  time: 0.6570  data: 0.0026  max mem: 2373\n",
            "Train: Epoch[4/5]  [300/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.0374  Acc@1: 87.5000 (88.8289)  Acc@5: 100.0000 (99.1694)  time: 0.6571  data: 0.0026  max mem: 2373\n",
            "Train: Epoch[4/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: -0.0164  Acc@1: 87.5000 (88.7862)  Acc@5: 100.0000 (99.1961)  time: 0.6565  data: 0.0015  max mem: 2373\n",
            "Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1813  Acc@1: 87.5000 (88.8400)  Acc@5: 100.0000 (99.2000)  time: 0.6405  data: 0.0015  max mem: 2373\n",
            "Train: Epoch[4/5] Total time: 0:03:25 (0.6566 s / it)\n",
            "Averaged stats: Lr: 0.001875  Loss: -0.1813  Acc@1: 87.5000 (88.8400)  Acc@5: 100.0000 (99.2000)\n",
            "Train: Epoch[5/5]  [  0/313]  eta: 0:03:58  Lr: 0.001875  Loss: 0.4697  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.7612  data: 0.1446  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 10/313]  eta: 0:03:22  Lr: 0.001875  Loss: -0.1002  Acc@1: 93.7500 (89.7727)  Acc@5: 100.0000 (99.4318)  time: 0.6678  data: 0.0145  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 20/313]  eta: 0:03:14  Lr: 0.001875  Loss: 0.2502  Acc@1: 87.5000 (88.6905)  Acc@5: 100.0000 (99.7024)  time: 0.6575  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 30/313]  eta: 0:03:07  Lr: 0.001875  Loss: 0.0268  Acc@1: 87.5000 (89.3145)  Acc@5: 100.0000 (99.5968)  time: 0.6571  data: 0.0013  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 40/313]  eta: 0:03:00  Lr: 0.001875  Loss: 0.0369  Acc@1: 87.5000 (89.9390)  Acc@5: 100.0000 (99.5427)  time: 0.6569  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 50/313]  eta: 0:02:53  Lr: 0.001875  Loss: 0.0823  Acc@1: 87.5000 (89.7059)  Acc@5: 100.0000 (99.5098)  time: 0.6569  data: 0.0035  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 60/313]  eta: 0:02:46  Lr: 0.001875  Loss: -0.0058  Acc@1: 87.5000 (89.5492)  Acc@5: 100.0000 (99.3852)  time: 0.6567  data: 0.0045  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 70/313]  eta: 0:02:39  Lr: 0.001875  Loss: 0.2087  Acc@1: 87.5000 (88.9085)  Acc@5: 100.0000 (99.2958)  time: 0.6559  data: 0.0027  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 80/313]  eta: 0:02:33  Lr: 0.001875  Loss: 0.1220  Acc@1: 87.5000 (89.0432)  Acc@5: 100.0000 (99.3056)  time: 0.6564  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 90/313]  eta: 0:02:26  Lr: 0.001875  Loss: -0.0432  Acc@1: 87.5000 (89.2170)  Acc@5: 100.0000 (99.3819)  time: 0.6565  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[5/5]  [100/313]  eta: 0:02:20  Lr: 0.001875  Loss: -0.0208  Acc@1: 87.5000 (88.9233)  Acc@5: 100.0000 (99.4431)  time: 0.6569  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[5/5]  [110/313]  eta: 0:02:13  Lr: 0.001875  Loss: 0.6871  Acc@1: 87.5000 (88.6824)  Acc@5: 100.0000 (99.3243)  time: 0.6570  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[5/5]  [120/313]  eta: 0:02:06  Lr: 0.001875  Loss: -0.1450  Acc@1: 93.7500 (88.7397)  Acc@5: 100.0000 (99.2769)  time: 0.6565  data: 0.0025  max mem: 2373\n",
            "Train: Epoch[5/5]  [130/313]  eta: 0:02:00  Lr: 0.001875  Loss: 0.1561  Acc@1: 93.7500 (88.9313)  Acc@5: 100.0000 (99.3321)  time: 0.6562  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[5/5]  [140/313]  eta: 0:01:53  Lr: 0.001875  Loss: 0.0702  Acc@1: 87.5000 (88.7411)  Acc@5: 100.0000 (99.1578)  time: 0.6564  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[5/5]  [150/313]  eta: 0:01:47  Lr: 0.001875  Loss: 0.0432  Acc@1: 87.5000 (88.6589)  Acc@5: 100.0000 (99.2136)  time: 0.6563  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[5/5]  [160/313]  eta: 0:01:40  Lr: 0.001875  Loss: 0.2460  Acc@1: 87.5000 (88.6258)  Acc@5: 100.0000 (99.1848)  time: 0.6557  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[5/5]  [170/313]  eta: 0:01:33  Lr: 0.001875  Loss: -0.1537  Acc@1: 87.5000 (88.6696)  Acc@5: 100.0000 (99.2325)  time: 0.6555  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[5/5]  [180/313]  eta: 0:01:27  Lr: 0.001875  Loss: -0.1346  Acc@1: 87.5000 (88.6395)  Acc@5: 100.0000 (99.2403)  time: 0.6550  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[5/5]  [190/313]  eta: 0:01:20  Lr: 0.001875  Loss: 0.5617  Acc@1: 87.5000 (88.5798)  Acc@5: 100.0000 (99.2474)  time: 0.6553  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[5/5]  [200/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.1164  Acc@1: 87.5000 (88.5883)  Acc@5: 100.0000 (99.2848)  time: 0.6558  data: 0.0014  max mem: 2373\n",
            "Train: Epoch[5/5]  [210/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.0635  Acc@1: 93.7500 (88.7737)  Acc@5: 100.0000 (99.3187)  time: 0.6558  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[5/5]  [220/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.1350  Acc@1: 93.7500 (88.8575)  Acc@5: 100.0000 (99.3213)  time: 0.6554  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[5/5]  [230/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.2258  Acc@1: 87.5000 (88.7987)  Acc@5: 100.0000 (99.2695)  time: 0.6552  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[5/5]  [240/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.1197  Acc@1: 87.5000 (88.6670)  Acc@5: 100.0000 (99.2479)  time: 0.6556  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[5/5]  [250/313]  eta: 0:00:41  Lr: 0.001875  Loss: -0.0687  Acc@1: 87.5000 (88.6952)  Acc@5: 100.0000 (99.2530)  time: 0.6553  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[5/5]  [260/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.0930  Acc@1: 87.5000 (88.6973)  Acc@5: 100.0000 (99.2816)  time: 0.6553  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[5/5]  [270/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.2489  Acc@1: 87.5000 (88.7223)  Acc@5: 100.0000 (99.2851)  time: 0.6557  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[5/5]  [280/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.0494  Acc@1: 93.7500 (88.8345)  Acc@5: 100.0000 (99.2883)  time: 0.6552  data: 0.0014  max mem: 2373\n",
            "Train: Epoch[5/5]  [290/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.1181  Acc@1: 93.7500 (88.8101)  Acc@5: 100.0000 (99.3127)  time: 0.6555  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[5/5]  [300/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.4432  Acc@1: 87.5000 (88.6628)  Acc@5: 100.0000 (99.3355)  time: 0.6557  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[5/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.2347  Acc@1: 87.5000 (88.7058)  Acc@5: 100.0000 (99.3368)  time: 0.6541  data: 0.0026  max mem: 2373\n",
            "Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.3333  Acc@1: 87.5000 (88.7200)  Acc@5: 100.0000 (99.3400)  time: 0.6382  data: 0.0026  max mem: 2373\n",
            "Train: Epoch[5/5] Total time: 0:03:25 (0.6555 s / it)\n",
            "Averaged stats: Lr: 0.001875  Loss: 0.3333  Acc@1: 87.5000 (88.7200)  Acc@5: 100.0000 (99.3400)\n",
            "Test: [Task 1]  [ 0/63]  eta: 0:00:33  Loss: 0.8777 (0.8777)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.5359  data: 0.1429  max mem: 2373\n",
            "Test: [Task 1]  [10/63]  eta: 0:00:23  Loss: 0.7007 (0.6269)  Acc@1: 87.5000 (85.2273)  Acc@5: 100.0000 (98.2955)  time: 0.4354  data: 0.0140  max mem: 2373\n",
            "Test: [Task 1]  [20/63]  eta: 0:00:18  Loss: 0.7007 (0.6898)  Acc@1: 81.2500 (81.8452)  Acc@5: 100.0000 (97.9167)  time: 0.4251  data: 0.0030  max mem: 2373\n",
            "Test: [Task 1]  [30/63]  eta: 0:00:14  Loss: 0.6036 (0.6643)  Acc@1: 81.2500 (82.8629)  Acc@5: 100.0000 (98.3871)  time: 0.4244  data: 0.0027  max mem: 2373\n",
            "Test: [Task 1]  [40/63]  eta: 0:00:09  Loss: 0.5757 (0.6480)  Acc@1: 81.2500 (83.5366)  Acc@5: 100.0000 (98.6280)  time: 0.4238  data: 0.0006  max mem: 2373\n",
            "Test: [Task 1]  [50/63]  eta: 0:00:05  Loss: 0.5014 (0.6183)  Acc@1: 87.5000 (84.5588)  Acc@5: 100.0000 (98.7745)  time: 0.4244  data: 0.0031  max mem: 2373\n",
            "Test: [Task 1]  [60/63]  eta: 0:00:01  Loss: 0.4991 (0.6024)  Acc@1: 87.5000 (85.5533)  Acc@5: 100.0000 (98.6680)  time: 0.4253  data: 0.0029  max mem: 2373\n",
            "Test: [Task 1]  [62/63]  eta: 0:00:00  Loss: 0.4555 (0.5968)  Acc@1: 93.7500 (85.9000)  Acc@5: 100.0000 (98.7000)  time: 0.4149  data: 0.0029  max mem: 2373\n",
            "Test: [Task 1] Total time: 0:00:26 (0.4241 s / it)\n",
            "* Acc@1 85.900 Acc@5 98.700 loss 0.597\n",
            "Test: [Task 2]  [ 0/63]  eta: 0:00:33  Loss: 0.8147 (0.8147)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)  time: 0.5380  data: 0.1467  max mem: 2373\n",
            "Test: [Task 2]  [10/63]  eta: 0:00:23  Loss: 0.7636 (0.7247)  Acc@1: 87.5000 (86.3636)  Acc@5: 100.0000 (97.1591)  time: 0.4367  data: 0.0147  max mem: 2373\n",
            "Test: [Task 2]  [20/63]  eta: 0:00:18  Loss: 0.6940 (0.7668)  Acc@1: 81.2500 (83.6310)  Acc@5: 100.0000 (97.0238)  time: 0.4265  data: 0.0025  max mem: 2373\n",
            "Test: [Task 2]  [30/63]  eta: 0:00:14  Loss: 0.6940 (0.7430)  Acc@1: 81.2500 (84.6774)  Acc@5: 100.0000 (96.7742)  time: 0.4265  data: 0.0020  max mem: 2373\n",
            "Test: [Task 2]  [40/63]  eta: 0:00:09  Loss: 0.6262 (0.7242)  Acc@1: 87.5000 (85.0610)  Acc@5: 100.0000 (96.9512)  time: 0.4255  data: 0.0005  max mem: 2373\n",
            "Test: [Task 2]  [50/63]  eta: 0:00:05  Loss: 0.6082 (0.7159)  Acc@1: 81.2500 (84.5588)  Acc@5: 100.0000 (97.0588)  time: 0.4247  data: 0.0024  max mem: 2373\n",
            "Test: [Task 2]  [60/63]  eta: 0:00:01  Loss: 0.6082 (0.6972)  Acc@1: 81.2500 (85.2459)  Acc@5: 100.0000 (97.4385)  time: 0.4259  data: 0.0026  max mem: 2373\n",
            "Test: [Task 2]  [62/63]  eta: 0:00:00  Loss: 0.5469 (0.6881)  Acc@1: 87.5000 (85.3000)  Acc@5: 100.0000 (97.5000)  time: 0.4152  data: 0.0026  max mem: 2373\n",
            "Test: [Task 2] Total time: 0:00:26 (0.4253 s / it)\n",
            "* Acc@1 85.300 Acc@5 97.500 loss 0.688\n",
            "Test: [Task 3]  [ 0/63]  eta: 0:00:38  Loss: 0.3517 (0.3517)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.6165  data: 0.2254  max mem: 2373\n",
            "Test: [Task 3]  [10/63]  eta: 0:00:23  Loss: 0.6365 (0.5770)  Acc@1: 87.5000 (85.7955)  Acc@5: 100.0000 (98.2955)  time: 0.4450  data: 0.0209  max mem: 2373\n",
            "Test: [Task 3]  [20/63]  eta: 0:00:18  Loss: 0.6459 (0.5970)  Acc@1: 81.2500 (83.6310)  Acc@5: 100.0000 (98.2143)  time: 0.4276  data: 0.0019  max mem: 2373\n",
            "Test: [Task 3]  [30/63]  eta: 0:00:14  Loss: 0.6490 (0.6000)  Acc@1: 81.2500 (84.0726)  Acc@5: 100.0000 (98.5887)  time: 0.4266  data: 0.0021  max mem: 2373\n",
            "Test: [Task 3]  [40/63]  eta: 0:00:09  Loss: 0.6220 (0.5987)  Acc@1: 87.5000 (84.9085)  Acc@5: 100.0000 (98.4756)  time: 0.4264  data: 0.0007  max mem: 2373\n",
            "Test: [Task 3]  [50/63]  eta: 0:00:05  Loss: 0.6431 (0.6057)  Acc@1: 87.5000 (85.2941)  Acc@5: 100.0000 (98.2843)  time: 0.4256  data: 0.0020  max mem: 2373\n",
            "Test: [Task 3]  [60/63]  eta: 0:00:01  Loss: 0.6241 (0.6138)  Acc@1: 87.5000 (85.0410)  Acc@5: 100.0000 (98.3607)  time: 0.4252  data: 0.0030  max mem: 2373\n",
            "Test: [Task 3]  [62/63]  eta: 0:00:00  Loss: 0.6743 (0.6135)  Acc@1: 87.5000 (85.1000)  Acc@5: 100.0000 (98.3000)  time: 0.4145  data: 0.0030  max mem: 2373\n",
            "Test: [Task 3] Total time: 0:00:26 (0.4269 s / it)\n",
            "* Acc@1 85.100 Acc@5 98.300 loss 0.613\n",
            "Test: [Task 4]  [ 0/63]  eta: 0:00:37  Loss: 0.8177 (0.8177)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.5931  data: 0.2010  max mem: 2373\n",
            "Test: [Task 4]  [10/63]  eta: 0:00:23  Loss: 0.7502 (0.6813)  Acc@1: 81.2500 (82.9545)  Acc@5: 100.0000 (97.1591)  time: 0.4428  data: 0.0187  max mem: 2373\n",
            "Test: [Task 4]  [20/63]  eta: 0:00:18  Loss: 0.6663 (0.6685)  Acc@1: 81.2500 (82.4405)  Acc@5: 100.0000 (97.0238)  time: 0.4283  data: 0.0015  max mem: 2373\n",
            "Test: [Task 4]  [30/63]  eta: 0:00:14  Loss: 0.5057 (0.6269)  Acc@1: 87.5000 (84.2742)  Acc@5: 100.0000 (97.3790)  time: 0.4282  data: 0.0019  max mem: 2373\n",
            "Test: [Task 4]  [40/63]  eta: 0:00:09  Loss: 0.3973 (0.5769)  Acc@1: 93.7500 (85.8232)  Acc@5: 100.0000 (97.8659)  time: 0.4275  data: 0.0008  max mem: 2373\n",
            "Test: [Task 4]  [50/63]  eta: 0:00:05  Loss: 0.3973 (0.5916)  Acc@1: 93.7500 (86.1520)  Acc@5: 100.0000 (97.5490)  time: 0.4263  data: 0.0019  max mem: 2373\n",
            "Test: [Task 4]  [60/63]  eta: 0:00:01  Loss: 0.5097 (0.6031)  Acc@1: 87.5000 (86.0656)  Acc@5: 100.0000 (97.3361)  time: 0.4269  data: 0.0033  max mem: 2373\n",
            "Test: [Task 4]  [62/63]  eta: 0:00:00  Loss: 0.4845 (0.6025)  Acc@1: 87.5000 (86.2000)  Acc@5: 100.0000 (97.4000)  time: 0.4165  data: 0.0032  max mem: 2373\n",
            "Test: [Task 4] Total time: 0:00:26 (0.4276 s / it)\n",
            "* Acc@1 86.200 Acc@5 97.400 loss 0.602\n",
            "Test: [Task 5]  [ 0/63]  eta: 0:00:37  Loss: 0.2773 (0.2773)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.5927  data: 0.1988  max mem: 2373\n",
            "Test: [Task 5]  [10/63]  eta: 0:00:23  Loss: 0.4128 (0.5336)  Acc@1: 93.7500 (91.4773)  Acc@5: 100.0000 (99.4318)  time: 0.4433  data: 0.0186  max mem: 2373\n",
            "Test: [Task 5]  [20/63]  eta: 0:00:18  Loss: 0.4128 (0.4930)  Acc@1: 93.7500 (91.9643)  Acc@5: 100.0000 (99.1071)  time: 0.4288  data: 0.0015  max mem: 2373\n",
            "Test: [Task 5]  [30/63]  eta: 0:00:14  Loss: 0.4080 (0.4840)  Acc@1: 93.7500 (92.1371)  Acc@5: 100.0000 (98.9919)  time: 0.4283  data: 0.0022  max mem: 2373\n",
            "Test: [Task 5]  [40/63]  eta: 0:00:09  Loss: 0.4080 (0.4701)  Acc@1: 93.7500 (92.5305)  Acc@5: 100.0000 (98.7805)  time: 0.4274  data: 0.0024  max mem: 2373\n",
            "Test: [Task 5]  [50/63]  eta: 0:00:05  Loss: 0.4483 (0.4813)  Acc@1: 93.7500 (92.6471)  Acc@5: 100.0000 (98.6520)  time: 0.4276  data: 0.0039  max mem: 2373\n",
            "Test: [Task 5]  [60/63]  eta: 0:00:01  Loss: 0.4573 (0.4878)  Acc@1: 93.7500 (92.2131)  Acc@5: 100.0000 (98.5656)  time: 0.4281  data: 0.0035  max mem: 2373\n",
            "Test: [Task 5]  [62/63]  eta: 0:00:00  Loss: 0.4731 (0.5074)  Acc@1: 93.7500 (91.6000)  Acc@5: 100.0000 (98.5000)  time: 0.4173  data: 0.0031  max mem: 2373\n",
            "Test: [Task 5] Total time: 0:00:26 (0.4283 s / it)\n",
            "* Acc@1 91.600 Acc@5 98.500 loss 0.507\n",
            "Test: [Task 6]  [ 0/63]  eta: 0:00:39  Loss: 0.4810 (0.4810)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.6204  data: 0.2242  max mem: 2373\n",
            "Test: [Task 6]  [10/63]  eta: 0:00:23  Loss: 0.6685 (0.6171)  Acc@1: 81.2500 (82.3864)  Acc@5: 100.0000 (98.8636)  time: 0.4459  data: 0.0212  max mem: 2373\n",
            "Test: [Task 6]  [20/63]  eta: 0:00:18  Loss: 0.6685 (0.6662)  Acc@1: 81.2500 (81.8452)  Acc@5: 100.0000 (98.8095)  time: 0.4281  data: 0.0026  max mem: 2373\n",
            "Test: [Task 6]  [30/63]  eta: 0:00:14  Loss: 0.6369 (0.6521)  Acc@1: 81.2500 (81.6532)  Acc@5: 100.0000 (99.1935)  time: 0.4279  data: 0.0030  max mem: 2373\n",
            "Test: [Task 6]  [40/63]  eta: 0:00:09  Loss: 0.6369 (0.6836)  Acc@1: 81.2500 (80.7927)  Acc@5: 100.0000 (98.7805)  time: 0.4278  data: 0.0011  max mem: 2373\n",
            "Test: [Task 6]  [50/63]  eta: 0:00:05  Loss: 0.6736 (0.6679)  Acc@1: 81.2500 (81.3725)  Acc@5: 100.0000 (99.0196)  time: 0.4265  data: 0.0010  max mem: 2373\n",
            "Test: [Task 6]  [60/63]  eta: 0:00:01  Loss: 0.6784 (0.6887)  Acc@1: 81.2500 (81.3525)  Acc@5: 100.0000 (98.7705)  time: 0.4257  data: 0.0023  max mem: 2373\n",
            "Test: [Task 6]  [62/63]  eta: 0:00:00  Loss: 0.6784 (0.6850)  Acc@1: 81.2500 (81.5000)  Acc@5: 100.0000 (98.8000)  time: 0.4150  data: 0.0022  max mem: 2373\n",
            "Test: [Task 6] Total time: 0:00:26 (0.4276 s / it)\n",
            "* Acc@1 81.500 Acc@5 98.800 loss 0.685\n",
            "[Average accuracy till task6]\tAcc@1: 85.9333\tAcc@5: 98.2000\tLoss: 0.6156\tForgetting: 6.1200\tBackward: -5.8800\n",
            "Train: Epoch[1/5]  [  0/313]  eta: 0:04:22  Lr: 0.001875  Loss: 2.1056  Acc@1: 0.0000 (0.0000)  Acc@5: 31.2500 (31.2500)  time: 0.8397  data: 0.2257  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 10/313]  eta: 0:03:24  Lr: 0.001875  Loss: 1.8154  Acc@1: 56.2500 (47.7273)  Acc@5: 87.5000 (81.8182)  time: 0.6736  data: 0.0217  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 20/313]  eta: 0:03:14  Lr: 0.001875  Loss: 1.3850  Acc@1: 68.7500 (61.0119)  Acc@5: 93.7500 (88.0952)  time: 0.6562  data: 0.0012  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 30/313]  eta: 0:03:07  Lr: 0.001875  Loss: 1.0754  Acc@1: 75.0000 (67.1371)  Acc@5: 93.7500 (90.5242)  time: 0.6556  data: 0.0007  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 40/313]  eta: 0:03:00  Lr: 0.001875  Loss: 0.8382  Acc@1: 81.2500 (70.8841)  Acc@5: 100.0000 (92.5305)  time: 0.6554  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 50/313]  eta: 0:02:53  Lr: 0.001875  Loss: 0.8955  Acc@1: 81.2500 (72.9167)  Acc@5: 100.0000 (93.2598)  time: 0.6555  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 60/313]  eta: 0:02:46  Lr: 0.001875  Loss: 0.5322  Acc@1: 81.2500 (74.5902)  Acc@5: 100.0000 (94.1598)  time: 0.6555  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 70/313]  eta: 0:02:39  Lr: 0.001875  Loss: 0.7203  Acc@1: 81.2500 (76.1444)  Acc@5: 100.0000 (94.3662)  time: 0.6555  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 80/313]  eta: 0:02:33  Lr: 0.001875  Loss: 0.6947  Acc@1: 81.2500 (76.6204)  Acc@5: 93.7500 (94.5216)  time: 0.6556  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 90/313]  eta: 0:02:26  Lr: 0.001875  Loss: 0.4764  Acc@1: 81.2500 (77.4725)  Acc@5: 100.0000 (94.9176)  time: 0.6557  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[1/5]  [100/313]  eta: 0:02:20  Lr: 0.001875  Loss: 0.8979  Acc@1: 87.5000 (78.4035)  Acc@5: 100.0000 (95.2970)  time: 0.6557  data: 0.0015  max mem: 2373\n",
            "Train: Epoch[1/5]  [110/313]  eta: 0:02:13  Lr: 0.001875  Loss: 0.2244  Acc@1: 87.5000 (79.0541)  Acc@5: 100.0000 (95.7207)  time: 0.6549  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[1/5]  [120/313]  eta: 0:02:06  Lr: 0.001875  Loss: 0.5111  Acc@1: 87.5000 (79.4421)  Acc@5: 100.0000 (95.9711)  time: 0.6552  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[1/5]  [130/313]  eta: 0:02:00  Lr: 0.001875  Loss: 0.4002  Acc@1: 87.5000 (79.9618)  Acc@5: 100.0000 (96.2309)  time: 0.6560  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[1/5]  [140/313]  eta: 0:01:53  Lr: 0.001875  Loss: 0.5520  Acc@1: 87.5000 (80.4521)  Acc@5: 100.0000 (96.2766)  time: 0.6560  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[1/5]  [150/313]  eta: 0:01:47  Lr: 0.001875  Loss: 0.0628  Acc@1: 87.5000 (80.7947)  Acc@5: 100.0000 (96.4818)  time: 0.6559  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[1/5]  [160/313]  eta: 0:01:40  Lr: 0.001875  Loss: 0.1975  Acc@1: 81.2500 (80.9394)  Acc@5: 100.0000 (96.6615)  time: 0.6553  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[1/5]  [170/313]  eta: 0:01:33  Lr: 0.001875  Loss: 0.2316  Acc@1: 87.5000 (81.5058)  Acc@5: 100.0000 (96.7836)  time: 0.6553  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[1/5]  [180/313]  eta: 0:01:27  Lr: 0.001875  Loss: -0.0103  Acc@1: 87.5000 (81.8715)  Acc@5: 100.0000 (96.9613)  time: 0.6556  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[1/5]  [190/313]  eta: 0:01:20  Lr: 0.001875  Loss: 0.0998  Acc@1: 87.5000 (82.2644)  Acc@5: 100.0000 (97.0877)  time: 0.6557  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[1/5]  [200/313]  eta: 0:01:14  Lr: 0.001875  Loss: 0.4979  Acc@1: 87.5000 (82.3694)  Acc@5: 100.0000 (97.1393)  time: 0.6557  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[1/5]  [210/313]  eta: 0:01:07  Lr: 0.001875  Loss: 0.2137  Acc@1: 81.2500 (82.5533)  Acc@5: 100.0000 (97.1564)  time: 0.6558  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[1/5]  [220/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.2172  Acc@1: 87.5000 (82.7771)  Acc@5: 100.0000 (97.2285)  time: 0.6552  data: 0.0013  max mem: 2373\n",
            "Train: Epoch[1/5]  [230/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.2799  Acc@1: 87.5000 (83.0898)  Acc@5: 100.0000 (97.3214)  time: 0.6546  data: 0.0015  max mem: 2373\n",
            "Train: Epoch[1/5]  [240/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.5825  Acc@1: 87.5000 (83.1950)  Acc@5: 100.0000 (97.2770)  time: 0.6554  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[1/5]  [250/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.1364  Acc@1: 87.5000 (83.2918)  Acc@5: 100.0000 (97.3855)  time: 0.6544  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[1/5]  [260/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.3164  Acc@1: 87.5000 (83.3573)  Acc@5: 100.0000 (97.4617)  time: 0.6538  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[1/5]  [270/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.7098  Acc@1: 87.5000 (83.4871)  Acc@5: 100.0000 (97.5092)  time: 0.6546  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[1/5]  [280/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.3090  Acc@1: 87.5000 (83.5409)  Acc@5: 100.0000 (97.5979)  time: 0.6548  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[1/5]  [290/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.1412  Acc@1: 87.5000 (83.5481)  Acc@5: 100.0000 (97.6375)  time: 0.6549  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[1/5]  [300/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.1766  Acc@1: 87.5000 (83.6171)  Acc@5: 100.0000 (97.6537)  time: 0.6554  data: 0.0013  max mem: 2373\n",
            "Train: Epoch[1/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.3171  Acc@1: 87.5000 (83.6817)  Acc@5: 100.0000 (97.6889)  time: 0.6556  data: 0.0012  max mem: 2373\n",
            "Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.1933  Acc@1: 87.5000 (83.7000)  Acc@5: 100.0000 (97.7000)  time: 0.6391  data: 0.0012  max mem: 2373\n",
            "Train: Epoch[1/5] Total time: 0:03:25 (0.6552 s / it)\n",
            "Averaged stats: Lr: 0.001875  Loss: 0.1933  Acc@1: 87.5000 (83.7000)  Acc@5: 100.0000 (97.7000)\n",
            "Train: Epoch[2/5]  [  0/313]  eta: 0:03:53  Lr: 0.001875  Loss: 0.0767  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.7473  data: 0.1316  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 10/313]  eta: 0:03:21  Lr: 0.001875  Loss: -0.0243  Acc@1: 81.2500 (84.0909)  Acc@5: 100.0000 (98.8636)  time: 0.6651  data: 0.0140  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 20/313]  eta: 0:03:13  Lr: 0.001875  Loss: -0.0087  Acc@1: 81.2500 (84.5238)  Acc@5: 100.0000 (98.8095)  time: 0.6561  data: 0.0013  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 30/313]  eta: 0:03:06  Lr: 0.001875  Loss: -0.0219  Acc@1: 87.5000 (85.8871)  Acc@5: 100.0000 (98.1855)  time: 0.6552  data: 0.0009  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 40/313]  eta: 0:02:59  Lr: 0.001875  Loss: -0.0124  Acc@1: 87.5000 (85.9756)  Acc@5: 100.0000 (98.3232)  time: 0.6554  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 50/313]  eta: 0:02:52  Lr: 0.001875  Loss: 0.0623  Acc@1: 87.5000 (86.3971)  Acc@5: 100.0000 (98.5294)  time: 0.6549  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 60/313]  eta: 0:02:46  Lr: 0.001875  Loss: 0.3165  Acc@1: 87.5000 (86.1680)  Acc@5: 100.0000 (98.6680)  time: 0.6546  data: 0.0015  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 70/313]  eta: 0:02:39  Lr: 0.001875  Loss: 0.6761  Acc@1: 87.5000 (86.1796)  Acc@5: 100.0000 (98.5915)  time: 0.6552  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 80/313]  eta: 0:02:32  Lr: 0.001875  Loss: -0.0136  Acc@1: 87.5000 (86.2654)  Acc@5: 100.0000 (98.6111)  time: 0.6551  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 90/313]  eta: 0:02:26  Lr: 0.001875  Loss: -0.0710  Acc@1: 87.5000 (86.1264)  Acc@5: 100.0000 (98.6264)  time: 0.6548  data: 0.0030  max mem: 2373\n",
            "Train: Epoch[2/5]  [100/313]  eta: 0:02:19  Lr: 0.001875  Loss: 0.1727  Acc@1: 87.5000 (86.2005)  Acc@5: 100.0000 (98.6386)  time: 0.6550  data: 0.0036  max mem: 2373\n",
            "Train: Epoch[2/5]  [110/313]  eta: 0:02:13  Lr: 0.001875  Loss: 0.1631  Acc@1: 87.5000 (86.3739)  Acc@5: 100.0000 (98.7613)  time: 0.6555  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[2/5]  [120/313]  eta: 0:02:06  Lr: 0.001875  Loss: 0.1846  Acc@1: 87.5000 (86.6219)  Acc@5: 100.0000 (98.7087)  time: 0.6546  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[2/5]  [130/313]  eta: 0:02:00  Lr: 0.001875  Loss: -0.1259  Acc@1: 87.5000 (86.7844)  Acc@5: 100.0000 (98.7595)  time: 0.6543  data: 0.0027  max mem: 2373\n",
            "Train: Epoch[2/5]  [140/313]  eta: 0:01:53  Lr: 0.001875  Loss: 0.3358  Acc@1: 87.5000 (86.7021)  Acc@5: 100.0000 (98.7589)  time: 0.6543  data: 0.0026  max mem: 2373\n",
            "Train: Epoch[2/5]  [150/313]  eta: 0:01:46  Lr: 0.001875  Loss: 0.2304  Acc@1: 87.5000 (86.7136)  Acc@5: 100.0000 (98.8411)  time: 0.6537  data: 0.0027  max mem: 2373\n",
            "Train: Epoch[2/5]  [160/313]  eta: 0:01:40  Lr: 0.001875  Loss: 0.0954  Acc@1: 87.5000 (86.9565)  Acc@5: 100.0000 (98.8354)  time: 0.6544  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[2/5]  [170/313]  eta: 0:01:33  Lr: 0.001875  Loss: -0.0762  Acc@1: 93.7500 (87.1345)  Acc@5: 100.0000 (98.8670)  time: 0.6556  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[2/5]  [180/313]  eta: 0:01:27  Lr: 0.001875  Loss: 0.0749  Acc@1: 87.5000 (87.1202)  Acc@5: 100.0000 (98.8950)  time: 0.6554  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[2/5]  [190/313]  eta: 0:01:20  Lr: 0.001875  Loss: -0.1034  Acc@1: 87.5000 (87.4018)  Acc@5: 100.0000 (98.9202)  time: 0.6548  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[2/5]  [200/313]  eta: 0:01:14  Lr: 0.001875  Loss: 0.0727  Acc@1: 93.7500 (87.4378)  Acc@5: 100.0000 (98.8806)  time: 0.6545  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[2/5]  [210/313]  eta: 0:01:07  Lr: 0.001875  Loss: 0.3071  Acc@1: 87.5000 (87.4408)  Acc@5: 100.0000 (98.8448)  time: 0.6544  data: 0.0026  max mem: 2373\n",
            "Train: Epoch[2/5]  [220/313]  eta: 0:01:00  Lr: 0.001875  Loss: 0.1852  Acc@1: 87.5000 (87.4434)  Acc@5: 100.0000 (98.8688)  time: 0.6550  data: 0.0027  max mem: 2373\n",
            "Train: Epoch[2/5]  [230/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.0051  Acc@1: 87.5000 (87.4459)  Acc@5: 100.0000 (98.8636)  time: 0.6556  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[2/5]  [240/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.9839  Acc@1: 87.5000 (87.4222)  Acc@5: 100.0000 (98.8589)  time: 0.6561  data: 0.0014  max mem: 2373\n",
            "Train: Epoch[2/5]  [250/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.2613  Acc@1: 87.5000 (87.3755)  Acc@5: 100.0000 (98.9044)  time: 0.6559  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[2/5]  [260/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.0575  Acc@1: 87.5000 (87.4761)  Acc@5: 100.0000 (98.9464)  time: 0.6547  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[2/5]  [270/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.1984  Acc@1: 87.5000 (87.5231)  Acc@5: 100.0000 (98.9391)  time: 0.6551  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[2/5]  [280/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.1406  Acc@1: 87.5000 (87.4555)  Acc@5: 100.0000 (98.9324)  time: 0.6553  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[2/5]  [290/313]  eta: 0:00:15  Lr: 0.001875  Loss: -0.0245  Acc@1: 87.5000 (87.5215)  Acc@5: 100.0000 (98.9046)  time: 0.6555  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[2/5]  [300/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.1670  Acc@1: 87.5000 (87.4585)  Acc@5: 100.0000 (98.8995)  time: 0.6561  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[2/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.2402  Acc@1: 87.5000 (87.4397)  Acc@5: 100.0000 (98.9148)  time: 0.6550  data: 0.0028  max mem: 2373\n",
            "Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.0418  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.9200)  time: 0.6389  data: 0.0027  max mem: 2373\n",
            "Train: Epoch[2/5] Total time: 0:03:24 (0.6546 s / it)\n",
            "Averaged stats: Lr: 0.001875  Loss: -0.0418  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.9200)\n",
            "Train: Epoch[3/5]  [  0/313]  eta: 0:04:31  Lr: 0.001875  Loss: 0.0150  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.8672  data: 0.2526  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 10/313]  eta: 0:03:24  Lr: 0.001875  Loss: 0.4743  Acc@1: 87.5000 (88.0682)  Acc@5: 100.0000 (100.0000)  time: 0.6754  data: 0.0246  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 20/313]  eta: 0:03:15  Lr: 0.001875  Loss: 0.1608  Acc@1: 87.5000 (89.5833)  Acc@5: 100.0000 (100.0000)  time: 0.6559  data: 0.0011  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 30/313]  eta: 0:03:07  Lr: 0.001875  Loss: 0.1540  Acc@1: 87.5000 (89.1129)  Acc@5: 100.0000 (100.0000)  time: 0.6556  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 40/313]  eta: 0:03:00  Lr: 0.001875  Loss: -0.0909  Acc@1: 87.5000 (89.0244)  Acc@5: 100.0000 (99.0854)  time: 0.6556  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 50/313]  eta: 0:02:53  Lr: 0.001875  Loss: 0.1224  Acc@1: 93.7500 (89.3382)  Acc@5: 100.0000 (99.0196)  time: 0.6553  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 60/313]  eta: 0:02:46  Lr: 0.001875  Loss: 0.2184  Acc@1: 87.5000 (88.8320)  Acc@5: 100.0000 (99.1803)  time: 0.6552  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 70/313]  eta: 0:02:40  Lr: 0.001875  Loss: 0.0215  Acc@1: 81.2500 (87.8521)  Acc@5: 100.0000 (99.1197)  time: 0.6557  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 80/313]  eta: 0:02:33  Lr: 0.001875  Loss: -0.1783  Acc@1: 87.5000 (88.1173)  Acc@5: 100.0000 (99.1512)  time: 0.6563  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 90/313]  eta: 0:02:26  Lr: 0.001875  Loss: 0.3406  Acc@1: 93.7500 (88.1868)  Acc@5: 100.0000 (99.1758)  time: 0.6562  data: 0.0010  max mem: 2373\n",
            "Train: Epoch[3/5]  [100/313]  eta: 0:02:20  Lr: 0.001875  Loss: 0.1461  Acc@1: 87.5000 (88.2426)  Acc@5: 100.0000 (99.1955)  time: 0.6552  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[3/5]  [110/313]  eta: 0:02:13  Lr: 0.001875  Loss: 0.4978  Acc@1: 87.5000 (88.2883)  Acc@5: 100.0000 (99.1554)  time: 0.6543  data: 0.0027  max mem: 2373\n",
            "Train: Epoch[3/5]  [120/313]  eta: 0:02:06  Lr: 0.001875  Loss: -0.1859  Acc@1: 87.5000 (88.0165)  Acc@5: 100.0000 (99.0702)  time: 0.6538  data: 0.0027  max mem: 2373\n",
            "Train: Epoch[3/5]  [130/313]  eta: 0:02:00  Lr: 0.001875  Loss: 0.0716  Acc@1: 81.2500 (87.8340)  Acc@5: 100.0000 (99.0458)  time: 0.6547  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[3/5]  [140/313]  eta: 0:01:53  Lr: 0.001875  Loss: 0.3451  Acc@1: 87.5000 (87.7660)  Acc@5: 100.0000 (99.0691)  time: 0.6553  data: 0.0026  max mem: 2373\n",
            "Train: Epoch[3/5]  [150/313]  eta: 0:01:47  Lr: 0.001875  Loss: -0.0455  Acc@1: 87.5000 (87.7897)  Acc@5: 100.0000 (99.0066)  time: 0.6550  data: 0.0030  max mem: 2373\n",
            "Train: Epoch[3/5]  [160/313]  eta: 0:01:40  Lr: 0.001875  Loss: 0.0127  Acc@1: 87.5000 (87.8106)  Acc@5: 100.0000 (98.9907)  time: 0.6544  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[3/5]  [170/313]  eta: 0:01:33  Lr: 0.001875  Loss: 0.3931  Acc@1: 87.5000 (87.9020)  Acc@5: 100.0000 (99.0497)  time: 0.6546  data: 0.0010  max mem: 2373\n",
            "Train: Epoch[3/5]  [180/313]  eta: 0:01:27  Lr: 0.001875  Loss: 0.1275  Acc@1: 87.5000 (87.9489)  Acc@5: 100.0000 (99.0331)  time: 0.6554  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[3/5]  [190/313]  eta: 0:01:20  Lr: 0.001875  Loss: 0.2299  Acc@1: 87.5000 (87.9581)  Acc@5: 100.0000 (99.0183)  time: 0.6555  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[3/5]  [200/313]  eta: 0:01:14  Lr: 0.001875  Loss: 0.2658  Acc@1: 87.5000 (87.8731)  Acc@5: 100.0000 (98.9739)  time: 0.6560  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[3/5]  [210/313]  eta: 0:01:07  Lr: 0.001875  Loss: 0.1003  Acc@1: 87.5000 (87.9443)  Acc@5: 100.0000 (98.9633)  time: 0.6556  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[3/5]  [220/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.1980  Acc@1: 87.5000 (87.6697)  Acc@5: 100.0000 (98.8405)  time: 0.6552  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[3/5]  [230/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.2687  Acc@1: 87.5000 (87.6894)  Acc@5: 100.0000 (98.8366)  time: 0.6555  data: 0.0025  max mem: 2373\n",
            "Train: Epoch[3/5]  [240/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.0430  Acc@1: 87.5000 (87.6556)  Acc@5: 100.0000 (98.8330)  time: 0.6554  data: 0.0025  max mem: 2373\n",
            "Train: Epoch[3/5]  [250/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.0268  Acc@1: 87.5000 (87.6743)  Acc@5: 100.0000 (98.8795)  time: 0.6545  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[3/5]  [260/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.0367  Acc@1: 93.7500 (87.8592)  Acc@5: 100.0000 (98.8985)  time: 0.6547  data: 0.0025  max mem: 2373\n",
            "Train: Epoch[3/5]  [270/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.3493  Acc@1: 93.7500 (87.8921)  Acc@5: 100.0000 (98.8699)  time: 0.6549  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[3/5]  [280/313]  eta: 0:00:21  Lr: 0.001875  Loss: -0.0925  Acc@1: 93.7500 (88.0338)  Acc@5: 100.0000 (98.8879)  time: 0.6542  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[3/5]  [290/313]  eta: 0:00:15  Lr: 0.001875  Loss: -0.0761  Acc@1: 93.7500 (88.1658)  Acc@5: 100.0000 (98.8617)  time: 0.6533  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[3/5]  [300/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.1289  Acc@1: 87.5000 (88.1229)  Acc@5: 100.0000 (98.8787)  time: 0.6524  data: 0.0012  max mem: 2373\n",
            "Train: Epoch[3/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.3593  Acc@1: 87.5000 (88.1230)  Acc@5: 100.0000 (98.8947)  time: 0.6526  data: 0.0012  max mem: 2373\n",
            "Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1630  Acc@1: 87.5000 (88.1600)  Acc@5: 100.0000 (98.9000)  time: 0.6369  data: 0.0012  max mem: 2373\n",
            "Train: Epoch[3/5] Total time: 0:03:24 (0.6548 s / it)\n",
            "Averaged stats: Lr: 0.001875  Loss: -0.1630  Acc@1: 87.5000 (88.1600)  Acc@5: 100.0000 (98.9000)\n",
            "Train: Epoch[4/5]  [  0/313]  eta: 0:03:59  Lr: 0.001875  Loss: 0.0114  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.7653  data: 0.1517  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 10/313]  eta: 0:03:21  Lr: 0.001875  Loss: -0.0268  Acc@1: 93.7500 (90.3409)  Acc@5: 100.0000 (98.8636)  time: 0.6646  data: 0.0157  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 20/313]  eta: 0:03:13  Lr: 0.001875  Loss: 0.0954  Acc@1: 93.7500 (89.5833)  Acc@5: 100.0000 (98.8095)  time: 0.6539  data: 0.0013  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 30/313]  eta: 0:03:06  Lr: 0.001875  Loss: -0.0932  Acc@1: 87.5000 (89.5161)  Acc@5: 100.0000 (99.1935)  time: 0.6536  data: 0.0013  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 40/313]  eta: 0:02:59  Lr: 0.001875  Loss: 0.4448  Acc@1: 87.5000 (88.5671)  Acc@5: 100.0000 (98.9329)  time: 0.6539  data: 0.0014  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 50/313]  eta: 0:02:52  Lr: 0.001875  Loss: 0.1920  Acc@1: 87.5000 (88.6029)  Acc@5: 100.0000 (98.4069)  time: 0.6542  data: 0.0015  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 60/313]  eta: 0:02:45  Lr: 0.001875  Loss: -0.0056  Acc@1: 87.5000 (88.5246)  Acc@5: 100.0000 (98.2582)  time: 0.6543  data: 0.0013  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 70/313]  eta: 0:02:39  Lr: 0.001875  Loss: -0.1693  Acc@1: 87.5000 (88.8204)  Acc@5: 100.0000 (98.3275)  time: 0.6542  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 80/313]  eta: 0:02:32  Lr: 0.001875  Loss: 0.0005  Acc@1: 93.7500 (89.3519)  Acc@5: 100.0000 (98.3796)  time: 0.6549  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 90/313]  eta: 0:02:26  Lr: 0.001875  Loss: 0.3262  Acc@1: 87.5000 (89.0797)  Acc@5: 100.0000 (98.4890)  time: 0.6553  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[4/5]  [100/313]  eta: 0:02:19  Lr: 0.001875  Loss: -0.1449  Acc@1: 87.5000 (89.2946)  Acc@5: 100.0000 (98.5767)  time: 0.6552  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[4/5]  [110/313]  eta: 0:02:13  Lr: 0.001875  Loss: 0.2954  Acc@1: 87.5000 (89.2455)  Acc@5: 100.0000 (98.5923)  time: 0.6545  data: 0.0027  max mem: 2373\n",
            "Train: Epoch[4/5]  [120/313]  eta: 0:02:06  Lr: 0.001875  Loss: 0.3825  Acc@1: 87.5000 (89.1012)  Acc@5: 100.0000 (98.6054)  time: 0.6545  data: 0.0026  max mem: 2373\n",
            "Train: Epoch[4/5]  [130/313]  eta: 0:01:59  Lr: 0.001875  Loss: -0.0421  Acc@1: 87.5000 (89.1698)  Acc@5: 100.0000 (98.6641)  time: 0.6546  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[4/5]  [140/313]  eta: 0:01:53  Lr: 0.001875  Loss: -0.1487  Acc@1: 93.7500 (89.1844)  Acc@5: 100.0000 (98.7145)  time: 0.6533  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[4/5]  [150/313]  eta: 0:01:46  Lr: 0.001875  Loss: 0.3354  Acc@1: 93.7500 (89.2798)  Acc@5: 100.0000 (98.7997)  time: 0.6533  data: 0.0015  max mem: 2373\n",
            "Train: Epoch[4/5]  [160/313]  eta: 0:01:40  Lr: 0.001875  Loss: 0.0398  Acc@1: 87.5000 (89.1304)  Acc@5: 100.0000 (98.7966)  time: 0.6535  data: 0.0015  max mem: 2373\n",
            "Train: Epoch[4/5]  [170/313]  eta: 0:01:33  Lr: 0.001875  Loss: -0.2024  Acc@1: 93.7500 (89.3640)  Acc@5: 100.0000 (98.8670)  time: 0.6526  data: 0.0013  max mem: 2373\n",
            "Train: Epoch[4/5]  [180/313]  eta: 0:01:27  Lr: 0.001875  Loss: -0.1564  Acc@1: 87.5000 (89.1575)  Acc@5: 100.0000 (98.8605)  time: 0.6530  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[4/5]  [190/313]  eta: 0:01:20  Lr: 0.001875  Loss: -0.1793  Acc@1: 87.5000 (89.1688)  Acc@5: 100.0000 (98.9202)  time: 0.6544  data: 0.0015  max mem: 2373\n",
            "Train: Epoch[4/5]  [200/313]  eta: 0:01:13  Lr: 0.001875  Loss: -0.0219  Acc@1: 87.5000 (89.1791)  Acc@5: 100.0000 (98.9739)  time: 0.6553  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[4/5]  [210/313]  eta: 0:01:07  Lr: 0.001875  Loss: 0.0477  Acc@1: 93.7500 (89.3957)  Acc@5: 100.0000 (98.9929)  time: 0.6549  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[4/5]  [220/313]  eta: 0:01:00  Lr: 0.001875  Loss: 0.2293  Acc@1: 93.7500 (89.3382)  Acc@5: 100.0000 (98.9536)  time: 0.6548  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[4/5]  [230/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.0433  Acc@1: 87.5000 (89.2316)  Acc@5: 100.0000 (98.9177)  time: 0.6556  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[4/5]  [240/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.1438  Acc@1: 87.5000 (89.2894)  Acc@5: 100.0000 (98.9108)  time: 0.6550  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[4/5]  [250/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.1617  Acc@1: 87.5000 (89.2430)  Acc@5: 100.0000 (98.9542)  time: 0.6551  data: 0.0015  max mem: 2373\n",
            "Train: Epoch[4/5]  [260/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.0434  Acc@1: 87.5000 (89.3439)  Acc@5: 100.0000 (98.9703)  time: 0.6559  data: 0.0013  max mem: 2373\n",
            "Train: Epoch[4/5]  [270/313]  eta: 0:00:28  Lr: 0.001875  Loss: -0.1841  Acc@1: 93.7500 (89.4603)  Acc@5: 100.0000 (98.9852)  time: 0.6561  data: 0.0014  max mem: 2373\n",
            "Train: Epoch[4/5]  [280/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.1138  Acc@1: 93.7500 (89.5463)  Acc@5: 100.0000 (98.9769)  time: 0.6564  data: 0.0013  max mem: 2373\n",
            "Train: Epoch[4/5]  [290/313]  eta: 0:00:15  Lr: 0.001875  Loss: -0.1868  Acc@1: 93.7500 (89.6048)  Acc@5: 100.0000 (98.9691)  time: 0.6566  data: 0.0014  max mem: 2373\n",
            "Train: Epoch[4/5]  [300/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.3418  Acc@1: 87.5000 (89.5141)  Acc@5: 100.0000 (98.9826)  time: 0.6565  data: 0.0015  max mem: 2373\n",
            "Train: Epoch[4/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.3392  Acc@1: 87.5000 (89.3891)  Acc@5: 100.0000 (98.9751)  time: 0.6562  data: 0.0013  max mem: 2373\n",
            "Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.0055  Acc@1: 87.5000 (89.4000)  Acc@5: 100.0000 (98.9800)  time: 0.6404  data: 0.0010  max mem: 2373\n",
            "Train: Epoch[4/5] Total time: 0:03:24 (0.6545 s / it)\n",
            "Averaged stats: Lr: 0.001875  Loss: 0.0055  Acc@1: 87.5000 (89.4000)  Acc@5: 100.0000 (98.9800)\n",
            "Train: Epoch[5/5]  [  0/313]  eta: 0:04:46  Lr: 0.001875  Loss: -0.1354  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.9164  data: 0.3018  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 10/313]  eta: 0:03:26  Lr: 0.001875  Loss: 0.0798  Acc@1: 93.7500 (90.9091)  Acc@5: 100.0000 (99.4318)  time: 0.6807  data: 0.0292  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 20/313]  eta: 0:03:15  Lr: 0.001875  Loss: 0.0811  Acc@1: 93.7500 (91.0714)  Acc@5: 100.0000 (99.4048)  time: 0.6565  data: 0.0012  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 30/313]  eta: 0:03:08  Lr: 0.001875  Loss: 0.0166  Acc@1: 87.5000 (90.5242)  Acc@5: 100.0000 (99.3952)  time: 0.6561  data: 0.0010  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 40/313]  eta: 0:03:00  Lr: 0.001875  Loss: -0.0820  Acc@1: 87.5000 (91.0061)  Acc@5: 100.0000 (99.3902)  time: 0.6562  data: 0.0014  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 50/313]  eta: 0:02:53  Lr: 0.001875  Loss: 0.6920  Acc@1: 87.5000 (89.5833)  Acc@5: 100.0000 (99.2647)  time: 0.6565  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 60/313]  eta: 0:02:47  Lr: 0.001875  Loss: 0.1062  Acc@1: 87.5000 (89.8566)  Acc@5: 100.0000 (99.2828)  time: 0.6563  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 70/313]  eta: 0:02:40  Lr: 0.001875  Loss: 0.5238  Acc@1: 93.7500 (89.7007)  Acc@5: 100.0000 (99.1197)  time: 0.6562  data: 0.0029  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 80/313]  eta: 0:02:33  Lr: 0.001875  Loss: 0.2936  Acc@1: 87.5000 (89.8920)  Acc@5: 100.0000 (99.2284)  time: 0.6569  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 90/313]  eta: 0:02:27  Lr: 0.001875  Loss: 0.1615  Acc@1: 87.5000 (89.6978)  Acc@5: 100.0000 (99.2445)  time: 0.6571  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[5/5]  [100/313]  eta: 0:02:20  Lr: 0.001875  Loss: 0.0207  Acc@1: 87.5000 (89.6658)  Acc@5: 100.0000 (99.3193)  time: 0.6573  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[5/5]  [110/313]  eta: 0:02:13  Lr: 0.001875  Loss: 0.3219  Acc@1: 93.7500 (89.4144)  Acc@5: 100.0000 (99.2680)  time: 0.6577  data: 0.0026  max mem: 2373\n",
            "Train: Epoch[5/5]  [120/313]  eta: 0:02:07  Lr: 0.001875  Loss: 0.0086  Acc@1: 87.5000 (89.4628)  Acc@5: 100.0000 (99.2769)  time: 0.6579  data: 0.0025  max mem: 2373\n",
            "Train: Epoch[5/5]  [130/313]  eta: 0:02:00  Lr: 0.001875  Loss: -0.0577  Acc@1: 87.5000 (89.4561)  Acc@5: 100.0000 (99.2844)  time: 0.6577  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[5/5]  [140/313]  eta: 0:01:53  Lr: 0.001875  Loss: 0.1009  Acc@1: 87.5000 (89.1844)  Acc@5: 100.0000 (99.2465)  time: 0.6579  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[5/5]  [150/313]  eta: 0:01:47  Lr: 0.001875  Loss: -0.0346  Acc@1: 87.5000 (89.2798)  Acc@5: 100.0000 (99.1722)  time: 0.6586  data: 0.0029  max mem: 2373\n",
            "Train: Epoch[5/5]  [160/313]  eta: 0:01:40  Lr: 0.001875  Loss: 0.2305  Acc@1: 93.7500 (89.3634)  Acc@5: 100.0000 (99.1460)  time: 0.6578  data: 0.0029  max mem: 2373\n",
            "Train: Epoch[5/5]  [170/313]  eta: 0:01:34  Lr: 0.001875  Loss: -0.2042  Acc@1: 93.7500 (89.3275)  Acc@5: 100.0000 (99.1594)  time: 0.6570  data: 0.0012  max mem: 2373\n",
            "Train: Epoch[5/5]  [180/313]  eta: 0:01:27  Lr: 0.001875  Loss: 0.4390  Acc@1: 87.5000 (89.2610)  Acc@5: 100.0000 (99.1022)  time: 0.6573  data: 0.0011  max mem: 2373\n",
            "Train: Epoch[5/5]  [190/313]  eta: 0:01:20  Lr: 0.001875  Loss: 0.1610  Acc@1: 87.5000 (89.2997)  Acc@5: 100.0000 (99.0838)  time: 0.6575  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[5/5]  [200/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.1260  Acc@1: 93.7500 (89.6455)  Acc@5: 100.0000 (99.0983)  time: 0.6571  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[5/5]  [210/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.1498  Acc@1: 93.7500 (89.6919)  Acc@5: 100.0000 (99.1410)  time: 0.6571  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[5/5]  [220/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.2331  Acc@1: 87.5000 (89.7342)  Acc@5: 100.0000 (99.0950)  time: 0.6572  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[5/5]  [230/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.2468  Acc@1: 87.5000 (89.8810)  Acc@5: 100.0000 (99.1342)  time: 0.6570  data: 0.0014  max mem: 2373\n",
            "Train: Epoch[5/5]  [240/313]  eta: 0:00:48  Lr: 0.001875  Loss: -0.0641  Acc@1: 87.5000 (89.9637)  Acc@5: 100.0000 (99.1701)  time: 0.6570  data: 0.0014  max mem: 2373\n",
            "Train: Epoch[5/5]  [250/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.0556  Acc@1: 93.7500 (89.8406)  Acc@5: 100.0000 (99.1285)  time: 0.6563  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[5/5]  [260/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.0178  Acc@1: 93.7500 (89.9186)  Acc@5: 100.0000 (99.1379)  time: 0.6562  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[5/5]  [270/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.0119  Acc@1: 87.5000 (89.8985)  Acc@5: 100.0000 (99.0775)  time: 0.6565  data: 0.0015  max mem: 2373\n",
            "Train: Epoch[5/5]  [280/313]  eta: 0:00:21  Lr: 0.001875  Loss: -0.0102  Acc@1: 93.7500 (90.0801)  Acc@5: 100.0000 (99.0881)  time: 0.6564  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[5/5]  [290/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.0435  Acc@1: 87.5000 (89.6692)  Acc@5: 100.0000 (99.0335)  time: 0.6562  data: 0.0026  max mem: 2373\n",
            "Train: Epoch[5/5]  [300/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.5280  Acc@1: 87.5000 (89.7218)  Acc@5: 100.0000 (99.0241)  time: 0.6565  data: 0.0026  max mem: 2373\n",
            "Train: Epoch[5/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.3788  Acc@1: 87.5000 (89.6302)  Acc@5: 100.0000 (99.0153)  time: 0.6573  data: 0.0008  max mem: 2373\n",
            "Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.0811  Acc@1: 93.7500 (89.6800)  Acc@5: 100.0000 (99.0200)  time: 0.6410  data: 0.0003  max mem: 2373\n",
            "Train: Epoch[5/5] Total time: 0:03:25 (0.6571 s / it)\n",
            "Averaged stats: Lr: 0.001875  Loss: -0.0811  Acc@1: 93.7500 (89.6800)  Acc@5: 100.0000 (99.0200)\n",
            "Test: [Task 1]  [ 0/63]  eta: 0:00:41  Loss: 0.7991 (0.7991)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.6632  data: 0.2714  max mem: 2373\n",
            "Test: [Task 1]  [10/63]  eta: 0:00:23  Loss: 0.6373 (0.6150)  Acc@1: 81.2500 (86.9318)  Acc@5: 100.0000 (98.2955)  time: 0.4490  data: 0.0250  max mem: 2373\n",
            "Test: [Task 1]  [20/63]  eta: 0:00:18  Loss: 0.6373 (0.6798)  Acc@1: 81.2500 (84.5238)  Acc@5: 100.0000 (97.9167)  time: 0.4277  data: 0.0005  max mem: 2373\n",
            "Test: [Task 1]  [30/63]  eta: 0:00:14  Loss: 0.6374 (0.6643)  Acc@1: 81.2500 (84.4758)  Acc@5: 100.0000 (98.1855)  time: 0.4272  data: 0.0028  max mem: 2373\n",
            "Test: [Task 1]  [40/63]  eta: 0:00:09  Loss: 0.5957 (0.6399)  Acc@1: 81.2500 (84.7561)  Acc@5: 100.0000 (98.6280)  time: 0.4271  data: 0.0033  max mem: 2373\n",
            "Test: [Task 1]  [50/63]  eta: 0:00:05  Loss: 0.5439 (0.6214)  Acc@1: 87.5000 (85.4167)  Acc@5: 100.0000 (98.7745)  time: 0.4274  data: 0.0010  max mem: 2373\n",
            "Test: [Task 1]  [60/63]  eta: 0:00:01  Loss: 0.5439 (0.6058)  Acc@1: 93.7500 (86.4754)  Acc@5: 100.0000 (98.7705)  time: 0.4275  data: 0.0004  max mem: 2373\n",
            "Test: [Task 1]  [62/63]  eta: 0:00:00  Loss: 0.4947 (0.6030)  Acc@1: 93.7500 (86.7000)  Acc@5: 100.0000 (98.8000)  time: 0.4169  data: 0.0004  max mem: 2373\n",
            "Test: [Task 1] Total time: 0:00:27 (0.4289 s / it)\n",
            "* Acc@1 86.700 Acc@5 98.800 loss 0.603\n",
            "Test: [Task 2]  [ 0/63]  eta: 0:00:46  Loss: 0.9417 (0.9417)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.7343  data: 0.3417  max mem: 2373\n",
            "Test: [Task 2]  [10/63]  eta: 0:00:24  Loss: 0.7273 (0.7699)  Acc@1: 87.5000 (85.7955)  Acc@5: 100.0000 (96.0227)  time: 0.4551  data: 0.0316  max mem: 2373\n",
            "Test: [Task 2]  [20/63]  eta: 0:00:19  Loss: 0.8372 (0.8144)  Acc@1: 87.5000 (84.2262)  Acc@5: 100.0000 (95.8333)  time: 0.4274  data: 0.0006  max mem: 2373\n",
            "Test: [Task 2]  [30/63]  eta: 0:00:14  Loss: 0.7828 (0.7972)  Acc@1: 81.2500 (83.8710)  Acc@5: 93.7500 (95.3629)  time: 0.4265  data: 0.0026  max mem: 2373\n",
            "Test: [Task 2]  [40/63]  eta: 0:00:09  Loss: 0.7592 (0.7801)  Acc@1: 87.5000 (83.9939)  Acc@5: 100.0000 (96.0366)  time: 0.4259  data: 0.0032  max mem: 2373\n",
            "Test: [Task 2]  [50/63]  eta: 0:00:05  Loss: 0.6460 (0.7742)  Acc@1: 81.2500 (83.2108)  Acc@5: 100.0000 (96.3235)  time: 0.4262  data: 0.0011  max mem: 2373\n",
            "Test: [Task 2]  [60/63]  eta: 0:00:01  Loss: 0.6110 (0.7549)  Acc@1: 81.2500 (83.7090)  Acc@5: 100.0000 (96.8238)  time: 0.4255  data: 0.0005  max mem: 2373\n",
            "Test: [Task 2]  [62/63]  eta: 0:00:00  Loss: 0.6110 (0.7452)  Acc@1: 81.2500 (83.8000)  Acc@5: 100.0000 (96.9000)  time: 0.4148  data: 0.0004  max mem: 2373\n",
            "Test: [Task 2] Total time: 0:00:27 (0.4290 s / it)\n",
            "* Acc@1 83.800 Acc@5 96.900 loss 0.745\n",
            "Test: [Task 3]  [ 0/63]  eta: 0:00:45  Loss: 0.5106 (0.5106)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.7155  data: 0.3226  max mem: 2373\n",
            "Test: [Task 3]  [10/63]  eta: 0:00:23  Loss: 0.6560 (0.6365)  Acc@1: 81.2500 (82.3864)  Acc@5: 100.0000 (97.7273)  time: 0.4519  data: 0.0300  max mem: 2373\n",
            "Test: [Task 3]  [20/63]  eta: 0:00:18  Loss: 0.6763 (0.6584)  Acc@1: 81.2500 (82.4405)  Acc@5: 100.0000 (97.3214)  time: 0.4264  data: 0.0006  max mem: 2373\n",
            "Test: [Task 3]  [30/63]  eta: 0:00:14  Loss: 0.6680 (0.6580)  Acc@1: 81.2500 (81.4516)  Acc@5: 100.0000 (97.9839)  time: 0.4263  data: 0.0020  max mem: 2373\n",
            "Test: [Task 3]  [40/63]  eta: 0:00:09  Loss: 0.5526 (0.6460)  Acc@1: 81.2500 (82.1646)  Acc@5: 100.0000 (98.1707)  time: 0.4254  data: 0.0030  max mem: 2373\n",
            "Test: [Task 3]  [50/63]  eta: 0:00:05  Loss: 0.6975 (0.6588)  Acc@1: 87.5000 (82.9657)  Acc@5: 100.0000 (97.9167)  time: 0.4257  data: 0.0015  max mem: 2373\n",
            "Test: [Task 3]  [60/63]  eta: 0:00:01  Loss: 0.7014 (0.6755)  Acc@1: 81.2500 (82.5820)  Acc@5: 100.0000 (97.8484)  time: 0.4256  data: 0.0004  max mem: 2373\n",
            "Test: [Task 3]  [62/63]  eta: 0:00:00  Loss: 0.7014 (0.6727)  Acc@1: 81.2500 (82.7000)  Acc@5: 93.7500 (97.8000)  time: 0.4151  data: 0.0004  max mem: 2373\n",
            "Test: [Task 3] Total time: 0:00:26 (0.4283 s / it)\n",
            "* Acc@1 82.700 Acc@5 97.800 loss 0.673\n",
            "Test: [Task 4]  [ 0/63]  eta: 0:00:47  Loss: 0.7177 (0.7177)  Acc@1: 93.7500 (93.7500)  Acc@5: 93.7500 (93.7500)  time: 0.7588  data: 0.3601  max mem: 2373\n",
            "Test: [Task 4]  [10/63]  eta: 0:00:24  Loss: 0.7177 (0.6992)  Acc@1: 87.5000 (86.9318)  Acc@5: 93.7500 (96.0227)  time: 0.4562  data: 0.0338  max mem: 2373\n",
            "Test: [Task 4]  [20/63]  eta: 0:00:18  Loss: 0.6719 (0.6962)  Acc@1: 81.2500 (83.6310)  Acc@5: 93.7500 (96.1310)  time: 0.4257  data: 0.0008  max mem: 2373\n",
            "Test: [Task 4]  [30/63]  eta: 0:00:14  Loss: 0.5766 (0.6755)  Acc@1: 81.2500 (84.0726)  Acc@5: 93.7500 (96.3710)  time: 0.4257  data: 0.0012  max mem: 2373\n",
            "Test: [Task 4]  [40/63]  eta: 0:00:09  Loss: 0.4735 (0.6222)  Acc@1: 87.5000 (85.8232)  Acc@5: 100.0000 (97.1037)  time: 0.4247  data: 0.0017  max mem: 2373\n",
            "Test: [Task 4]  [50/63]  eta: 0:00:05  Loss: 0.5472 (0.6464)  Acc@1: 87.5000 (86.0294)  Acc@5: 100.0000 (96.9363)  time: 0.4241  data: 0.0010  max mem: 2373\n",
            "Test: [Task 4]  [60/63]  eta: 0:00:01  Loss: 0.6785 (0.6549)  Acc@1: 87.5000 (85.6557)  Acc@5: 100.0000 (96.8238)  time: 0.4249  data: 0.0004  max mem: 2373\n",
            "Test: [Task 4]  [62/63]  eta: 0:00:00  Loss: 0.6090 (0.6540)  Acc@1: 87.5000 (85.7000)  Acc@5: 100.0000 (96.9000)  time: 0.4143  data: 0.0003  max mem: 2373\n",
            "Test: [Task 4] Total time: 0:00:26 (0.4285 s / it)\n",
            "* Acc@1 85.700 Acc@5 96.900 loss 0.654\n",
            "Test: [Task 5]  [ 0/63]  eta: 0:00:52  Loss: 0.2762 (0.2762)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.8363  data: 0.4406  max mem: 2373\n",
            "Test: [Task 5]  [10/63]  eta: 0:00:24  Loss: 0.5075 (0.6060)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (97.7273)  time: 0.4639  data: 0.0421  max mem: 2373\n",
            "Test: [Task 5]  [20/63]  eta: 0:00:19  Loss: 0.5075 (0.5494)  Acc@1: 93.7500 (90.1786)  Acc@5: 100.0000 (97.3214)  time: 0.4272  data: 0.0014  max mem: 2373\n",
            "Test: [Task 5]  [30/63]  eta: 0:00:14  Loss: 0.4524 (0.5395)  Acc@1: 93.7500 (90.1210)  Acc@5: 100.0000 (97.7823)  time: 0.4266  data: 0.0029  max mem: 2373\n",
            "Test: [Task 5]  [40/63]  eta: 0:00:10  Loss: 0.4345 (0.5170)  Acc@1: 93.7500 (91.0061)  Acc@5: 100.0000 (97.8659)  time: 0.4261  data: 0.0054  max mem: 2373\n",
            "Test: [Task 5]  [50/63]  eta: 0:00:05  Loss: 0.5563 (0.5206)  Acc@1: 93.7500 (91.0539)  Acc@5: 100.0000 (97.9167)  time: 0.4265  data: 0.0032  max mem: 2373\n",
            "Test: [Task 5]  [60/63]  eta: 0:00:01  Loss: 0.5514 (0.5254)  Acc@1: 87.5000 (90.2664)  Acc@5: 100.0000 (97.8484)  time: 0.4259  data: 0.0007  max mem: 2373\n",
            "Test: [Task 5]  [62/63]  eta: 0:00:00  Loss: 0.5563 (0.5440)  Acc@1: 87.5000 (89.7000)  Acc@5: 100.0000 (97.7000)  time: 0.4150  data: 0.0005  max mem: 2373\n",
            "Test: [Task 5] Total time: 0:00:27 (0.4306 s / it)\n",
            "* Acc@1 89.700 Acc@5 97.700 loss 0.544\n",
            "Test: [Task 6]  [ 0/63]  eta: 0:00:48  Loss: 0.6734 (0.6734)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.7704  data: 0.3720  max mem: 2373\n",
            "Test: [Task 6]  [10/63]  eta: 0:00:24  Loss: 0.7371 (0.7495)  Acc@1: 81.2500 (81.8182)  Acc@5: 93.7500 (96.0227)  time: 0.4570  data: 0.0347  max mem: 2373\n",
            "Test: [Task 6]  [20/63]  eta: 0:00:19  Loss: 0.7725 (0.7837)  Acc@1: 81.2500 (80.0595)  Acc@5: 100.0000 (97.0238)  time: 0.4265  data: 0.0009  max mem: 2373\n",
            "Test: [Task 6]  [30/63]  eta: 0:00:14  Loss: 0.6576 (0.7607)  Acc@1: 81.2500 (80.4435)  Acc@5: 100.0000 (97.5806)  time: 0.4271  data: 0.0012  max mem: 2373\n",
            "Test: [Task 6]  [40/63]  eta: 0:00:09  Loss: 0.7239 (0.8041)  Acc@1: 75.0000 (78.5061)  Acc@5: 100.0000 (97.2561)  time: 0.4259  data: 0.0027  max mem: 2373\n",
            "Test: [Task 6]  [50/63]  eta: 0:00:05  Loss: 0.8299 (0.7893)  Acc@1: 75.0000 (79.0441)  Acc@5: 100.0000 (97.4265)  time: 0.4257  data: 0.0021  max mem: 2373\n",
            "Test: [Task 6]  [60/63]  eta: 0:00:01  Loss: 0.7684 (0.8031)  Acc@1: 81.2500 (79.2008)  Acc@5: 100.0000 (97.2336)  time: 0.4266  data: 0.0004  max mem: 2373\n",
            "Test: [Task 6]  [62/63]  eta: 0:00:00  Loss: 0.7684 (0.8014)  Acc@1: 81.2500 (79.4000)  Acc@5: 100.0000 (97.3000)  time: 0.4159  data: 0.0003  max mem: 2373\n",
            "Test: [Task 6] Total time: 0:00:27 (0.4297 s / it)\n",
            "* Acc@1 79.400 Acc@5 97.300 loss 0.801\n",
            "Test: [Task 7]  [ 0/63]  eta: 0:00:46  Loss: 0.5926 (0.5926)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.7324  data: 0.3414  max mem: 2373\n",
            "Test: [Task 7]  [10/63]  eta: 0:00:24  Loss: 0.5044 (0.5064)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.8636)  time: 0.4550  data: 0.0327  max mem: 2373\n",
            "Test: [Task 7]  [20/63]  eta: 0:00:19  Loss: 0.5044 (0.5707)  Acc@1: 87.5000 (87.2024)  Acc@5: 100.0000 (97.0238)  time: 0.4277  data: 0.0012  max mem: 2373\n",
            "Test: [Task 7]  [30/63]  eta: 0:00:14  Loss: 0.5234 (0.5695)  Acc@1: 87.5000 (87.0968)  Acc@5: 100.0000 (97.3790)  time: 0.4268  data: 0.0017  max mem: 2373\n",
            "Test: [Task 7]  [40/63]  eta: 0:00:09  Loss: 0.4672 (0.5600)  Acc@1: 87.5000 (87.8049)  Acc@5: 100.0000 (97.5610)  time: 0.4258  data: 0.0026  max mem: 2373\n",
            "Test: [Task 7]  [50/63]  eta: 0:00:05  Loss: 0.5646 (0.5793)  Acc@1: 87.5000 (87.1324)  Acc@5: 100.0000 (97.3039)  time: 0.4258  data: 0.0015  max mem: 2373\n",
            "Test: [Task 7]  [60/63]  eta: 0:00:01  Loss: 0.4782 (0.5635)  Acc@1: 87.5000 (87.8074)  Acc@5: 100.0000 (97.5410)  time: 0.4258  data: 0.0004  max mem: 2373\n",
            "Test: [Task 7]  [62/63]  eta: 0:00:00  Loss: 0.5646 (0.5615)  Acc@1: 87.5000 (87.8000)  Acc@5: 100.0000 (97.6000)  time: 0.4156  data: 0.0004  max mem: 2373\n",
            "Test: [Task 7] Total time: 0:00:27 (0.4296 s / it)\n",
            "* Acc@1 87.800 Acc@5 97.600 loss 0.562\n",
            "[Average accuracy till task7]\tAcc@1: 85.1143\tAcc@5: 97.5714\tLoss: 0.6545\tForgetting: 6.3667\tBackward: -6.1667\n",
            "Train: Epoch[1/5]  [  0/313]  eta: 0:04:56  Lr: 0.001875  Loss: 2.0742  Acc@1: 6.2500 (6.2500)  Acc@5: 62.5000 (62.5000)  time: 0.9477  data: 0.3346  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 10/313]  eta: 0:03:27  Lr: 0.001875  Loss: 1.5789  Acc@1: 62.5000 (55.6818)  Acc@5: 81.2500 (81.8182)  time: 0.6834  data: 0.0313  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 20/313]  eta: 0:03:16  Lr: 0.001875  Loss: 1.1812  Acc@1: 68.7500 (65.1786)  Acc@5: 87.5000 (86.9048)  time: 0.6565  data: 0.0009  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 30/313]  eta: 0:03:08  Lr: 0.001875  Loss: 1.0225  Acc@1: 81.2500 (70.1613)  Acc@5: 100.0000 (89.7177)  time: 0.6562  data: 0.0007  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 40/313]  eta: 0:03:01  Lr: 0.001875  Loss: 1.0051  Acc@1: 81.2500 (72.8659)  Acc@5: 93.7500 (91.0061)  time: 0.6570  data: 0.0010  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 50/313]  eta: 0:02:54  Lr: 0.001875  Loss: 0.5567  Acc@1: 81.2500 (75.3676)  Acc@5: 100.0000 (92.4020)  time: 0.6577  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 60/313]  eta: 0:02:47  Lr: 0.001875  Loss: 0.3655  Acc@1: 81.2500 (76.8443)  Acc@5: 100.0000 (93.3402)  time: 0.6581  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 70/313]  eta: 0:02:40  Lr: 0.001875  Loss: 0.3399  Acc@1: 87.5000 (78.3451)  Acc@5: 100.0000 (93.8380)  time: 0.6581  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 80/313]  eta: 0:02:33  Lr: 0.001875  Loss: 0.5762  Acc@1: 87.5000 (79.0123)  Acc@5: 100.0000 (94.0586)  time: 0.6576  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 90/313]  eta: 0:02:27  Lr: 0.001875  Loss: 0.1684  Acc@1: 81.2500 (79.8077)  Acc@5: 100.0000 (94.5742)  time: 0.6577  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[1/5]  [100/313]  eta: 0:02:20  Lr: 0.001875  Loss: 0.3846  Acc@1: 87.5000 (80.7550)  Acc@5: 100.0000 (94.9876)  time: 0.6580  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[1/5]  [110/313]  eta: 0:02:13  Lr: 0.001875  Loss: 0.3929  Acc@1: 87.5000 (81.0811)  Acc@5: 100.0000 (95.2703)  time: 0.6574  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[1/5]  [120/313]  eta: 0:02:07  Lr: 0.001875  Loss: 0.3254  Acc@1: 87.5000 (81.3533)  Acc@5: 100.0000 (95.4545)  time: 0.6564  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[1/5]  [130/313]  eta: 0:02:00  Lr: 0.001875  Loss: 0.5113  Acc@1: 87.5000 (81.5840)  Acc@5: 100.0000 (95.6107)  time: 0.6561  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[1/5]  [140/313]  eta: 0:01:54  Lr: 0.001875  Loss: 0.4463  Acc@1: 87.5000 (81.8262)  Acc@5: 100.0000 (95.7890)  time: 0.6569  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[1/5]  [150/313]  eta: 0:01:47  Lr: 0.001875  Loss: 0.3232  Acc@1: 87.5000 (82.3262)  Acc@5: 100.0000 (95.8609)  time: 0.6571  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[1/5]  [160/313]  eta: 0:01:40  Lr: 0.001875  Loss: 0.2125  Acc@1: 87.5000 (82.8416)  Acc@5: 100.0000 (96.0792)  time: 0.6569  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[1/5]  [170/313]  eta: 0:01:34  Lr: 0.001875  Loss: 0.2080  Acc@1: 87.5000 (83.1140)  Acc@5: 100.0000 (96.2354)  time: 0.6564  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[1/5]  [180/313]  eta: 0:01:27  Lr: 0.001875  Loss: 0.1855  Acc@1: 87.5000 (83.3218)  Acc@5: 100.0000 (96.3052)  time: 0.6564  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[1/5]  [190/313]  eta: 0:01:21  Lr: 0.001875  Loss: 0.0585  Acc@1: 87.5000 (83.7369)  Acc@5: 100.0000 (96.4987)  time: 0.6567  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[1/5]  [200/313]  eta: 0:01:14  Lr: 0.001875  Loss: 0.6684  Acc@1: 93.7500 (83.9863)  Acc@5: 100.0000 (96.6107)  time: 0.6567  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[1/5]  [210/313]  eta: 0:01:07  Lr: 0.001875  Loss: 0.2004  Acc@1: 87.5000 (83.9455)  Acc@5: 100.0000 (96.6825)  time: 0.6562  data: 0.0025  max mem: 2373\n",
            "Train: Epoch[1/5]  [220/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.3450  Acc@1: 87.5000 (84.1346)  Acc@5: 100.0000 (96.6629)  time: 0.6559  data: 0.0025  max mem: 2373\n",
            "Train: Epoch[1/5]  [230/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.3079  Acc@1: 87.5000 (84.1991)  Acc@5: 100.0000 (96.6721)  time: 0.6560  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[1/5]  [240/313]  eta: 0:00:48  Lr: 0.001875  Loss: -0.0384  Acc@1: 87.5000 (84.4139)  Acc@5: 100.0000 (96.7842)  time: 0.6562  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[1/5]  [250/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.1213  Acc@1: 87.5000 (84.3875)  Acc@5: 100.0000 (96.8376)  time: 0.6566  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[1/5]  [260/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.0382  Acc@1: 81.2500 (84.3870)  Acc@5: 100.0000 (96.8151)  time: 0.6560  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[1/5]  [270/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.3127  Acc@1: 87.5000 (84.5249)  Acc@5: 100.0000 (96.8635)  time: 0.6563  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[1/5]  [280/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.0768  Acc@1: 87.5000 (84.5863)  Acc@5: 100.0000 (96.9306)  time: 0.6562  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[1/5]  [290/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.2023  Acc@1: 87.5000 (84.7723)  Acc@5: 100.0000 (96.9931)  time: 0.6561  data: 0.0026  max mem: 2373\n",
            "Train: Epoch[1/5]  [300/313]  eta: 0:00:08  Lr: 0.001875  Loss: -0.0781  Acc@1: 93.7500 (85.0498)  Acc@5: 100.0000 (97.0723)  time: 0.6562  data: 0.0026  max mem: 2373\n",
            "Train: Epoch[1/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.4815  Acc@1: 93.7500 (85.0884)  Acc@5: 100.0000 (97.0860)  time: 0.6558  data: 0.0004  max mem: 2373\n",
            "Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.3325  Acc@1: 93.7500 (85.1200)  Acc@5: 100.0000 (97.1000)  time: 0.6395  data: 0.0003  max mem: 2373\n",
            "Train: Epoch[1/5] Total time: 0:03:25 (0.6568 s / it)\n",
            "Averaged stats: Lr: 0.001875  Loss: 0.3325  Acc@1: 93.7500 (85.1200)  Acc@5: 100.0000 (97.1000)\n",
            "Train: Epoch[2/5]  [  0/313]  eta: 0:03:55  Lr: 0.001875  Loss: 0.4498  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.7513  data: 0.1376  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 10/313]  eta: 0:03:21  Lr: 0.001875  Loss: 0.1018  Acc@1: 87.5000 (88.0682)  Acc@5: 100.0000 (98.2955)  time: 0.6660  data: 0.0131  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 20/313]  eta: 0:03:13  Lr: 0.001875  Loss: 0.4541  Acc@1: 87.5000 (87.2024)  Acc@5: 100.0000 (98.8095)  time: 0.6564  data: 0.0031  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 30/313]  eta: 0:03:06  Lr: 0.001875  Loss: 0.3050  Acc@1: 87.5000 (87.9032)  Acc@5: 100.0000 (98.5887)  time: 0.6549  data: 0.0033  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 40/313]  eta: 0:02:59  Lr: 0.001875  Loss: 0.1950  Acc@1: 87.5000 (88.1098)  Acc@5: 100.0000 (98.6280)  time: 0.6551  data: 0.0033  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 50/313]  eta: 0:02:52  Lr: 0.001875  Loss: 0.1185  Acc@1: 87.5000 (88.3578)  Acc@5: 100.0000 (98.6520)  time: 0.6557  data: 0.0029  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 60/313]  eta: 0:02:46  Lr: 0.001875  Loss: -0.0079  Acc@1: 87.5000 (88.9344)  Acc@5: 100.0000 (98.6680)  time: 0.6558  data: 0.0014  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 70/313]  eta: 0:02:39  Lr: 0.001875  Loss: -0.0215  Acc@1: 87.5000 (88.6444)  Acc@5: 100.0000 (98.6796)  time: 0.6552  data: 0.0015  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 80/313]  eta: 0:02:33  Lr: 0.001875  Loss: -0.1045  Acc@1: 87.5000 (89.0432)  Acc@5: 100.0000 (98.6883)  time: 0.6549  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 90/313]  eta: 0:02:26  Lr: 0.001875  Loss: -0.0736  Acc@1: 87.5000 (88.3929)  Acc@5: 100.0000 (98.7637)  time: 0.6556  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[2/5]  [100/313]  eta: 0:02:19  Lr: 0.001875  Loss: 0.4311  Acc@1: 81.2500 (87.9950)  Acc@5: 100.0000 (98.8861)  time: 0.6558  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[2/5]  [110/313]  eta: 0:02:13  Lr: 0.001875  Loss: 0.0233  Acc@1: 87.5000 (87.9505)  Acc@5: 100.0000 (98.8739)  time: 0.6558  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[2/5]  [120/313]  eta: 0:02:06  Lr: 0.001875  Loss: 0.0475  Acc@1: 87.5000 (88.2231)  Acc@5: 100.0000 (98.9669)  time: 0.6557  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[2/5]  [130/313]  eta: 0:02:00  Lr: 0.001875  Loss: 0.3636  Acc@1: 93.7500 (88.1679)  Acc@5: 100.0000 (98.9504)  time: 0.6549  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[2/5]  [140/313]  eta: 0:01:53  Lr: 0.001875  Loss: 0.0336  Acc@1: 87.5000 (88.3422)  Acc@5: 100.0000 (98.9362)  time: 0.6550  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[2/5]  [150/313]  eta: 0:01:46  Lr: 0.001875  Loss: 0.3081  Acc@1: 87.5000 (88.2036)  Acc@5: 100.0000 (98.8825)  time: 0.6559  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[2/5]  [160/313]  eta: 0:01:40  Lr: 0.001875  Loss: -0.0760  Acc@1: 87.5000 (88.0823)  Acc@5: 100.0000 (98.8742)  time: 0.6558  data: 0.0011  max mem: 2373\n",
            "Train: Epoch[2/5]  [170/313]  eta: 0:01:33  Lr: 0.001875  Loss: 0.0025  Acc@1: 87.5000 (88.1944)  Acc@5: 100.0000 (98.8670)  time: 0.6557  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[2/5]  [180/313]  eta: 0:01:27  Lr: 0.001875  Loss: 0.1076  Acc@1: 93.7500 (88.2251)  Acc@5: 100.0000 (98.7914)  time: 0.6552  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[2/5]  [190/313]  eta: 0:01:20  Lr: 0.001875  Loss: 0.0625  Acc@1: 93.7500 (88.3835)  Acc@5: 100.0000 (98.7893)  time: 0.6553  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[2/5]  [200/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.0869  Acc@1: 87.5000 (88.4017)  Acc@5: 100.0000 (98.7562)  time: 0.6561  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[2/5]  [210/313]  eta: 0:01:07  Lr: 0.001875  Loss: 0.5448  Acc@1: 87.5000 (88.2701)  Acc@5: 100.0000 (98.6967)  time: 0.6558  data: 0.0028  max mem: 2373\n",
            "Train: Epoch[2/5]  [220/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.6114  Acc@1: 87.5000 (88.4050)  Acc@5: 100.0000 (98.6708)  time: 0.6549  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[2/5]  [230/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.0496  Acc@1: 87.5000 (88.2576)  Acc@5: 100.0000 (98.5931)  time: 0.6543  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[2/5]  [240/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.2606  Acc@1: 87.5000 (88.1743)  Acc@5: 100.0000 (98.5996)  time: 0.6543  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[2/5]  [250/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.2139  Acc@1: 87.5000 (88.0229)  Acc@5: 100.0000 (98.6305)  time: 0.6546  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[2/5]  [260/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.0197  Acc@1: 87.5000 (88.1466)  Acc@5: 100.0000 (98.6590)  time: 0.6548  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[2/5]  [270/313]  eta: 0:00:28  Lr: 0.001875  Loss: -0.1185  Acc@1: 93.7500 (88.3072)  Acc@5: 100.0000 (98.6162)  time: 0.6546  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[2/5]  [280/313]  eta: 0:00:21  Lr: 0.001875  Loss: -0.0061  Acc@1: 93.7500 (88.2562)  Acc@5: 100.0000 (98.6655)  time: 0.6552  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[2/5]  [290/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.1735  Acc@1: 87.5000 (88.2732)  Acc@5: 100.0000 (98.6254)  time: 0.6553  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[2/5]  [300/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.1460  Acc@1: 93.7500 (88.4967)  Acc@5: 100.0000 (98.6503)  time: 0.6555  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[2/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: -0.0151  Acc@1: 93.7500 (88.5048)  Acc@5: 100.0000 (98.6535)  time: 0.6558  data: 0.0011  max mem: 2373\n",
            "Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.1158  Acc@1: 93.7500 (88.4800)  Acc@5: 100.0000 (98.6600)  time: 0.6396  data: 0.0011  max mem: 2373\n",
            "Train: Epoch[2/5] Total time: 0:03:24 (0.6549 s / it)\n",
            "Averaged stats: Lr: 0.001875  Loss: 0.1158  Acc@1: 93.7500 (88.4800)  Acc@5: 100.0000 (98.6600)\n",
            "Train: Epoch[3/5]  [  0/313]  eta: 0:03:59  Lr: 0.001875  Loss: 0.2079  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.7646  data: 0.1525  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 10/313]  eta: 0:03:22  Lr: 0.001875  Loss: 0.2965  Acc@1: 93.7500 (89.7727)  Acc@5: 100.0000 (99.4318)  time: 0.6672  data: 0.0144  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 20/313]  eta: 0:03:13  Lr: 0.001875  Loss: 0.2169  Acc@1: 87.5000 (85.4167)  Acc@5: 100.0000 (98.5119)  time: 0.6554  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 30/313]  eta: 0:03:06  Lr: 0.001875  Loss: 0.2072  Acc@1: 87.5000 (87.7016)  Acc@5: 100.0000 (98.5887)  time: 0.6542  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 40/313]  eta: 0:02:59  Lr: 0.001875  Loss: 0.3000  Acc@1: 93.7500 (87.9573)  Acc@5: 100.0000 (98.6280)  time: 0.6552  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 50/313]  eta: 0:02:52  Lr: 0.001875  Loss: 0.0776  Acc@1: 87.5000 (88.4804)  Acc@5: 100.0000 (98.7745)  time: 0.6550  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 60/313]  eta: 0:02:46  Lr: 0.001875  Loss: 0.1249  Acc@1: 87.5000 (88.2172)  Acc@5: 100.0000 (98.7705)  time: 0.6545  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 70/313]  eta: 0:02:39  Lr: 0.001875  Loss: -0.1346  Acc@1: 87.5000 (88.1162)  Acc@5: 100.0000 (98.6796)  time: 0.6553  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 80/313]  eta: 0:02:32  Lr: 0.001875  Loss: 0.5079  Acc@1: 87.5000 (88.1944)  Acc@5: 100.0000 (98.5340)  time: 0.6556  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 90/313]  eta: 0:02:26  Lr: 0.001875  Loss: 0.2055  Acc@1: 87.5000 (88.2555)  Acc@5: 100.0000 (98.5577)  time: 0.6552  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[3/5]  [100/313]  eta: 0:02:19  Lr: 0.001875  Loss: 0.1085  Acc@1: 87.5000 (88.1188)  Acc@5: 100.0000 (98.6386)  time: 0.6551  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[3/5]  [110/313]  eta: 0:02:13  Lr: 0.001875  Loss: 0.2621  Acc@1: 87.5000 (88.0631)  Acc@5: 100.0000 (98.6486)  time: 0.6551  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[3/5]  [120/313]  eta: 0:02:06  Lr: 0.001875  Loss: 0.3317  Acc@1: 81.2500 (87.8099)  Acc@5: 100.0000 (98.6570)  time: 0.6559  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[3/5]  [130/313]  eta: 0:02:00  Lr: 0.001875  Loss: 0.1236  Acc@1: 87.5000 (87.8817)  Acc@5: 100.0000 (98.7118)  time: 0.6558  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[3/5]  [140/313]  eta: 0:01:53  Lr: 0.001875  Loss: -0.0946  Acc@1: 87.5000 (87.9433)  Acc@5: 100.0000 (98.5816)  time: 0.6558  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[3/5]  [150/313]  eta: 0:01:46  Lr: 0.001875  Loss: -0.0170  Acc@1: 87.5000 (87.8725)  Acc@5: 100.0000 (98.6341)  time: 0.6557  data: 0.0031  max mem: 2373\n",
            "Train: Epoch[3/5]  [160/313]  eta: 0:01:40  Lr: 0.001875  Loss: 0.5923  Acc@1: 81.2500 (87.7717)  Acc@5: 100.0000 (98.5637)  time: 0.6552  data: 0.0028  max mem: 2373\n",
            "Train: Epoch[3/5]  [170/313]  eta: 0:01:33  Lr: 0.001875  Loss: 0.0442  Acc@1: 87.5000 (87.6827)  Acc@5: 100.0000 (98.6111)  time: 0.6552  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[3/5]  [180/313]  eta: 0:01:27  Lr: 0.001875  Loss: 0.1328  Acc@1: 87.5000 (87.8798)  Acc@5: 100.0000 (98.5843)  time: 0.6550  data: 0.0012  max mem: 2373\n",
            "Train: Epoch[3/5]  [190/313]  eta: 0:01:20  Lr: 0.001875  Loss: 0.1635  Acc@1: 87.5000 (87.6636)  Acc@5: 100.0000 (98.5602)  time: 0.6553  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[3/5]  [200/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.0774  Acc@1: 87.5000 (87.9353)  Acc@5: 100.0000 (98.5697)  time: 0.6556  data: 0.0025  max mem: 2373\n",
            "Train: Epoch[3/5]  [210/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.0686  Acc@1: 87.5000 (87.9443)  Acc@5: 100.0000 (98.5782)  time: 0.6555  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[3/5]  [220/313]  eta: 0:01:00  Lr: 0.001875  Loss: 0.1175  Acc@1: 87.5000 (88.2070)  Acc@5: 100.0000 (98.6143)  time: 0.6556  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[3/5]  [230/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.0196  Acc@1: 93.7500 (88.2305)  Acc@5: 100.0000 (98.6472)  time: 0.6552  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[3/5]  [240/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.1611  Acc@1: 93.7500 (88.3039)  Acc@5: 100.0000 (98.7033)  time: 0.6552  data: 0.0012  max mem: 2373\n",
            "Train: Epoch[3/5]  [250/313]  eta: 0:00:41  Lr: 0.001875  Loss: -0.1007  Acc@1: 93.7500 (88.2719)  Acc@5: 100.0000 (98.7052)  time: 0.6554  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[3/5]  [260/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.0010  Acc@1: 93.7500 (88.3381)  Acc@5: 100.0000 (98.6830)  time: 0.6556  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[3/5]  [270/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.0638  Acc@1: 93.7500 (88.4456)  Acc@5: 100.0000 (98.6854)  time: 0.6548  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[3/5]  [280/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.2488  Acc@1: 93.7500 (88.5676)  Acc@5: 100.0000 (98.7322)  time: 0.6548  data: 0.0015  max mem: 2373\n",
            "Train: Epoch[3/5]  [290/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.0918  Acc@1: 87.5000 (88.4450)  Acc@5: 100.0000 (98.7328)  time: 0.6559  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[3/5]  [300/313]  eta: 0:00:08  Lr: 0.001875  Loss: -0.0844  Acc@1: 87.5000 (88.5174)  Acc@5: 100.0000 (98.7334)  time: 0.6554  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[3/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.2264  Acc@1: 87.5000 (88.5048)  Acc@5: 100.0000 (98.7540)  time: 0.6547  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.4335  Acc@1: 87.5000 (88.5000)  Acc@5: 100.0000 (98.7600)  time: 0.6384  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[3/5] Total time: 0:03:24 (0.6548 s / it)\n",
            "Averaged stats: Lr: 0.001875  Loss: 0.4335  Acc@1: 87.5000 (88.5000)  Acc@5: 100.0000 (98.7600)\n",
            "Train: Epoch[4/5]  [  0/313]  eta: 0:04:16  Lr: 0.001875  Loss: 0.2127  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.8185  data: 0.2024  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 10/313]  eta: 0:03:23  Lr: 0.001875  Loss: 0.2627  Acc@1: 87.5000 (88.6364)  Acc@5: 100.0000 (97.7273)  time: 0.6716  data: 0.0207  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 20/313]  eta: 0:03:14  Lr: 0.001875  Loss: 0.2011  Acc@1: 87.5000 (86.0119)  Acc@5: 100.0000 (98.8095)  time: 0.6559  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 30/313]  eta: 0:03:06  Lr: 0.001875  Loss: -0.1000  Acc@1: 87.5000 (86.4919)  Acc@5: 100.0000 (98.5887)  time: 0.6546  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 40/313]  eta: 0:02:59  Lr: 0.001875  Loss: 0.0946  Acc@1: 87.5000 (86.8902)  Acc@5: 100.0000 (98.3232)  time: 0.6542  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 50/313]  eta: 0:02:53  Lr: 0.001875  Loss: -0.1046  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.5294)  time: 0.6548  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 60/313]  eta: 0:02:46  Lr: 0.001875  Loss: 0.4048  Acc@1: 87.5000 (87.2951)  Acc@5: 100.0000 (98.2582)  time: 0.6549  data: 0.0012  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 70/313]  eta: 0:02:39  Lr: 0.001875  Loss: -0.1956  Acc@1: 87.5000 (87.8521)  Acc@5: 100.0000 (98.3275)  time: 0.6545  data: 0.0013  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 80/313]  eta: 0:02:33  Lr: 0.001875  Loss: -0.0480  Acc@1: 93.7500 (88.8117)  Acc@5: 100.0000 (98.5340)  time: 0.6546  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 90/313]  eta: 0:02:26  Lr: 0.001875  Loss: 0.2848  Acc@1: 93.7500 (89.2170)  Acc@5: 100.0000 (98.6264)  time: 0.6549  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[4/5]  [100/313]  eta: 0:02:19  Lr: 0.001875  Loss: 0.4204  Acc@1: 93.7500 (89.3564)  Acc@5: 100.0000 (98.7005)  time: 0.6554  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[4/5]  [110/313]  eta: 0:02:13  Lr: 0.001875  Loss: -0.0051  Acc@1: 93.7500 (89.5833)  Acc@5: 100.0000 (98.7050)  time: 0.6554  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[4/5]  [120/313]  eta: 0:02:06  Lr: 0.001875  Loss: 0.0382  Acc@1: 93.7500 (89.4628)  Acc@5: 100.0000 (98.6570)  time: 0.6556  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[4/5]  [130/313]  eta: 0:02:00  Lr: 0.001875  Loss: -0.0820  Acc@1: 87.5000 (89.4561)  Acc@5: 100.0000 (98.6641)  time: 0.6560  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[4/5]  [140/313]  eta: 0:01:53  Lr: 0.001875  Loss: 0.2335  Acc@1: 87.5000 (89.1844)  Acc@5: 100.0000 (98.6702)  time: 0.6560  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[4/5]  [150/313]  eta: 0:01:46  Lr: 0.001875  Loss: 0.4830  Acc@1: 87.5000 (88.9901)  Acc@5: 100.0000 (98.6341)  time: 0.6558  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[4/5]  [160/313]  eta: 0:01:40  Lr: 0.001875  Loss: 0.2298  Acc@1: 87.5000 (89.2469)  Acc@5: 100.0000 (98.6801)  time: 0.6547  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[4/5]  [170/313]  eta: 0:01:33  Lr: 0.001875  Loss: 0.2575  Acc@1: 93.7500 (89.3275)  Acc@5: 100.0000 (98.6111)  time: 0.6544  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[4/5]  [180/313]  eta: 0:01:27  Lr: 0.001875  Loss: 0.3588  Acc@1: 87.5000 (89.2956)  Acc@5: 100.0000 (98.4807)  time: 0.6551  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[4/5]  [190/313]  eta: 0:01:20  Lr: 0.001875  Loss: -0.1591  Acc@1: 87.5000 (89.2343)  Acc@5: 93.7500 (98.4293)  time: 0.6555  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[4/5]  [200/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.0292  Acc@1: 93.7500 (89.3968)  Acc@5: 100.0000 (98.5075)  time: 0.6552  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[4/5]  [210/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.0549  Acc@1: 93.7500 (89.4550)  Acc@5: 100.0000 (98.5190)  time: 0.6548  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[4/5]  [220/313]  eta: 0:01:00  Lr: 0.001875  Loss: 0.0335  Acc@1: 87.5000 (89.4231)  Acc@5: 100.0000 (98.5577)  time: 0.6549  data: 0.0013  max mem: 2373\n",
            "Train: Epoch[4/5]  [230/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.0969  Acc@1: 93.7500 (89.4210)  Acc@5: 100.0000 (98.5931)  time: 0.6552  data: 0.0013  max mem: 2373\n",
            "Train: Epoch[4/5]  [240/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.0853  Acc@1: 93.7500 (89.6006)  Acc@5: 100.0000 (98.6515)  time: 0.6559  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[4/5]  [250/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.1378  Acc@1: 93.7500 (89.5916)  Acc@5: 100.0000 (98.7052)  time: 0.6556  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[4/5]  [260/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.3767  Acc@1: 87.5000 (89.5354)  Acc@5: 100.0000 (98.6830)  time: 0.6549  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[4/5]  [270/313]  eta: 0:00:28  Lr: 0.001875  Loss: -0.0072  Acc@1: 87.5000 (89.4834)  Acc@5: 100.0000 (98.7085)  time: 0.6548  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[4/5]  [280/313]  eta: 0:00:21  Lr: 0.001875  Loss: -0.0966  Acc@1: 87.5000 (89.5018)  Acc@5: 100.0000 (98.6877)  time: 0.6552  data: 0.0027  max mem: 2373\n",
            "Train: Epoch[4/5]  [290/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.0998  Acc@1: 87.5000 (89.4115)  Acc@5: 100.0000 (98.7328)  time: 0.6544  data: 0.0034  max mem: 2373\n",
            "Train: Epoch[4/5]  [300/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.1544  Acc@1: 87.5000 (89.4103)  Acc@5: 100.0000 (98.6711)  time: 0.6535  data: 0.0015  max mem: 2373\n",
            "Train: Epoch[4/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.1492  Acc@1: 87.5000 (89.3891)  Acc@5: 100.0000 (98.6535)  time: 0.6545  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1723  Acc@1: 87.5000 (89.4400)  Acc@5: 100.0000 (98.6600)  time: 0.6388  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[4/5] Total time: 0:03:24 (0.6548 s / it)\n",
            "Averaged stats: Lr: 0.001875  Loss: -0.1723  Acc@1: 87.5000 (89.4400)  Acc@5: 100.0000 (98.6600)\n",
            "Train: Epoch[5/5]  [  0/313]  eta: 0:03:54  Lr: 0.001875  Loss: 0.0594  Acc@1: 93.7500 (93.7500)  Acc@5: 93.7500 (93.7500)  time: 0.7491  data: 0.1333  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 10/313]  eta: 0:03:21  Lr: 0.001875  Loss: 0.2995  Acc@1: 81.2500 (82.9545)  Acc@5: 100.0000 (97.7273)  time: 0.6635  data: 0.0139  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 20/313]  eta: 0:03:13  Lr: 0.001875  Loss: 0.1570  Acc@1: 87.5000 (86.0119)  Acc@5: 100.0000 (98.5119)  time: 0.6543  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 30/313]  eta: 0:03:06  Lr: 0.001875  Loss: 0.3145  Acc@1: 87.5000 (86.6935)  Acc@5: 100.0000 (98.3871)  time: 0.6546  data: 0.0014  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 40/313]  eta: 0:02:59  Lr: 0.001875  Loss: 0.0830  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.4756)  time: 0.6552  data: 0.0014  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 50/313]  eta: 0:02:52  Lr: 0.001875  Loss: 0.1882  Acc@1: 93.7500 (88.1127)  Acc@5: 100.0000 (98.7745)  time: 0.6541  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 60/313]  eta: 0:02:46  Lr: 0.001875  Loss: 0.4983  Acc@1: 87.5000 (87.7049)  Acc@5: 100.0000 (98.7705)  time: 0.6545  data: 0.0029  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 70/313]  eta: 0:02:39  Lr: 0.001875  Loss: -0.0045  Acc@1: 87.5000 (87.5880)  Acc@5: 100.0000 (98.9437)  time: 0.6552  data: 0.0025  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 80/313]  eta: 0:02:32  Lr: 0.001875  Loss: 0.2347  Acc@1: 87.5000 (87.8858)  Acc@5: 100.0000 (98.7654)  time: 0.6551  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 90/313]  eta: 0:02:26  Lr: 0.001875  Loss: 0.2504  Acc@1: 87.5000 (87.9121)  Acc@5: 100.0000 (98.7637)  time: 0.6546  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[5/5]  [100/313]  eta: 0:02:19  Lr: 0.001875  Loss: -0.1456  Acc@1: 87.5000 (88.1807)  Acc@5: 100.0000 (98.8243)  time: 0.6542  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[5/5]  [110/313]  eta: 0:02:13  Lr: 0.001875  Loss: -0.1132  Acc@1: 93.7500 (88.4572)  Acc@5: 100.0000 (98.9302)  time: 0.6549  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[5/5]  [120/313]  eta: 0:02:06  Lr: 0.001875  Loss: 0.0300  Acc@1: 93.7500 (88.6364)  Acc@5: 100.0000 (99.0186)  time: 0.6545  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[5/5]  [130/313]  eta: 0:01:59  Lr: 0.001875  Loss: 0.0754  Acc@1: 93.7500 (88.8836)  Acc@5: 100.0000 (98.9981)  time: 0.6546  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[5/5]  [140/313]  eta: 0:01:53  Lr: 0.001875  Loss: 0.0524  Acc@1: 93.7500 (89.0071)  Acc@5: 100.0000 (98.9805)  time: 0.6552  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[5/5]  [150/313]  eta: 0:01:46  Lr: 0.001875  Loss: 0.2260  Acc@1: 87.5000 (89.0315)  Acc@5: 100.0000 (99.0066)  time: 0.6550  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[5/5]  [160/313]  eta: 0:01:40  Lr: 0.001875  Loss: -0.0317  Acc@1: 87.5000 (89.2469)  Acc@5: 100.0000 (98.9519)  time: 0.6546  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[5/5]  [170/313]  eta: 0:01:33  Lr: 0.001875  Loss: -0.0087  Acc@1: 87.5000 (89.0351)  Acc@5: 100.0000 (98.9035)  time: 0.6544  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[5/5]  [180/313]  eta: 0:01:27  Lr: 0.001875  Loss: -0.1287  Acc@1: 87.5000 (89.2265)  Acc@5: 100.0000 (98.9641)  time: 0.6551  data: 0.0014  max mem: 2373\n",
            "Train: Epoch[5/5]  [190/313]  eta: 0:01:20  Lr: 0.001875  Loss: 0.1003  Acc@1: 93.7500 (89.2016)  Acc@5: 100.0000 (98.8874)  time: 0.6557  data: 0.0015  max mem: 2373\n",
            "Train: Epoch[5/5]  [200/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.0316  Acc@1: 93.7500 (89.4590)  Acc@5: 100.0000 (98.8184)  time: 0.6550  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[5/5]  [210/313]  eta: 0:01:07  Lr: 0.001875  Loss: 0.0479  Acc@1: 93.7500 (89.5735)  Acc@5: 100.0000 (98.8448)  time: 0.6546  data: 0.0015  max mem: 2373\n",
            "Train: Epoch[5/5]  [220/313]  eta: 0:01:00  Lr: 0.001875  Loss: 0.1380  Acc@1: 93.7500 (89.6210)  Acc@5: 100.0000 (98.7839)  time: 0.6549  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[5/5]  [230/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.0979  Acc@1: 87.5000 (89.6104)  Acc@5: 100.0000 (98.8095)  time: 0.6549  data: 0.0027  max mem: 2373\n",
            "Train: Epoch[5/5]  [240/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.1370  Acc@1: 87.5000 (89.7044)  Acc@5: 100.0000 (98.7811)  time: 0.6546  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[5/5]  [250/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.1956  Acc@1: 93.7500 (89.7908)  Acc@5: 100.0000 (98.8048)  time: 0.6544  data: 0.0015  max mem: 2373\n",
            "Train: Epoch[5/5]  [260/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.1806  Acc@1: 93.7500 (89.9186)  Acc@5: 100.0000 (98.8506)  time: 0.6548  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[5/5]  [270/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.1050  Acc@1: 93.7500 (89.9908)  Acc@5: 100.0000 (98.8469)  time: 0.6552  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[5/5]  [280/313]  eta: 0:00:21  Lr: 0.001875  Loss: -0.0513  Acc@1: 93.7500 (89.8354)  Acc@5: 100.0000 (98.8212)  time: 0.6546  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[5/5]  [290/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.0663  Acc@1: 87.5000 (89.8196)  Acc@5: 100.0000 (98.8402)  time: 0.6540  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[5/5]  [300/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.1613  Acc@1: 87.5000 (89.7841)  Acc@5: 100.0000 (98.8580)  time: 0.6547  data: 0.0014  max mem: 2373\n",
            "Train: Epoch[5/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.2388  Acc@1: 87.5000 (89.6101)  Acc@5: 100.0000 (98.8344)  time: 0.6548  data: 0.0013  max mem: 2373\n",
            "Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1761  Acc@1: 87.5000 (89.6200)  Acc@5: 100.0000 (98.8400)  time: 0.6386  data: 0.0012  max mem: 2373\n",
            "Train: Epoch[5/5] Total time: 0:03:24 (0.6543 s / it)\n",
            "Averaged stats: Lr: 0.001875  Loss: -0.1761  Acc@1: 87.5000 (89.6200)  Acc@5: 100.0000 (98.8400)\n",
            "Test: [Task 1]  [ 0/63]  eta: 0:00:38  Loss: 0.8377 (0.8377)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.6185  data: 0.2283  max mem: 2373\n",
            "Test: [Task 1]  [10/63]  eta: 0:00:23  Loss: 0.5784 (0.6291)  Acc@1: 87.5000 (86.3636)  Acc@5: 100.0000 (98.8636)  time: 0.4431  data: 0.0232  max mem: 2373\n",
            "Test: [Task 1]  [20/63]  eta: 0:00:18  Loss: 0.5820 (0.6788)  Acc@1: 87.5000 (83.0357)  Acc@5: 100.0000 (98.2143)  time: 0.4253  data: 0.0019  max mem: 2373\n",
            "Test: [Task 1]  [30/63]  eta: 0:00:14  Loss: 0.5820 (0.6569)  Acc@1: 81.2500 (84.0726)  Acc@5: 100.0000 (98.5887)  time: 0.4243  data: 0.0009  max mem: 2373\n",
            "Test: [Task 1]  [40/63]  eta: 0:00:09  Loss: 0.5524 (0.6379)  Acc@1: 81.2500 (84.4512)  Acc@5: 100.0000 (98.7805)  time: 0.4234  data: 0.0014  max mem: 2373\n",
            "Test: [Task 1]  [50/63]  eta: 0:00:05  Loss: 0.5200 (0.6170)  Acc@1: 87.5000 (85.1716)  Acc@5: 100.0000 (98.7745)  time: 0.4236  data: 0.0030  max mem: 2373\n",
            "Test: [Task 1]  [60/63]  eta: 0:00:01  Loss: 0.5146 (0.6010)  Acc@1: 87.5000 (85.9631)  Acc@5: 100.0000 (98.7705)  time: 0.4240  data: 0.0026  max mem: 2373\n",
            "Test: [Task 1]  [62/63]  eta: 0:00:00  Loss: 0.4940 (0.5963)  Acc@1: 87.5000 (86.1000)  Acc@5: 100.0000 (98.8000)  time: 0.4133  data: 0.0019  max mem: 2373\n",
            "Test: [Task 1] Total time: 0:00:26 (0.4248 s / it)\n",
            "* Acc@1 86.100 Acc@5 98.800 loss 0.596\n",
            "Test: [Task 2]  [ 0/63]  eta: 0:00:41  Loss: 0.8736 (0.8736)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.6519  data: 0.2648  max mem: 2373\n",
            "Test: [Task 2]  [10/63]  eta: 0:00:23  Loss: 0.7568 (0.7269)  Acc@1: 87.5000 (85.2273)  Acc@5: 100.0000 (97.7273)  time: 0.4467  data: 0.0257  max mem: 2373\n",
            "Test: [Task 2]  [20/63]  eta: 0:00:18  Loss: 0.7886 (0.7876)  Acc@1: 81.2500 (82.7381)  Acc@5: 100.0000 (97.6190)  time: 0.4258  data: 0.0021  max mem: 2373\n",
            "Test: [Task 2]  [30/63]  eta: 0:00:14  Loss: 0.7989 (0.7743)  Acc@1: 87.5000 (84.0726)  Acc@5: 100.0000 (96.9758)  time: 0.4247  data: 0.0016  max mem: 2373\n",
            "Test: [Task 2]  [40/63]  eta: 0:00:09  Loss: 0.6948 (0.7552)  Acc@1: 87.5000 (84.6037)  Acc@5: 93.7500 (96.6463)  time: 0.4237  data: 0.0009  max mem: 2373\n",
            "Test: [Task 2]  [50/63]  eta: 0:00:05  Loss: 0.6612 (0.7460)  Acc@1: 87.5000 (84.4363)  Acc@5: 100.0000 (96.8137)  time: 0.4238  data: 0.0029  max mem: 2373\n",
            "Test: [Task 2]  [60/63]  eta: 0:00:01  Loss: 0.6333 (0.7311)  Acc@1: 81.2500 (84.6311)  Acc@5: 100.0000 (97.1311)  time: 0.4247  data: 0.0026  max mem: 2373\n",
            "Test: [Task 2]  [62/63]  eta: 0:00:00  Loss: 0.6333 (0.7223)  Acc@1: 81.2500 (84.6000)  Acc@5: 100.0000 (97.2000)  time: 0.4140  data: 0.0019  max mem: 2373\n",
            "Test: [Task 2] Total time: 0:00:26 (0.4257 s / it)\n",
            "* Acc@1 84.600 Acc@5 97.200 loss 0.722\n",
            "Test: [Task 3]  [ 0/63]  eta: 0:00:33  Loss: 0.4445 (0.4445)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.5378  data: 0.1469  max mem: 2373\n",
            "Test: [Task 3]  [10/63]  eta: 0:00:23  Loss: 0.6417 (0.6503)  Acc@1: 87.5000 (84.0909)  Acc@5: 100.0000 (97.1591)  time: 0.4357  data: 0.0155  max mem: 2373\n",
            "Test: [Task 3]  [20/63]  eta: 0:00:18  Loss: 0.6597 (0.6544)  Acc@1: 81.2500 (83.0357)  Acc@5: 93.7500 (97.0238)  time: 0.4261  data: 0.0052  max mem: 2373\n",
            "Test: [Task 3]  [30/63]  eta: 0:00:14  Loss: 0.6597 (0.6609)  Acc@1: 81.2500 (82.6613)  Acc@5: 100.0000 (97.5806)  time: 0.4263  data: 0.0047  max mem: 2373\n",
            "Test: [Task 3]  [40/63]  eta: 0:00:09  Loss: 0.6192 (0.6508)  Acc@1: 81.2500 (83.0793)  Acc@5: 100.0000 (97.8659)  time: 0.4245  data: 0.0010  max mem: 2373\n",
            "Test: [Task 3]  [50/63]  eta: 0:00:05  Loss: 0.6360 (0.6565)  Acc@1: 81.2500 (83.2108)  Acc@5: 100.0000 (97.6716)  time: 0.4233  data: 0.0021  max mem: 2373\n",
            "Test: [Task 3]  [60/63]  eta: 0:00:01  Loss: 0.7240 (0.6690)  Acc@1: 81.2500 (82.8893)  Acc@5: 93.7500 (97.5410)  time: 0.4239  data: 0.0031  max mem: 2373\n",
            "Test: [Task 3]  [62/63]  eta: 0:00:00  Loss: 0.7240 (0.6705)  Acc@1: 81.2500 (82.6000)  Acc@5: 93.7500 (97.5000)  time: 0.4132  data: 0.0031  max mem: 2373\n",
            "Test: [Task 3] Total time: 0:00:26 (0.4241 s / it)\n",
            "* Acc@1 82.600 Acc@5 97.500 loss 0.671\n",
            "Test: [Task 4]  [ 0/63]  eta: 0:00:37  Loss: 0.7867 (0.7867)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.5993  data: 0.2073  max mem: 2373\n",
            "Test: [Task 4]  [10/63]  eta: 0:00:23  Loss: 0.7871 (0.7439)  Acc@1: 81.2500 (83.5227)  Acc@5: 93.7500 (96.0227)  time: 0.4408  data: 0.0192  max mem: 2373\n",
            "Test: [Task 4]  [20/63]  eta: 0:00:18  Loss: 0.7672 (0.7456)  Acc@1: 81.2500 (81.5476)  Acc@5: 93.7500 (95.8333)  time: 0.4255  data: 0.0018  max mem: 2373\n",
            "Test: [Task 4]  [30/63]  eta: 0:00:14  Loss: 0.5982 (0.7217)  Acc@1: 81.2500 (82.2581)  Acc@5: 93.7500 (95.9677)  time: 0.4252  data: 0.0022  max mem: 2373\n",
            "Test: [Task 4]  [40/63]  eta: 0:00:09  Loss: 0.3914 (0.6526)  Acc@1: 87.5000 (84.4512)  Acc@5: 100.0000 (96.7988)  time: 0.4248  data: 0.0009  max mem: 2373\n",
            "Test: [Task 4]  [50/63]  eta: 0:00:05  Loss: 0.4237 (0.6694)  Acc@1: 87.5000 (84.8039)  Acc@5: 100.0000 (96.4461)  time: 0.4247  data: 0.0012  max mem: 2373\n",
            "Test: [Task 4]  [60/63]  eta: 0:00:01  Loss: 0.6825 (0.6708)  Acc@1: 81.2500 (84.6311)  Acc@5: 100.0000 (96.2090)  time: 0.4243  data: 0.0023  max mem: 2373\n",
            "Test: [Task 4]  [62/63]  eta: 0:00:00  Loss: 0.6188 (0.6673)  Acc@1: 87.5000 (84.8000)  Acc@5: 100.0000 (96.3000)  time: 0.4134  data: 0.0023  max mem: 2373\n",
            "Test: [Task 4] Total time: 0:00:26 (0.4251 s / it)\n",
            "* Acc@1 84.800 Acc@5 96.300 loss 0.667\n",
            "Test: [Task 5]  [ 0/63]  eta: 0:00:37  Loss: 0.2609 (0.2609)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.5981  data: 0.2067  max mem: 2373\n",
            "Test: [Task 5]  [10/63]  eta: 0:00:23  Loss: 0.4746 (0.5386)  Acc@1: 87.5000 (90.9091)  Acc@5: 100.0000 (98.8636)  time: 0.4412  data: 0.0193  max mem: 2373\n",
            "Test: [Task 5]  [20/63]  eta: 0:00:18  Loss: 0.4746 (0.5122)  Acc@1: 93.7500 (91.9643)  Acc@5: 100.0000 (98.2143)  time: 0.4260  data: 0.0011  max mem: 2373\n",
            "Test: [Task 5]  [30/63]  eta: 0:00:14  Loss: 0.4726 (0.5168)  Acc@1: 93.7500 (91.3306)  Acc@5: 100.0000 (98.3871)  time: 0.4253  data: 0.0022  max mem: 2373\n",
            "Test: [Task 5]  [40/63]  eta: 0:00:09  Loss: 0.4258 (0.5022)  Acc@1: 93.7500 (91.4634)  Acc@5: 100.0000 (98.4756)  time: 0.4246  data: 0.0015  max mem: 2373\n",
            "Test: [Task 5]  [50/63]  eta: 0:00:05  Loss: 0.5070 (0.5051)  Acc@1: 87.5000 (91.1765)  Acc@5: 100.0000 (98.6520)  time: 0.4244  data: 0.0008  max mem: 2373\n",
            "Test: [Task 5]  [60/63]  eta: 0:00:01  Loss: 0.5070 (0.5092)  Acc@1: 87.5000 (90.3689)  Acc@5: 100.0000 (98.7705)  time: 0.4237  data: 0.0021  max mem: 2373\n",
            "Test: [Task 5]  [62/63]  eta: 0:00:00  Loss: 0.5165 (0.5294)  Acc@1: 87.5000 (89.9000)  Acc@5: 100.0000 (98.6000)  time: 0.4131  data: 0.0021  max mem: 2373\n",
            "Test: [Task 5] Total time: 0:00:26 (0.4250 s / it)\n",
            "* Acc@1 89.900 Acc@5 98.600 loss 0.529\n",
            "Test: [Task 6]  [ 0/63]  eta: 0:00:35  Loss: 0.4943 (0.4943)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.5626  data: 0.1726  max mem: 2373\n",
            "Test: [Task 6]  [10/63]  eta: 0:00:23  Loss: 0.6980 (0.6981)  Acc@1: 81.2500 (81.8182)  Acc@5: 100.0000 (97.7273)  time: 0.4379  data: 0.0160  max mem: 2373\n",
            "Test: [Task 6]  [20/63]  eta: 0:00:18  Loss: 0.6980 (0.7450)  Acc@1: 81.2500 (78.8690)  Acc@5: 100.0000 (97.6190)  time: 0.4254  data: 0.0015  max mem: 2373\n",
            "Test: [Task 6]  [30/63]  eta: 0:00:14  Loss: 0.6615 (0.7305)  Acc@1: 81.2500 (79.4355)  Acc@5: 100.0000 (98.1855)  time: 0.4250  data: 0.0030  max mem: 2373\n",
            "Test: [Task 6]  [40/63]  eta: 0:00:09  Loss: 0.6930 (0.7633)  Acc@1: 75.0000 (78.0488)  Acc@5: 100.0000 (97.7134)  time: 0.4245  data: 0.0020  max mem: 2373\n",
            "Test: [Task 6]  [50/63]  eta: 0:00:05  Loss: 0.7663 (0.7437)  Acc@1: 75.0000 (78.7990)  Acc@5: 100.0000 (98.0392)  time: 0.4241  data: 0.0005  max mem: 2373\n",
            "Test: [Task 6]  [60/63]  eta: 0:00:01  Loss: 0.6414 (0.7554)  Acc@1: 81.2500 (78.8934)  Acc@5: 100.0000 (97.7459)  time: 0.4244  data: 0.0011  max mem: 2373\n",
            "Test: [Task 6]  [62/63]  eta: 0:00:00  Loss: 0.6414 (0.7527)  Acc@1: 81.2500 (79.1000)  Acc@5: 100.0000 (97.8000)  time: 0.4141  data: 0.0010  max mem: 2373\n",
            "Test: [Task 6] Total time: 0:00:26 (0.4245 s / it)\n",
            "* Acc@1 79.100 Acc@5 97.800 loss 0.753\n",
            "Test: [Task 7]  [ 0/63]  eta: 0:00:34  Loss: 0.7145 (0.7145)  Acc@1: 68.7500 (68.7500)  Acc@5: 93.7500 (93.7500)  time: 0.5432  data: 0.1473  max mem: 2373\n",
            "Test: [Task 7]  [10/63]  eta: 0:00:23  Loss: 0.5840 (0.6142)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (98.2955)  time: 0.4362  data: 0.0144  max mem: 2373\n",
            "Test: [Task 7]  [20/63]  eta: 0:00:18  Loss: 0.5840 (0.6595)  Acc@1: 81.2500 (82.1429)  Acc@5: 100.0000 (97.0238)  time: 0.4261  data: 0.0014  max mem: 2373\n",
            "Test: [Task 7]  [30/63]  eta: 0:00:14  Loss: 0.6193 (0.6553)  Acc@1: 81.2500 (82.6613)  Acc@5: 100.0000 (97.1774)  time: 0.4256  data: 0.0029  max mem: 2373\n",
            "Test: [Task 7]  [40/63]  eta: 0:00:09  Loss: 0.6193 (0.6499)  Acc@1: 87.5000 (83.3841)  Acc@5: 100.0000 (97.2561)  time: 0.4248  data: 0.0024  max mem: 2373\n",
            "Test: [Task 7]  [50/63]  eta: 0:00:05  Loss: 0.6798 (0.6691)  Acc@1: 87.5000 (83.0882)  Acc@5: 100.0000 (96.9363)  time: 0.4244  data: 0.0007  max mem: 2373\n",
            "Test: [Task 7]  [60/63]  eta: 0:00:01  Loss: 0.6830 (0.6566)  Acc@1: 81.2500 (83.4016)  Acc@5: 100.0000 (96.9262)  time: 0.4244  data: 0.0016  max mem: 2373\n",
            "Test: [Task 7]  [62/63]  eta: 0:00:00  Loss: 0.6883 (0.6564)  Acc@1: 81.2500 (83.3000)  Acc@5: 100.0000 (96.9000)  time: 0.4140  data: 0.0016  max mem: 2373\n",
            "Test: [Task 7] Total time: 0:00:26 (0.4246 s / it)\n",
            "* Acc@1 83.300 Acc@5 96.900 loss 0.656\n",
            "Test: [Task 8]  [ 0/63]  eta: 0:00:33  Loss: 0.5361 (0.5361)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.5369  data: 0.1426  max mem: 2373\n",
            "Test: [Task 8]  [10/63]  eta: 0:00:23  Loss: 0.5361 (0.5834)  Acc@1: 87.5000 (85.7955)  Acc@5: 100.0000 (97.1591)  time: 0.4362  data: 0.0134  max mem: 2373\n",
            "Test: [Task 8]  [20/63]  eta: 0:00:18  Loss: 0.5788 (0.6544)  Acc@1: 87.5000 (84.5238)  Acc@5: 100.0000 (96.4286)  time: 0.4265  data: 0.0005  max mem: 2373\n",
            "Test: [Task 8]  [30/63]  eta: 0:00:14  Loss: 0.5611 (0.6274)  Acc@1: 87.5000 (85.6855)  Acc@5: 100.0000 (96.7742)  time: 0.4258  data: 0.0031  max mem: 2373\n",
            "Test: [Task 8]  [40/63]  eta: 0:00:09  Loss: 0.5552 (0.6352)  Acc@1: 87.5000 (85.8232)  Acc@5: 93.7500 (96.4939)  time: 0.4249  data: 0.0031  max mem: 2373\n",
            "Test: [Task 8]  [50/63]  eta: 0:00:05  Loss: 0.6606 (0.6331)  Acc@1: 81.2500 (85.1716)  Acc@5: 100.0000 (96.9363)  time: 0.4255  data: 0.0005  max mem: 2373\n",
            "Test: [Task 8]  [60/63]  eta: 0:00:01  Loss: 0.6755 (0.6516)  Acc@1: 81.2500 (84.6311)  Acc@5: 100.0000 (96.5164)  time: 0.4249  data: 0.0008  max mem: 2373\n",
            "Test: [Task 8]  [62/63]  eta: 0:00:00  Loss: 0.6662 (0.6428)  Acc@1: 81.2500 (84.9000)  Acc@5: 100.0000 (96.6000)  time: 0.4142  data: 0.0008  max mem: 2373\n",
            "Test: [Task 8] Total time: 0:00:26 (0.4246 s / it)\n",
            "* Acc@1 84.900 Acc@5 96.600 loss 0.643\n",
            "[Average accuracy till task8]\tAcc@1: 84.4125\tAcc@5: 97.4625\tLoss: 0.6547\tForgetting: 6.2286\tBackward: -6.0571\n",
            "Train: Epoch[1/5]  [  0/313]  eta: 0:04:12  Lr: 0.001875  Loss: 2.0568  Acc@1: 37.5000 (37.5000)  Acc@5: 68.7500 (68.7500)  time: 0.8057  data: 0.1948  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 10/313]  eta: 0:03:22  Lr: 0.001875  Loss: 1.7305  Acc@1: 56.2500 (55.6818)  Acc@5: 87.5000 (84.6591)  time: 0.6691  data: 0.0180  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 20/313]  eta: 0:03:13  Lr: 0.001875  Loss: 1.4239  Acc@1: 68.7500 (66.0714)  Acc@5: 93.7500 (90.4762)  time: 0.6547  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 30/313]  eta: 0:03:06  Lr: 0.001875  Loss: 0.9841  Acc@1: 81.2500 (71.7742)  Acc@5: 100.0000 (92.7419)  time: 0.6542  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 40/313]  eta: 0:02:59  Lr: 0.001875  Loss: 0.8928  Acc@1: 87.5000 (75.9146)  Acc@5: 100.0000 (94.0549)  time: 0.6543  data: 0.0013  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 50/313]  eta: 0:02:52  Lr: 0.001875  Loss: 0.8915  Acc@1: 93.7500 (78.6765)  Acc@5: 100.0000 (94.9755)  time: 0.6542  data: 0.0014  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 60/313]  eta: 0:02:46  Lr: 0.001875  Loss: 0.5953  Acc@1: 87.5000 (80.2254)  Acc@5: 100.0000 (95.5943)  time: 0.6548  data: 0.0028  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 70/313]  eta: 0:02:39  Lr: 0.001875  Loss: 1.0054  Acc@1: 87.5000 (81.1620)  Acc@5: 100.0000 (96.1268)  time: 0.6551  data: 0.0032  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 80/313]  eta: 0:02:32  Lr: 0.001875  Loss: 0.2186  Acc@1: 87.5000 (82.1759)  Acc@5: 100.0000 (96.3735)  time: 0.6552  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 90/313]  eta: 0:02:26  Lr: 0.001875  Loss: 0.2056  Acc@1: 93.7500 (83.3791)  Acc@5: 100.0000 (96.7033)  time: 0.6548  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[1/5]  [100/313]  eta: 0:02:19  Lr: 0.001875  Loss: 0.1176  Acc@1: 93.7500 (84.0347)  Acc@5: 100.0000 (96.8441)  time: 0.6549  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[1/5]  [110/313]  eta: 0:02:13  Lr: 0.001875  Loss: 0.4180  Acc@1: 87.5000 (84.2905)  Acc@5: 100.0000 (96.9595)  time: 0.6560  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[1/5]  [120/313]  eta: 0:02:06  Lr: 0.001875  Loss: 0.4044  Acc@1: 87.5000 (84.5558)  Acc@5: 100.0000 (97.1074)  time: 0.6559  data: 0.0010  max mem: 2373\n",
            "Train: Epoch[1/5]  [130/313]  eta: 0:02:00  Lr: 0.001875  Loss: 0.2457  Acc@1: 87.5000 (84.8760)  Acc@5: 100.0000 (97.1374)  time: 0.6558  data: 0.0011  max mem: 2373\n",
            "Train: Epoch[1/5]  [140/313]  eta: 0:01:53  Lr: 0.001875  Loss: 0.1068  Acc@1: 87.5000 (84.9734)  Acc@5: 100.0000 (97.2074)  time: 0.6560  data: 0.0014  max mem: 2373\n",
            "Train: Epoch[1/5]  [150/313]  eta: 0:01:46  Lr: 0.001875  Loss: 0.1577  Acc@1: 87.5000 (85.2649)  Acc@5: 100.0000 (97.2682)  time: 0.6558  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[1/5]  [160/313]  eta: 0:01:40  Lr: 0.001875  Loss: 0.4105  Acc@1: 87.5000 (85.4425)  Acc@5: 100.0000 (97.3991)  time: 0.6557  data: 0.0015  max mem: 2373\n",
            "Train: Epoch[1/5]  [170/313]  eta: 0:01:33  Lr: 0.001875  Loss: -0.0338  Acc@1: 87.5000 (85.7091)  Acc@5: 100.0000 (97.5146)  time: 0.6557  data: 0.0015  max mem: 2373\n",
            "Train: Epoch[1/5]  [180/313]  eta: 0:01:27  Lr: 0.001875  Loss: -0.0102  Acc@1: 87.5000 (85.9807)  Acc@5: 100.0000 (97.6174)  time: 0.6556  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[1/5]  [190/313]  eta: 0:01:20  Lr: 0.001875  Loss: 0.0770  Acc@1: 87.5000 (86.0929)  Acc@5: 100.0000 (97.5785)  time: 0.6558  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[1/5]  [200/313]  eta: 0:01:14  Lr: 0.001875  Loss: 0.2227  Acc@1: 93.7500 (86.4739)  Acc@5: 100.0000 (97.6679)  time: 0.6567  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[1/5]  [210/313]  eta: 0:01:07  Lr: 0.001875  Loss: 0.6319  Acc@1: 87.5000 (86.4929)  Acc@5: 100.0000 (97.7488)  time: 0.6568  data: 0.0031  max mem: 2373\n",
            "Train: Epoch[1/5]  [220/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.1296  Acc@1: 87.5000 (86.7081)  Acc@5: 100.0000 (97.8507)  time: 0.6563  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[1/5]  [230/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.1110  Acc@1: 87.5000 (86.9589)  Acc@5: 100.0000 (97.9437)  time: 0.6565  data: 0.0026  max mem: 2373\n",
            "Train: Epoch[1/5]  [240/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.0228  Acc@1: 93.7500 (87.1629)  Acc@5: 100.0000 (97.9512)  time: 0.6565  data: 0.0026  max mem: 2373\n",
            "Train: Epoch[1/5]  [250/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.2754  Acc@1: 93.7500 (87.3257)  Acc@5: 100.0000 (97.9582)  time: 0.6568  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[1/5]  [260/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.3752  Acc@1: 93.7500 (87.4521)  Acc@5: 100.0000 (97.9885)  time: 0.6570  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[1/5]  [270/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.4669  Acc@1: 93.7500 (87.6384)  Acc@5: 100.0000 (98.0397)  time: 0.6566  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[1/5]  [280/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.5168  Acc@1: 87.5000 (87.5890)  Acc@5: 100.0000 (98.0872)  time: 0.6572  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[1/5]  [290/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.0355  Acc@1: 87.5000 (87.6289)  Acc@5: 100.0000 (98.0885)  time: 0.6578  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[1/5]  [300/313]  eta: 0:00:08  Lr: 0.001875  Loss: -0.0144  Acc@1: 93.7500 (87.8322)  Acc@5: 100.0000 (98.1312)  time: 0.6581  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[1/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.4855  Acc@1: 93.7500 (87.9421)  Acc@5: 100.0000 (98.1913)  time: 0.6583  data: 0.0006  max mem: 2373\n",
            "Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1521  Acc@1: 93.7500 (87.9400)  Acc@5: 100.0000 (98.2000)  time: 0.6423  data: 0.0006  max mem: 2373\n",
            "Train: Epoch[1/5] Total time: 0:03:25 (0.6557 s / it)\n",
            "Averaged stats: Lr: 0.001875  Loss: -0.1521  Acc@1: 93.7500 (87.9400)  Acc@5: 100.0000 (98.2000)\n",
            "Train: Epoch[2/5]  [  0/313]  eta: 0:04:11  Lr: 0.001875  Loss: 0.2709  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.8040  data: 0.1874  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 10/313]  eta: 0:03:23  Lr: 0.001875  Loss: 0.2293  Acc@1: 87.5000 (86.9318)  Acc@5: 100.0000 (97.7273)  time: 0.6720  data: 0.0173  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 20/313]  eta: 0:03:14  Lr: 0.001875  Loss: 0.0481  Acc@1: 87.5000 (86.6071)  Acc@5: 100.0000 (98.2143)  time: 0.6582  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 30/313]  eta: 0:03:07  Lr: 0.001875  Loss: 0.0256  Acc@1: 93.7500 (88.7097)  Acc@5: 100.0000 (98.3871)  time: 0.6576  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 40/313]  eta: 0:03:00  Lr: 0.001875  Loss: -0.0574  Acc@1: 93.7500 (89.4817)  Acc@5: 100.0000 (98.3232)  time: 0.6580  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 50/313]  eta: 0:02:53  Lr: 0.001875  Loss: 0.4754  Acc@1: 87.5000 (88.1127)  Acc@5: 100.0000 (97.6716)  time: 0.6582  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 60/313]  eta: 0:02:47  Lr: 0.001875  Loss: 0.1869  Acc@1: 87.5000 (88.9344)  Acc@5: 100.0000 (97.9508)  time: 0.6582  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 70/313]  eta: 0:02:40  Lr: 0.001875  Loss: 0.0074  Acc@1: 93.7500 (89.1725)  Acc@5: 100.0000 (98.1514)  time: 0.6579  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 80/313]  eta: 0:02:33  Lr: 0.001875  Loss: 0.2563  Acc@1: 93.7500 (89.4290)  Acc@5: 100.0000 (98.1481)  time: 0.6580  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 90/313]  eta: 0:02:27  Lr: 0.001875  Loss: 0.1298  Acc@1: 93.7500 (89.6291)  Acc@5: 100.0000 (98.3516)  time: 0.6581  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[2/5]  [100/313]  eta: 0:02:20  Lr: 0.001875  Loss: 0.1274  Acc@1: 87.5000 (89.4183)  Acc@5: 100.0000 (98.3911)  time: 0.6582  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[2/5]  [110/313]  eta: 0:02:13  Lr: 0.001875  Loss: 0.5135  Acc@1: 87.5000 (89.1892)  Acc@5: 100.0000 (98.1982)  time: 0.6579  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[2/5]  [120/313]  eta: 0:02:07  Lr: 0.001875  Loss: -0.0230  Acc@1: 87.5000 (89.2045)  Acc@5: 100.0000 (98.1405)  time: 0.6568  data: 0.0027  max mem: 2373\n",
            "Train: Epoch[2/5]  [130/313]  eta: 0:02:00  Lr: 0.001875  Loss: 0.4517  Acc@1: 87.5000 (88.9313)  Acc@5: 100.0000 (98.1393)  time: 0.6565  data: 0.0027  max mem: 2373\n",
            "Train: Epoch[2/5]  [140/313]  eta: 0:01:53  Lr: 0.001875  Loss: 0.0164  Acc@1: 87.5000 (89.0071)  Acc@5: 100.0000 (98.2270)  time: 0.6569  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[2/5]  [150/313]  eta: 0:01:47  Lr: 0.001875  Loss: -0.0338  Acc@1: 87.5000 (88.9073)  Acc@5: 100.0000 (98.1788)  time: 0.6573  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[2/5]  [160/313]  eta: 0:01:40  Lr: 0.001875  Loss: 0.3850  Acc@1: 87.5000 (88.9363)  Acc@5: 100.0000 (98.2531)  time: 0.6564  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[2/5]  [170/313]  eta: 0:01:34  Lr: 0.001875  Loss: 0.0167  Acc@1: 93.7500 (88.9254)  Acc@5: 100.0000 (98.2822)  time: 0.6558  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[2/5]  [180/313]  eta: 0:01:27  Lr: 0.001875  Loss: 0.1853  Acc@1: 93.7500 (89.0539)  Acc@5: 100.0000 (98.3425)  time: 0.6554  data: 0.0015  max mem: 2373\n",
            "Train: Epoch[2/5]  [190/313]  eta: 0:01:20  Lr: 0.001875  Loss: 0.0181  Acc@1: 87.5000 (88.9725)  Acc@5: 100.0000 (98.3639)  time: 0.6553  data: 0.0014  max mem: 2373\n",
            "Train: Epoch[2/5]  [200/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.0236  Acc@1: 87.5000 (89.0236)  Acc@5: 100.0000 (98.3831)  time: 0.6556  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[2/5]  [210/313]  eta: 0:01:07  Lr: 0.001875  Loss: 0.2999  Acc@1: 93.7500 (89.1588)  Acc@5: 100.0000 (98.4301)  time: 0.6552  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[2/5]  [220/313]  eta: 0:01:01  Lr: 0.001875  Loss: -0.1386  Acc@1: 93.7500 (89.4231)  Acc@5: 100.0000 (98.5011)  time: 0.6547  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[2/5]  [230/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.1502  Acc@1: 93.7500 (89.5022)  Acc@5: 100.0000 (98.5119)  time: 0.6539  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[2/5]  [240/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.0841  Acc@1: 87.5000 (89.4710)  Acc@5: 100.0000 (98.4699)  time: 0.6546  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[2/5]  [250/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.2680  Acc@1: 87.5000 (89.5667)  Acc@5: 100.0000 (98.4562)  time: 0.6546  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[2/5]  [260/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.0587  Acc@1: 93.7500 (89.6073)  Acc@5: 100.0000 (98.4914)  time: 0.6540  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[2/5]  [270/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.1863  Acc@1: 87.5000 (89.5987)  Acc@5: 100.0000 (98.4779)  time: 0.6542  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[2/5]  [280/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.0722  Acc@1: 87.5000 (89.6575)  Acc@5: 100.0000 (98.4875)  time: 0.6537  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[2/5]  [290/313]  eta: 0:00:15  Lr: 0.001875  Loss: -0.1090  Acc@1: 87.5000 (89.5189)  Acc@5: 100.0000 (98.5180)  time: 0.6539  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[2/5]  [300/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.0279  Acc@1: 87.5000 (89.5764)  Acc@5: 100.0000 (98.4427)  time: 0.6540  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[2/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.4183  Acc@1: 87.5000 (89.4895)  Acc@5: 100.0000 (98.4727)  time: 0.6539  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1172  Acc@1: 87.5000 (89.5200)  Acc@5: 100.0000 (98.4800)  time: 0.6379  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[2/5] Total time: 0:03:25 (0.6558 s / it)\n",
            "Averaged stats: Lr: 0.001875  Loss: -0.1172  Acc@1: 87.5000 (89.5200)  Acc@5: 100.0000 (98.4800)\n",
            "Train: Epoch[3/5]  [  0/313]  eta: 0:03:54  Lr: 0.001875  Loss: 0.1827  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.7480  data: 0.1344  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 10/313]  eta: 0:03:20  Lr: 0.001875  Loss: 0.0102  Acc@1: 93.7500 (89.7727)  Acc@5: 100.0000 (98.8636)  time: 0.6633  data: 0.0148  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 20/313]  eta: 0:03:12  Lr: 0.001875  Loss: -0.0756  Acc@1: 93.7500 (90.4762)  Acc@5: 100.0000 (99.4048)  time: 0.6537  data: 0.0032  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 30/313]  eta: 0:03:05  Lr: 0.001875  Loss: 0.1659  Acc@1: 93.7500 (90.5242)  Acc@5: 100.0000 (99.1935)  time: 0.6539  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 40/313]  eta: 0:02:59  Lr: 0.001875  Loss: 0.0620  Acc@1: 87.5000 (90.3963)  Acc@5: 100.0000 (99.0854)  time: 0.6555  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 50/313]  eta: 0:02:52  Lr: 0.001875  Loss: -0.1981  Acc@1: 93.7500 (90.5637)  Acc@5: 100.0000 (98.7745)  time: 0.6554  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 60/313]  eta: 0:02:45  Lr: 0.001875  Loss: 0.2016  Acc@1: 93.7500 (90.5738)  Acc@5: 100.0000 (98.8730)  time: 0.6542  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 70/313]  eta: 0:02:39  Lr: 0.001875  Loss: 0.0958  Acc@1: 93.7500 (90.3169)  Acc@5: 100.0000 (98.7676)  time: 0.6538  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 80/313]  eta: 0:02:32  Lr: 0.001875  Loss: -0.1314  Acc@1: 87.5000 (90.4321)  Acc@5: 100.0000 (98.8426)  time: 0.6547  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 90/313]  eta: 0:02:26  Lr: 0.001875  Loss: 0.0913  Acc@1: 87.5000 (89.9038)  Acc@5: 100.0000 (98.7637)  time: 0.6554  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[3/5]  [100/313]  eta: 0:02:19  Lr: 0.001875  Loss: 0.1738  Acc@1: 93.7500 (90.3465)  Acc@5: 100.0000 (98.7624)  time: 0.6551  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[3/5]  [110/313]  eta: 0:02:13  Lr: 0.001875  Loss: 0.1481  Acc@1: 93.7500 (90.4279)  Acc@5: 100.0000 (98.7613)  time: 0.6552  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[3/5]  [120/313]  eta: 0:02:06  Lr: 0.001875  Loss: -0.1354  Acc@1: 93.7500 (90.5992)  Acc@5: 100.0000 (98.8636)  time: 0.6556  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[3/5]  [130/313]  eta: 0:01:59  Lr: 0.001875  Loss: -0.1164  Acc@1: 93.7500 (90.8397)  Acc@5: 100.0000 (98.9027)  time: 0.6553  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[3/5]  [140/313]  eta: 0:01:53  Lr: 0.001875  Loss: -0.1717  Acc@1: 93.7500 (90.8245)  Acc@5: 100.0000 (98.9805)  time: 0.6556  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[3/5]  [150/313]  eta: 0:01:46  Lr: 0.001875  Loss: 0.3423  Acc@1: 87.5000 (90.7699)  Acc@5: 100.0000 (99.0480)  time: 0.6557  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[3/5]  [160/313]  eta: 0:01:40  Lr: 0.001875  Loss: -0.1467  Acc@1: 87.5000 (90.7609)  Acc@5: 100.0000 (99.0683)  time: 0.6553  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[3/5]  [170/313]  eta: 0:01:33  Lr: 0.001875  Loss: 0.1274  Acc@1: 87.5000 (90.5336)  Acc@5: 100.0000 (98.9401)  time: 0.6554  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[3/5]  [180/313]  eta: 0:01:27  Lr: 0.001875  Loss: 0.2488  Acc@1: 87.5000 (90.4696)  Acc@5: 100.0000 (98.8605)  time: 0.6555  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[3/5]  [190/313]  eta: 0:01:20  Lr: 0.001875  Loss: 0.1191  Acc@1: 87.5000 (90.5432)  Acc@5: 100.0000 (98.8220)  time: 0.6558  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[3/5]  [200/313]  eta: 0:01:14  Lr: 0.001875  Loss: 0.2417  Acc@1: 87.5000 (90.6405)  Acc@5: 100.0000 (98.7562)  time: 0.6558  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[3/5]  [210/313]  eta: 0:01:07  Lr: 0.001875  Loss: 0.2592  Acc@1: 87.5000 (90.5806)  Acc@5: 100.0000 (98.7559)  time: 0.6557  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[3/5]  [220/313]  eta: 0:01:00  Lr: 0.001875  Loss: -0.0087  Acc@1: 87.5000 (90.5826)  Acc@5: 100.0000 (98.8122)  time: 0.6558  data: 0.0015  max mem: 2373\n",
            "Train: Epoch[3/5]  [230/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.1314  Acc@1: 93.7500 (90.4762)  Acc@5: 100.0000 (98.7825)  time: 0.6564  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[3/5]  [240/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.5550  Acc@1: 93.7500 (90.5083)  Acc@5: 100.0000 (98.8071)  time: 0.6568  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[3/5]  [250/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.2670  Acc@1: 93.7500 (90.5129)  Acc@5: 100.0000 (98.8297)  time: 0.6563  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[3/5]  [260/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.1746  Acc@1: 93.7500 (90.5651)  Acc@5: 100.0000 (98.8266)  time: 0.6559  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[3/5]  [270/313]  eta: 0:00:28  Lr: 0.001875  Loss: -0.0243  Acc@1: 93.7500 (90.6596)  Acc@5: 100.0000 (98.7546)  time: 0.6559  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[3/5]  [280/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.1769  Acc@1: 93.7500 (90.7028)  Acc@5: 100.0000 (98.7544)  time: 0.6561  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[3/5]  [290/313]  eta: 0:00:15  Lr: 0.001875  Loss: -0.1393  Acc@1: 93.7500 (90.8505)  Acc@5: 100.0000 (98.7973)  time: 0.6564  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[3/5]  [300/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.3838  Acc@1: 93.7500 (90.8846)  Acc@5: 100.0000 (98.7749)  time: 0.6565  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[3/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.3306  Acc@1: 87.5000 (90.9365)  Acc@5: 100.0000 (98.7741)  time: 0.6561  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.2081  Acc@1: 93.7500 (90.9600)  Acc@5: 100.0000 (98.7800)  time: 0.6402  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[3/5] Total time: 0:03:25 (0.6550 s / it)\n",
            "Averaged stats: Lr: 0.001875  Loss: 0.2081  Acc@1: 93.7500 (90.9600)  Acc@5: 100.0000 (98.7800)\n",
            "Train: Epoch[4/5]  [  0/313]  eta: 0:04:02  Lr: 0.001875  Loss: -0.0217  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.7747  data: 0.1620  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 10/313]  eta: 0:03:22  Lr: 0.001875  Loss: -0.1765  Acc@1: 93.7500 (92.0455)  Acc@5: 100.0000 (98.8636)  time: 0.6674  data: 0.0162  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 20/313]  eta: 0:03:13  Lr: 0.001875  Loss: 0.0024  Acc@1: 87.5000 (91.3690)  Acc@5: 100.0000 (98.8095)  time: 0.6560  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 30/313]  eta: 0:03:06  Lr: 0.001875  Loss: 0.2813  Acc@1: 93.7500 (91.1290)  Acc@5: 100.0000 (98.7903)  time: 0.6558  data: 0.0015  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 40/313]  eta: 0:02:59  Lr: 0.001875  Loss: 0.5285  Acc@1: 93.7500 (91.0061)  Acc@5: 100.0000 (98.4756)  time: 0.6561  data: 0.0015  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 50/313]  eta: 0:02:53  Lr: 0.001875  Loss: -0.2060  Acc@1: 93.7500 (91.1765)  Acc@5: 100.0000 (98.5294)  time: 0.6562  data: 0.0014  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 60/313]  eta: 0:02:46  Lr: 0.001875  Loss: 0.1729  Acc@1: 93.7500 (90.9836)  Acc@5: 100.0000 (98.7705)  time: 0.6561  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 70/313]  eta: 0:02:39  Lr: 0.001875  Loss: 0.0061  Acc@1: 93.7500 (90.6690)  Acc@5: 100.0000 (98.9437)  time: 0.6559  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 80/313]  eta: 0:02:33  Lr: 0.001875  Loss: -0.1137  Acc@1: 93.7500 (91.1265)  Acc@5: 100.0000 (98.9969)  time: 0.6560  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 90/313]  eta: 0:02:26  Lr: 0.001875  Loss: 0.4434  Acc@1: 93.7500 (90.9341)  Acc@5: 100.0000 (99.0385)  time: 0.6560  data: 0.0014  max mem: 2373\n",
            "Train: Epoch[4/5]  [100/313]  eta: 0:02:19  Lr: 0.001875  Loss: 0.0730  Acc@1: 87.5000 (90.5941)  Acc@5: 100.0000 (99.0099)  time: 0.6558  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[4/5]  [110/313]  eta: 0:02:13  Lr: 0.001875  Loss: -0.1146  Acc@1: 87.5000 (90.8221)  Acc@5: 100.0000 (99.0991)  time: 0.6559  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[4/5]  [120/313]  eta: 0:02:06  Lr: 0.001875  Loss: 0.3328  Acc@1: 93.7500 (90.9607)  Acc@5: 100.0000 (99.1736)  time: 0.6562  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[4/5]  [130/313]  eta: 0:02:00  Lr: 0.001875  Loss: 0.1468  Acc@1: 93.7500 (90.9351)  Acc@5: 100.0000 (99.2366)  time: 0.6561  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[4/5]  [140/313]  eta: 0:01:53  Lr: 0.001875  Loss: 0.4503  Acc@1: 87.5000 (90.8245)  Acc@5: 100.0000 (99.2465)  time: 0.6555  data: 0.0041  max mem: 2373\n",
            "Train: Epoch[4/5]  [150/313]  eta: 0:01:47  Lr: 0.001875  Loss: -0.0986  Acc@1: 93.7500 (90.9354)  Acc@5: 100.0000 (99.2964)  time: 0.6555  data: 0.0043  max mem: 2373\n",
            "Train: Epoch[4/5]  [160/313]  eta: 0:01:40  Lr: 0.001875  Loss: -0.0489  Acc@1: 93.7500 (90.9161)  Acc@5: 100.0000 (99.3012)  time: 0.6561  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[4/5]  [170/313]  eta: 0:01:33  Lr: 0.001875  Loss: -0.0212  Acc@1: 87.5000 (90.7529)  Acc@5: 100.0000 (99.3056)  time: 0.6561  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[4/5]  [180/313]  eta: 0:01:27  Lr: 0.001875  Loss: 0.6753  Acc@1: 87.5000 (90.5732)  Acc@5: 100.0000 (99.2058)  time: 0.6562  data: 0.0013  max mem: 2373\n",
            "Train: Epoch[4/5]  [190/313]  eta: 0:01:20  Lr: 0.001875  Loss: 0.1528  Acc@1: 87.5000 (90.4123)  Acc@5: 100.0000 (99.2147)  time: 0.6561  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[4/5]  [200/313]  eta: 0:01:14  Lr: 0.001875  Loss: 0.1985  Acc@1: 87.5000 (90.2674)  Acc@5: 100.0000 (99.1915)  time: 0.6558  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[4/5]  [210/313]  eta: 0:01:07  Lr: 0.001875  Loss: 0.0790  Acc@1: 93.7500 (90.3140)  Acc@5: 100.0000 (99.1706)  time: 0.6566  data: 0.0026  max mem: 2373\n",
            "Train: Epoch[4/5]  [220/313]  eta: 0:01:01  Lr: 0.001875  Loss: -0.0422  Acc@1: 93.7500 (90.3563)  Acc@5: 100.0000 (99.2081)  time: 0.6568  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[4/5]  [230/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.1075  Acc@1: 93.7500 (90.4221)  Acc@5: 100.0000 (99.1342)  time: 0.6560  data: 0.0013  max mem: 2373\n",
            "Train: Epoch[4/5]  [240/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.1108  Acc@1: 93.7500 (90.5342)  Acc@5: 100.0000 (99.1442)  time: 0.6559  data: 0.0012  max mem: 2373\n",
            "Train: Epoch[4/5]  [250/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.2832  Acc@1: 93.7500 (90.4382)  Acc@5: 100.0000 (99.1783)  time: 0.6567  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[4/5]  [260/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.0425  Acc@1: 87.5000 (90.4454)  Acc@5: 100.0000 (99.1858)  time: 0.6565  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[4/5]  [270/313]  eta: 0:00:28  Lr: 0.001875  Loss: -0.1298  Acc@1: 93.7500 (90.5443)  Acc@5: 100.0000 (99.1928)  time: 0.6558  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[4/5]  [280/313]  eta: 0:00:21  Lr: 0.001875  Loss: -0.0484  Acc@1: 93.7500 (90.5027)  Acc@5: 100.0000 (99.2215)  time: 0.6558  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[4/5]  [290/313]  eta: 0:00:15  Lr: 0.001875  Loss: -0.1301  Acc@1: 87.5000 (90.4639)  Acc@5: 100.0000 (99.2268)  time: 0.6561  data: 0.0026  max mem: 2373\n",
            "Train: Epoch[4/5]  [300/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.0492  Acc@1: 87.5000 (90.3239)  Acc@5: 100.0000 (99.1902)  time: 0.6564  data: 0.0026  max mem: 2373\n",
            "Train: Epoch[4/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.1919  Acc@1: 87.5000 (90.3135)  Acc@5: 100.0000 (99.1760)  time: 0.6561  data: 0.0015  max mem: 2373\n",
            "Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.1540  Acc@1: 87.5000 (90.2800)  Acc@5: 100.0000 (99.1800)  time: 0.6398  data: 0.0015  max mem: 2373\n",
            "Train: Epoch[4/5] Total time: 0:03:25 (0.6557 s / it)\n",
            "Averaged stats: Lr: 0.001875  Loss: 0.1540  Acc@1: 87.5000 (90.2800)  Acc@5: 100.0000 (99.1800)\n",
            "Train: Epoch[5/5]  [  0/313]  eta: 0:04:16  Lr: 0.001875  Loss: 0.2994  Acc@1: 93.7500 (93.7500)  Acc@5: 93.7500 (93.7500)  time: 0.8195  data: 0.2036  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 10/313]  eta: 0:03:23  Lr: 0.001875  Loss: 0.0731  Acc@1: 93.7500 (89.7727)  Acc@5: 100.0000 (98.2955)  time: 0.6721  data: 0.0194  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 20/313]  eta: 0:03:14  Lr: 0.001875  Loss: -0.0727  Acc@1: 87.5000 (88.9881)  Acc@5: 100.0000 (98.5119)  time: 0.6574  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 30/313]  eta: 0:03:07  Lr: 0.001875  Loss: 0.2572  Acc@1: 93.7500 (91.1290)  Acc@5: 100.0000 (98.9919)  time: 0.6567  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 40/313]  eta: 0:03:00  Lr: 0.001875  Loss: 0.1678  Acc@1: 93.7500 (92.0732)  Acc@5: 100.0000 (99.0854)  time: 0.6561  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 50/313]  eta: 0:02:53  Lr: 0.001875  Loss: 0.0222  Acc@1: 93.7500 (92.0343)  Acc@5: 100.0000 (99.1422)  time: 0.6563  data: 0.0015  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 60/313]  eta: 0:02:46  Lr: 0.001875  Loss: -0.0819  Acc@1: 93.7500 (92.0082)  Acc@5: 100.0000 (99.2828)  time: 0.6564  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 70/313]  eta: 0:02:40  Lr: 0.001875  Loss: -0.0751  Acc@1: 93.7500 (91.7254)  Acc@5: 100.0000 (99.3838)  time: 0.6565  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 80/313]  eta: 0:02:33  Lr: 0.001875  Loss: 0.0434  Acc@1: 93.7500 (91.8981)  Acc@5: 100.0000 (99.3056)  time: 0.6565  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 90/313]  eta: 0:02:26  Lr: 0.001875  Loss: 0.1026  Acc@1: 93.7500 (91.8269)  Acc@5: 100.0000 (99.3132)  time: 0.6566  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[5/5]  [100/313]  eta: 0:02:20  Lr: 0.001875  Loss: -0.1638  Acc@1: 93.7500 (92.0173)  Acc@5: 100.0000 (99.3812)  time: 0.6571  data: 0.0014  max mem: 2373\n",
            "Train: Epoch[5/5]  [110/313]  eta: 0:02:13  Lr: 0.001875  Loss: -0.0081  Acc@1: 93.7500 (91.8919)  Acc@5: 100.0000 (99.3243)  time: 0.6572  data: 0.0013  max mem: 2373\n",
            "Train: Epoch[5/5]  [120/313]  eta: 0:02:06  Lr: 0.001875  Loss: -0.0310  Acc@1: 93.7500 (91.7872)  Acc@5: 100.0000 (99.3285)  time: 0.6564  data: 0.0015  max mem: 2373\n",
            "Train: Epoch[5/5]  [130/313]  eta: 0:02:00  Lr: 0.001875  Loss: 0.0320  Acc@1: 87.5000 (91.4599)  Acc@5: 100.0000 (99.2366)  time: 0.6564  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[5/5]  [140/313]  eta: 0:01:53  Lr: 0.001875  Loss: 0.3380  Acc@1: 87.5000 (91.3564)  Acc@5: 100.0000 (99.2465)  time: 0.6563  data: 0.0030  max mem: 2373\n",
            "Train: Epoch[5/5]  [150/313]  eta: 0:01:47  Lr: 0.001875  Loss: 0.2234  Acc@1: 93.7500 (91.3907)  Acc@5: 100.0000 (99.2136)  time: 0.6564  data: 0.0030  max mem: 2373\n",
            "Train: Epoch[5/5]  [160/313]  eta: 0:01:40  Lr: 0.001875  Loss: -0.1495  Acc@1: 93.7500 (91.3820)  Acc@5: 100.0000 (99.2236)  time: 0.6572  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[5/5]  [170/313]  eta: 0:01:34  Lr: 0.001875  Loss: -0.1389  Acc@1: 87.5000 (91.1915)  Acc@5: 100.0000 (99.2325)  time: 0.6574  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[5/5]  [180/313]  eta: 0:01:27  Lr: 0.001875  Loss: -0.1530  Acc@1: 93.7500 (91.4365)  Acc@5: 100.0000 (99.2749)  time: 0.6571  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[5/5]  [190/313]  eta: 0:01:20  Lr: 0.001875  Loss: -0.0252  Acc@1: 93.7500 (91.3285)  Acc@5: 100.0000 (99.1819)  time: 0.6577  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[5/5]  [200/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.0436  Acc@1: 87.5000 (91.2935)  Acc@5: 100.0000 (99.1604)  time: 0.6580  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[5/5]  [210/313]  eta: 0:01:07  Lr: 0.001875  Loss: 0.0436  Acc@1: 87.5000 (91.1137)  Acc@5: 100.0000 (99.1706)  time: 0.6572  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[5/5]  [220/313]  eta: 0:01:01  Lr: 0.001875  Loss: -0.1177  Acc@1: 93.7500 (91.1482)  Acc@5: 100.0000 (99.1799)  time: 0.6570  data: 0.0027  max mem: 2373\n",
            "Train: Epoch[5/5]  [230/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.0523  Acc@1: 93.7500 (91.2067)  Acc@5: 100.0000 (99.2154)  time: 0.6571  data: 0.0027  max mem: 2373\n",
            "Train: Epoch[5/5]  [240/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.0438  Acc@1: 93.7500 (91.1566)  Acc@5: 100.0000 (99.1701)  time: 0.6567  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[5/5]  [250/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.0671  Acc@1: 93.7500 (91.0857)  Acc@5: 100.0000 (99.1285)  time: 0.6569  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[5/5]  [260/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.0273  Acc@1: 93.7500 (91.0920)  Acc@5: 100.0000 (99.1619)  time: 0.6577  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[5/5]  [270/313]  eta: 0:00:28  Lr: 0.001875  Loss: -0.1558  Acc@1: 93.7500 (91.2362)  Acc@5: 100.0000 (99.1928)  time: 0.6574  data: 0.0037  max mem: 2373\n",
            "Train: Epoch[5/5]  [280/313]  eta: 0:00:21  Lr: 0.001875  Loss: -0.1149  Acc@1: 93.7500 (91.3256)  Acc@5: 100.0000 (99.1770)  time: 0.6566  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[5/5]  [290/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.0086  Acc@1: 93.7500 (91.3015)  Acc@5: 100.0000 (99.2053)  time: 0.6569  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[5/5]  [300/313]  eta: 0:00:08  Lr: 0.001875  Loss: -0.0611  Acc@1: 93.7500 (91.3829)  Acc@5: 100.0000 (99.1694)  time: 0.6577  data: 0.0014  max mem: 2373\n",
            "Train: Epoch[5/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: -0.1625  Acc@1: 93.7500 (91.3786)  Acc@5: 100.0000 (99.1559)  time: 0.6576  data: 0.0013  max mem: 2373\n",
            "Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.0493  Acc@1: 93.7500 (91.3600)  Acc@5: 100.0000 (99.1600)  time: 0.6415  data: 0.0013  max mem: 2373\n",
            "Train: Epoch[5/5] Total time: 0:03:25 (0.6567 s / it)\n",
            "Averaged stats: Lr: 0.001875  Loss: 0.0493  Acc@1: 93.7500 (91.3600)  Acc@5: 100.0000 (99.1600)\n",
            "Test: [Task 1]  [ 0/63]  eta: 0:00:33  Loss: 1.0659 (1.0659)  Acc@1: 75.0000 (75.0000)  Acc@5: 87.5000 (87.5000)  time: 0.5357  data: 0.1441  max mem: 2373\n",
            "Test: [Task 1]  [10/63]  eta: 0:00:23  Loss: 0.6852 (0.6780)  Acc@1: 87.5000 (82.9545)  Acc@5: 100.0000 (97.7273)  time: 0.4376  data: 0.0134  max mem: 2373\n",
            "Test: [Task 1]  [20/63]  eta: 0:00:18  Loss: 0.6852 (0.7211)  Acc@1: 81.2500 (80.9524)  Acc@5: 100.0000 (97.3214)  time: 0.4275  data: 0.0026  max mem: 2373\n",
            "Test: [Task 1]  [30/63]  eta: 0:00:14  Loss: 0.6866 (0.7076)  Acc@1: 81.2500 (81.6532)  Acc@5: 100.0000 (97.7823)  time: 0.4261  data: 0.0027  max mem: 2373\n",
            "Test: [Task 1]  [40/63]  eta: 0:00:09  Loss: 0.5511 (0.6916)  Acc@1: 81.2500 (82.3171)  Acc@5: 100.0000 (98.0183)  time: 0.4256  data: 0.0005  max mem: 2373\n",
            "Test: [Task 1]  [50/63]  eta: 0:00:05  Loss: 0.5522 (0.6683)  Acc@1: 87.5000 (83.2108)  Acc@5: 100.0000 (98.0392)  time: 0.4262  data: 0.0024  max mem: 2373\n",
            "Test: [Task 1]  [60/63]  eta: 0:00:01  Loss: 0.5522 (0.6515)  Acc@1: 87.5000 (84.0164)  Acc@5: 100.0000 (97.9508)  time: 0.4266  data: 0.0031  max mem: 2373\n",
            "Test: [Task 1]  [62/63]  eta: 0:00:00  Loss: 0.4995 (0.6456)  Acc@1: 87.5000 (84.4000)  Acc@5: 100.0000 (98.0000)  time: 0.4159  data: 0.0030  max mem: 2373\n",
            "Test: [Task 1] Total time: 0:00:26 (0.4258 s / it)\n",
            "* Acc@1 84.400 Acc@5 98.000 loss 0.646\n",
            "Test: [Task 2]  [ 0/63]  eta: 0:00:37  Loss: 1.1099 (1.1099)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)  time: 0.5913  data: 0.1903  max mem: 2373\n",
            "Test: [Task 2]  [10/63]  eta: 0:00:23  Loss: 0.7431 (0.7675)  Acc@1: 87.5000 (84.0909)  Acc@5: 100.0000 (97.7273)  time: 0.4431  data: 0.0176  max mem: 2373\n",
            "Test: [Task 2]  [20/63]  eta: 0:00:18  Loss: 0.7432 (0.8279)  Acc@1: 81.2500 (80.9524)  Acc@5: 100.0000 (96.4286)  time: 0.4275  data: 0.0020  max mem: 2373\n",
            "Test: [Task 2]  [30/63]  eta: 0:00:14  Loss: 0.7834 (0.8022)  Acc@1: 81.2500 (82.2581)  Acc@5: 93.7500 (96.3710)  time: 0.4265  data: 0.0022  max mem: 2373\n",
            "Test: [Task 2]  [40/63]  eta: 0:00:09  Loss: 0.7058 (0.7888)  Acc@1: 87.5000 (82.7744)  Acc@5: 100.0000 (96.4939)  time: 0.4266  data: 0.0006  max mem: 2373\n",
            "Test: [Task 2]  [50/63]  eta: 0:00:05  Loss: 0.6780 (0.7777)  Acc@1: 81.2500 (81.9853)  Acc@5: 100.0000 (96.5686)  time: 0.4261  data: 0.0025  max mem: 2373\n",
            "Test: [Task 2]  [60/63]  eta: 0:00:01  Loss: 0.6925 (0.7647)  Acc@1: 81.2500 (82.4795)  Acc@5: 100.0000 (96.8238)  time: 0.4257  data: 0.0029  max mem: 2373\n",
            "Test: [Task 2]  [62/63]  eta: 0:00:00  Loss: 0.6676 (0.7561)  Acc@1: 81.2500 (82.6000)  Acc@5: 100.0000 (96.9000)  time: 0.4154  data: 0.0028  max mem: 2373\n",
            "Test: [Task 2] Total time: 0:00:26 (0.4267 s / it)\n",
            "* Acc@1 82.600 Acc@5 96.900 loss 0.756\n",
            "Test: [Task 3]  [ 0/63]  eta: 0:00:40  Loss: 0.4320 (0.4320)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.6427  data: 0.2509  max mem: 2373\n",
            "Test: [Task 3]  [10/63]  eta: 0:00:23  Loss: 0.6377 (0.6638)  Acc@1: 81.2500 (83.5227)  Acc@5: 100.0000 (97.1591)  time: 0.4456  data: 0.0233  max mem: 2373\n",
            "Test: [Task 3]  [20/63]  eta: 0:00:18  Loss: 0.7332 (0.6729)  Acc@1: 81.2500 (82.7381)  Acc@5: 93.7500 (96.7262)  time: 0.4264  data: 0.0022  max mem: 2373\n",
            "Test: [Task 3]  [30/63]  eta: 0:00:14  Loss: 0.7161 (0.6882)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (97.3790)  time: 0.4265  data: 0.0022  max mem: 2373\n",
            "Test: [Task 3]  [40/63]  eta: 0:00:09  Loss: 0.6848 (0.6755)  Acc@1: 81.2500 (82.1646)  Acc@5: 100.0000 (97.2561)  time: 0.4258  data: 0.0005  max mem: 2373\n",
            "Test: [Task 3]  [50/63]  eta: 0:00:05  Loss: 0.6965 (0.6829)  Acc@1: 81.2500 (82.4755)  Acc@5: 93.7500 (97.0588)  time: 0.4246  data: 0.0017  max mem: 2373\n",
            "Test: [Task 3]  [60/63]  eta: 0:00:01  Loss: 0.7669 (0.7030)  Acc@1: 81.2500 (81.9672)  Acc@5: 93.7500 (96.9262)  time: 0.4248  data: 0.0028  max mem: 2373\n",
            "Test: [Task 3]  [62/63]  eta: 0:00:00  Loss: 0.7561 (0.6990)  Acc@1: 81.2500 (81.8000)  Acc@5: 93.7500 (96.9000)  time: 0.4142  data: 0.0028  max mem: 2373\n",
            "Test: [Task 3] Total time: 0:00:26 (0.4266 s / it)\n",
            "* Acc@1 81.800 Acc@5 96.900 loss 0.699\n",
            "Test: [Task 4]  [ 0/63]  eta: 0:00:34  Loss: 0.7772 (0.7772)  Acc@1: 87.5000 (87.5000)  Acc@5: 93.7500 (93.7500)  time: 0.5400  data: 0.1440  max mem: 2373\n",
            "Test: [Task 4]  [10/63]  eta: 0:00:23  Loss: 0.7886 (0.7727)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (94.8864)  time: 0.4375  data: 0.0136  max mem: 2373\n",
            "Test: [Task 4]  [20/63]  eta: 0:00:18  Loss: 0.7470 (0.7635)  Acc@1: 81.2500 (80.3571)  Acc@5: 93.7500 (94.9405)  time: 0.4273  data: 0.0018  max mem: 2373\n",
            "Test: [Task 4]  [30/63]  eta: 0:00:14  Loss: 0.6715 (0.7394)  Acc@1: 81.2500 (81.4516)  Acc@5: 93.7500 (95.1613)  time: 0.4270  data: 0.0021  max mem: 2373\n",
            "Test: [Task 4]  [40/63]  eta: 0:00:09  Loss: 0.4202 (0.6674)  Acc@1: 87.5000 (83.5366)  Acc@5: 100.0000 (96.1890)  time: 0.4259  data: 0.0010  max mem: 2373\n",
            "Test: [Task 4]  [50/63]  eta: 0:00:05  Loss: 0.4348 (0.6819)  Acc@1: 87.5000 (83.7010)  Acc@5: 100.0000 (95.7108)  time: 0.4243  data: 0.0020  max mem: 2373\n",
            "Test: [Task 4]  [60/63]  eta: 0:00:01  Loss: 0.5614 (0.6824)  Acc@1: 87.5000 (83.7090)  Acc@5: 93.7500 (95.6967)  time: 0.4248  data: 0.0031  max mem: 2373\n",
            "Test: [Task 4]  [62/63]  eta: 0:00:00  Loss: 0.5971 (0.6830)  Acc@1: 87.5000 (83.8000)  Acc@5: 100.0000 (95.8000)  time: 0.4141  data: 0.0031  max mem: 2373\n",
            "Test: [Task 4] Total time: 0:00:26 (0.4253 s / it)\n",
            "* Acc@1 83.800 Acc@5 95.800 loss 0.683\n",
            "Test: [Task 5]  [ 0/63]  eta: 0:00:33  Loss: 0.3469 (0.3469)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.5328  data: 0.1400  max mem: 2373\n",
            "Test: [Task 5]  [10/63]  eta: 0:00:23  Loss: 0.5137 (0.5924)  Acc@1: 93.7500 (89.7727)  Acc@5: 100.0000 (97.7273)  time: 0.4355  data: 0.0138  max mem: 2373\n",
            "Test: [Task 5]  [20/63]  eta: 0:00:18  Loss: 0.5137 (0.5598)  Acc@1: 87.5000 (90.7738)  Acc@5: 100.0000 (97.6190)  time: 0.4270  data: 0.0023  max mem: 2373\n",
            "Test: [Task 5]  [30/63]  eta: 0:00:14  Loss: 0.5199 (0.5709)  Acc@1: 87.5000 (89.3145)  Acc@5: 100.0000 (97.5806)  time: 0.4273  data: 0.0027  max mem: 2373\n",
            "Test: [Task 5]  [40/63]  eta: 0:00:09  Loss: 0.4595 (0.5503)  Acc@1: 87.5000 (89.6341)  Acc@5: 100.0000 (97.7134)  time: 0.4265  data: 0.0014  max mem: 2373\n",
            "Test: [Task 5]  [50/63]  eta: 0:00:05  Loss: 0.4957 (0.5570)  Acc@1: 87.5000 (89.4608)  Acc@5: 100.0000 (97.7941)  time: 0.4259  data: 0.0022  max mem: 2373\n",
            "Test: [Task 5]  [60/63]  eta: 0:00:01  Loss: 0.5016 (0.5617)  Acc@1: 87.5000 (88.9344)  Acc@5: 100.0000 (97.5410)  time: 0.4258  data: 0.0026  max mem: 2373\n",
            "Test: [Task 5]  [62/63]  eta: 0:00:00  Loss: 0.5206 (0.5793)  Acc@1: 87.5000 (88.6000)  Acc@5: 100.0000 (97.4000)  time: 0.4150  data: 0.0026  max mem: 2373\n",
            "Test: [Task 5] Total time: 0:00:26 (0.4255 s / it)\n",
            "* Acc@1 88.600 Acc@5 97.400 loss 0.579\n",
            "Test: [Task 6]  [ 0/63]  eta: 0:00:38  Loss: 0.6067 (0.6067)  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (100.0000)  time: 0.6076  data: 0.2142  max mem: 2373\n",
            "Test: [Task 6]  [10/63]  eta: 0:00:23  Loss: 0.7026 (0.7007)  Acc@1: 81.2500 (80.1136)  Acc@5: 100.0000 (96.5909)  time: 0.4428  data: 0.0199  max mem: 2373\n",
            "Test: [Task 6]  [20/63]  eta: 0:00:18  Loss: 0.7196 (0.7563)  Acc@1: 81.2500 (79.1667)  Acc@5: 100.0000 (96.7262)  time: 0.4267  data: 0.0011  max mem: 2373\n",
            "Test: [Task 6]  [30/63]  eta: 0:00:14  Loss: 0.7000 (0.7492)  Acc@1: 81.2500 (79.2339)  Acc@5: 100.0000 (97.7823)  time: 0.4267  data: 0.0021  max mem: 2373\n",
            "Test: [Task 6]  [40/63]  eta: 0:00:09  Loss: 0.7083 (0.7818)  Acc@1: 75.0000 (77.5915)  Acc@5: 100.0000 (97.4085)  time: 0.4259  data: 0.0020  max mem: 2373\n",
            "Test: [Task 6]  [50/63]  eta: 0:00:05  Loss: 0.7835 (0.7666)  Acc@1: 75.0000 (78.3088)  Acc@5: 100.0000 (97.6716)  time: 0.4254  data: 0.0013  max mem: 2373\n",
            "Test: [Task 6]  [60/63]  eta: 0:00:01  Loss: 0.7835 (0.7847)  Acc@1: 81.2500 (78.0738)  Acc@5: 100.0000 (97.4385)  time: 0.4255  data: 0.0019  max mem: 2373\n",
            "Test: [Task 6]  [62/63]  eta: 0:00:00  Loss: 0.7835 (0.7818)  Acc@1: 81.2500 (78.3000)  Acc@5: 100.0000 (97.5000)  time: 0.4150  data: 0.0019  max mem: 2373\n",
            "Test: [Task 6] Total time: 0:00:26 (0.4264 s / it)\n",
            "* Acc@1 78.300 Acc@5 97.500 loss 0.782\n",
            "Test: [Task 7]  [ 0/63]  eta: 0:00:37  Loss: 0.7932 (0.7932)  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (100.0000)  time: 0.6006  data: 0.2066  max mem: 2373\n",
            "Test: [Task 7]  [10/63]  eta: 0:00:23  Loss: 0.5911 (0.6270)  Acc@1: 81.2500 (81.8182)  Acc@5: 100.0000 (98.2955)  time: 0.4420  data: 0.0198  max mem: 2373\n",
            "Test: [Task 7]  [20/63]  eta: 0:00:18  Loss: 0.6091 (0.6958)  Acc@1: 81.2500 (82.1429)  Acc@5: 100.0000 (96.4286)  time: 0.4265  data: 0.0022  max mem: 2373\n",
            "Test: [Task 7]  [30/63]  eta: 0:00:14  Loss: 0.6603 (0.6806)  Acc@1: 81.2500 (81.8548)  Acc@5: 100.0000 (96.7742)  time: 0.4260  data: 0.0036  max mem: 2373\n",
            "Test: [Task 7]  [40/63]  eta: 0:00:09  Loss: 0.6369 (0.6801)  Acc@1: 81.2500 (82.4695)  Acc@5: 100.0000 (96.3415)  time: 0.4256  data: 0.0022  max mem: 2373\n",
            "Test: [Task 7]  [50/63]  eta: 0:00:05  Loss: 0.6894 (0.7050)  Acc@1: 81.2500 (81.7402)  Acc@5: 93.7500 (95.9559)  time: 0.4258  data: 0.0005  max mem: 2373\n",
            "Test: [Task 7]  [60/63]  eta: 0:00:01  Loss: 0.6894 (0.6938)  Acc@1: 81.2500 (81.9672)  Acc@5: 100.0000 (96.0041)  time: 0.4259  data: 0.0017  max mem: 2373\n",
            "Test: [Task 7]  [62/63]  eta: 0:00:00  Loss: 0.7291 (0.6975)  Acc@1: 81.2500 (81.9000)  Acc@5: 100.0000 (96.0000)  time: 0.4152  data: 0.0017  max mem: 2373\n",
            "Test: [Task 7] Total time: 0:00:26 (0.4262 s / it)\n",
            "* Acc@1 81.900 Acc@5 96.000 loss 0.697\n",
            "Test: [Task 8]  [ 0/63]  eta: 0:00:33  Loss: 0.4819 (0.4819)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.5389  data: 0.1435  max mem: 2373\n",
            "Test: [Task 8]  [10/63]  eta: 0:00:23  Loss: 0.5818 (0.6597)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (97.7273)  time: 0.4370  data: 0.0137  max mem: 2373\n",
            "Test: [Task 8]  [20/63]  eta: 0:00:18  Loss: 0.6160 (0.7047)  Acc@1: 81.2500 (81.5476)  Acc@5: 100.0000 (96.1310)  time: 0.4275  data: 0.0010  max mem: 2373\n",
            "Test: [Task 8]  [30/63]  eta: 0:00:14  Loss: 0.5709 (0.6671)  Acc@1: 87.5000 (83.0645)  Acc@5: 100.0000 (96.9758)  time: 0.4278  data: 0.0020  max mem: 2373\n",
            "Test: [Task 8]  [40/63]  eta: 0:00:09  Loss: 0.5709 (0.6656)  Acc@1: 87.5000 (83.3841)  Acc@5: 100.0000 (96.7988)  time: 0.4267  data: 0.0017  max mem: 2373\n",
            "Test: [Task 8]  [50/63]  eta: 0:00:05  Loss: 0.6909 (0.6661)  Acc@1: 81.2500 (82.5980)  Acc@5: 93.7500 (96.6912)  time: 0.4261  data: 0.0008  max mem: 2373\n",
            "Test: [Task 8]  [60/63]  eta: 0:00:01  Loss: 0.7339 (0.6919)  Acc@1: 81.2500 (82.3770)  Acc@5: 93.7500 (96.1066)  time: 0.4263  data: 0.0013  max mem: 2373\n",
            "Test: [Task 8]  [62/63]  eta: 0:00:00  Loss: 0.7300 (0.6839)  Acc@1: 81.2500 (82.6000)  Acc@5: 93.7500 (96.2000)  time: 0.4154  data: 0.0012  max mem: 2373\n",
            "Test: [Task 8] Total time: 0:00:26 (0.4261 s / it)\n",
            "* Acc@1 82.600 Acc@5 96.200 loss 0.684\n",
            "Test: [Task 9]  [ 0/63]  eta: 0:00:33  Loss: 0.1421 (0.1421)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.5279  data: 0.1338  max mem: 2373\n",
            "Test: [Task 9]  [10/63]  eta: 0:00:23  Loss: 0.4052 (0.4354)  Acc@1: 87.5000 (89.7727)  Acc@5: 100.0000 (99.4318)  time: 0.4368  data: 0.0127  max mem: 2373\n",
            "Test: [Task 9]  [20/63]  eta: 0:00:18  Loss: 0.4052 (0.4598)  Acc@1: 87.5000 (88.0952)  Acc@5: 100.0000 (99.4048)  time: 0.4283  data: 0.0009  max mem: 2373\n",
            "Test: [Task 9]  [30/63]  eta: 0:00:14  Loss: 0.3681 (0.4205)  Acc@1: 87.5000 (89.3145)  Acc@5: 100.0000 (99.5968)  time: 0.4277  data: 0.0028  max mem: 2373\n",
            "Test: [Task 9]  [40/63]  eta: 0:00:09  Loss: 0.3092 (0.4235)  Acc@1: 93.7500 (89.1768)  Acc@5: 100.0000 (99.5427)  time: 0.4258  data: 0.0024  max mem: 2373\n",
            "Test: [Task 9]  [50/63]  eta: 0:00:05  Loss: 0.3951 (0.4248)  Acc@1: 87.5000 (89.2157)  Acc@5: 100.0000 (99.2647)  time: 0.4261  data: 0.0006  max mem: 2373\n",
            "Test: [Task 9]  [60/63]  eta: 0:00:01  Loss: 0.3406 (0.4039)  Acc@1: 93.7500 (90.0615)  Acc@5: 100.0000 (99.2828)  time: 0.4273  data: 0.0014  max mem: 2373\n",
            "Test: [Task 9]  [62/63]  eta: 0:00:00  Loss: 0.2631 (0.3966)  Acc@1: 93.7500 (90.3000)  Acc@5: 100.0000 (99.3000)  time: 0.4161  data: 0.0014  max mem: 2373\n",
            "Test: [Task 9] Total time: 0:00:26 (0.4262 s / it)\n",
            "* Acc@1 90.300 Acc@5 99.300 loss 0.397\n",
            "[Average accuracy till task9]\tAcc@1: 83.8111\tAcc@5: 97.1111\tLoss: 0.6581\tForgetting: 6.8625\tBackward: -6.7125\n",
            "Train: Epoch[1/5]  [  0/313]  eta: 0:04:31  Lr: 0.001875  Loss: 2.0645  Acc@1: 0.0000 (0.0000)  Acc@5: 81.2500 (81.2500)  time: 0.8665  data: 0.2541  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 10/313]  eta: 0:03:25  Lr: 0.001875  Loss: 1.6810  Acc@1: 62.5000 (56.2500)  Acc@5: 93.7500 (90.3409)  time: 0.6774  data: 0.0246  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 20/313]  eta: 0:03:15  Lr: 0.001875  Loss: 1.4092  Acc@1: 81.2500 (72.0238)  Acc@5: 93.7500 (93.7500)  time: 0.6570  data: 0.0027  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 30/313]  eta: 0:03:07  Lr: 0.001875  Loss: 0.8570  Acc@1: 87.5000 (77.6210)  Acc@5: 100.0000 (95.5645)  time: 0.6558  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 40/313]  eta: 0:03:00  Lr: 0.001875  Loss: 0.8496  Acc@1: 87.5000 (79.4207)  Acc@5: 100.0000 (95.7317)  time: 0.6562  data: 0.0026  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 50/313]  eta: 0:02:53  Lr: 0.001875  Loss: 0.5626  Acc@1: 87.5000 (81.3725)  Acc@5: 100.0000 (96.2010)  time: 0.6565  data: 0.0026  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 60/313]  eta: 0:02:47  Lr: 0.001875  Loss: 0.6863  Acc@1: 93.7500 (83.7090)  Acc@5: 100.0000 (96.7213)  time: 0.6569  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 70/313]  eta: 0:02:40  Lr: 0.001875  Loss: 0.3968  Acc@1: 93.7500 (84.7711)  Acc@5: 100.0000 (97.0951)  time: 0.6572  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 80/313]  eta: 0:02:33  Lr: 0.001875  Loss: 0.6339  Acc@1: 87.5000 (85.2623)  Acc@5: 100.0000 (97.3765)  time: 0.6577  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[1/5]  [ 90/313]  eta: 0:02:27  Lr: 0.001875  Loss: 0.7516  Acc@1: 87.5000 (85.8516)  Acc@5: 100.0000 (97.6648)  time: 0.6578  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[1/5]  [100/313]  eta: 0:02:20  Lr: 0.001875  Loss: 0.0217  Acc@1: 93.7500 (86.5099)  Acc@5: 100.0000 (97.7104)  time: 0.6582  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[1/5]  [110/313]  eta: 0:02:13  Lr: 0.001875  Loss: 0.4061  Acc@1: 93.7500 (87.1622)  Acc@5: 100.0000 (97.9167)  time: 0.6584  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[1/5]  [120/313]  eta: 0:02:07  Lr: 0.001875  Loss: 0.3011  Acc@1: 93.7500 (87.7066)  Acc@5: 100.0000 (97.9339)  time: 0.6581  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[1/5]  [130/313]  eta: 0:02:00  Lr: 0.001875  Loss: 0.3857  Acc@1: 93.7500 (88.2156)  Acc@5: 100.0000 (98.0439)  time: 0.6579  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[1/5]  [140/313]  eta: 0:01:53  Lr: 0.001875  Loss: 0.0088  Acc@1: 93.7500 (88.4309)  Acc@5: 100.0000 (98.1383)  time: 0.6574  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[1/5]  [150/313]  eta: 0:01:47  Lr: 0.001875  Loss: 0.3463  Acc@1: 93.7500 (88.6175)  Acc@5: 100.0000 (98.2202)  time: 0.6577  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[1/5]  [160/313]  eta: 0:01:40  Lr: 0.001875  Loss: -0.0338  Acc@1: 93.7500 (88.7811)  Acc@5: 100.0000 (98.2919)  time: 0.6584  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[1/5]  [170/313]  eta: 0:01:34  Lr: 0.001875  Loss: -0.0799  Acc@1: 93.7500 (88.9254)  Acc@5: 100.0000 (98.3553)  time: 0.6582  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[1/5]  [180/313]  eta: 0:01:27  Lr: 0.001875  Loss: 0.0433  Acc@1: 93.7500 (89.2956)  Acc@5: 100.0000 (98.3771)  time: 0.6573  data: 0.0015  max mem: 2373\n",
            "Train: Epoch[1/5]  [190/313]  eta: 0:01:21  Lr: 0.001875  Loss: 0.1510  Acc@1: 93.7500 (89.3652)  Acc@5: 100.0000 (98.2984)  time: 0.6571  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[1/5]  [200/313]  eta: 0:01:14  Lr: 0.001875  Loss: 0.2754  Acc@1: 93.7500 (89.4279)  Acc@5: 100.0000 (98.2587)  time: 0.6572  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[1/5]  [210/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.0051  Acc@1: 93.7500 (89.5438)  Acc@5: 100.0000 (98.3412)  time: 0.6563  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[1/5]  [220/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.1196  Acc@1: 93.7500 (89.5362)  Acc@5: 100.0000 (98.3314)  time: 0.6560  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[1/5]  [230/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.0629  Acc@1: 93.7500 (89.7998)  Acc@5: 100.0000 (98.3496)  time: 0.6557  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[1/5]  [240/313]  eta: 0:00:48  Lr: 0.001875  Loss: -0.0137  Acc@1: 93.7500 (90.0156)  Acc@5: 100.0000 (98.4180)  time: 0.6553  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[1/5]  [250/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.2205  Acc@1: 93.7500 (90.0647)  Acc@5: 100.0000 (98.4562)  time: 0.6560  data: 0.0014  max mem: 2373\n",
            "Train: Epoch[1/5]  [260/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.3925  Acc@1: 93.7500 (90.2299)  Acc@5: 100.0000 (98.5153)  time: 0.6564  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[1/5]  [270/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.3162  Acc@1: 93.7500 (90.2675)  Acc@5: 100.0000 (98.5240)  time: 0.6556  data: 0.0029  max mem: 2373\n",
            "Train: Epoch[1/5]  [280/313]  eta: 0:00:21  Lr: 0.001875  Loss: -0.0418  Acc@1: 93.7500 (90.3470)  Acc@5: 100.0000 (98.5543)  time: 0.6554  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[1/5]  [290/313]  eta: 0:00:15  Lr: 0.001875  Loss: -0.0017  Acc@1: 93.7500 (90.3351)  Acc@5: 100.0000 (98.6040)  time: 0.6554  data: 0.0011  max mem: 2373\n",
            "Train: Epoch[1/5]  [300/313]  eta: 0:00:08  Lr: 0.001875  Loss: -0.1069  Acc@1: 93.7500 (90.4485)  Acc@5: 100.0000 (98.6296)  time: 0.6546  data: 0.0012  max mem: 2373\n",
            "Train: Epoch[1/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.0006  Acc@1: 93.7500 (90.4944)  Acc@5: 100.0000 (98.6736)  time: 0.6549  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.3594  Acc@1: 93.7500 (90.4200)  Acc@5: 100.0000 (98.6800)  time: 0.6386  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[1/5] Total time: 0:03:25 (0.6566 s / it)\n",
            "Averaged stats: Lr: 0.001875  Loss: 0.3594  Acc@1: 93.7500 (90.4200)  Acc@5: 100.0000 (98.6800)\n",
            "Train: Epoch[2/5]  [  0/313]  eta: 0:03:58  Lr: 0.001875  Loss: 0.0908  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.7619  data: 0.1466  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 10/313]  eta: 0:03:21  Lr: 0.001875  Loss: -0.0202  Acc@1: 93.7500 (90.9091)  Acc@5: 100.0000 (99.4318)  time: 0.6646  data: 0.0143  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 20/313]  eta: 0:03:13  Lr: 0.001875  Loss: 0.3078  Acc@1: 87.5000 (91.0714)  Acc@5: 100.0000 (99.4048)  time: 0.6543  data: 0.0014  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 30/313]  eta: 0:03:06  Lr: 0.001875  Loss: -0.0457  Acc@1: 93.7500 (90.9274)  Acc@5: 100.0000 (98.9919)  time: 0.6539  data: 0.0015  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 40/313]  eta: 0:02:59  Lr: 0.001875  Loss: 0.0418  Acc@1: 93.7500 (91.1585)  Acc@5: 100.0000 (98.4756)  time: 0.6538  data: 0.0010  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 50/313]  eta: 0:02:52  Lr: 0.001875  Loss: -0.0665  Acc@1: 93.7500 (91.5441)  Acc@5: 100.0000 (98.7745)  time: 0.6537  data: 0.0011  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 60/313]  eta: 0:02:45  Lr: 0.001875  Loss: 0.1515  Acc@1: 93.7500 (91.5984)  Acc@5: 100.0000 (98.8730)  time: 0.6536  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 70/313]  eta: 0:02:39  Lr: 0.001875  Loss: 0.1298  Acc@1: 93.7500 (91.8134)  Acc@5: 100.0000 (99.0317)  time: 0.6542  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 80/313]  eta: 0:02:32  Lr: 0.001875  Loss: 0.1679  Acc@1: 93.7500 (92.1296)  Acc@5: 100.0000 (99.0741)  time: 0.6539  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[2/5]  [ 90/313]  eta: 0:02:26  Lr: 0.001875  Loss: 0.2726  Acc@1: 93.7500 (91.9643)  Acc@5: 100.0000 (99.1071)  time: 0.6540  data: 0.0014  max mem: 2373\n",
            "Train: Epoch[2/5]  [100/313]  eta: 0:02:19  Lr: 0.001875  Loss: -0.1324  Acc@1: 93.7500 (91.7079)  Acc@5: 100.0000 (99.0718)  time: 0.6537  data: 0.0015  max mem: 2373\n",
            "Train: Epoch[2/5]  [110/313]  eta: 0:02:12  Lr: 0.001875  Loss: -0.1566  Acc@1: 93.7500 (91.9482)  Acc@5: 100.0000 (99.0428)  time: 0.6532  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[2/5]  [120/313]  eta: 0:02:06  Lr: 0.001875  Loss: -0.1585  Acc@1: 93.7500 (92.2521)  Acc@5: 100.0000 (99.0702)  time: 0.6543  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[2/5]  [130/313]  eta: 0:01:59  Lr: 0.001875  Loss: -0.1257  Acc@1: 93.7500 (92.0802)  Acc@5: 100.0000 (98.9504)  time: 0.6542  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[2/5]  [140/313]  eta: 0:01:53  Lr: 0.001875  Loss: 0.3476  Acc@1: 87.5000 (92.0213)  Acc@5: 100.0000 (98.9362)  time: 0.6545  data: 0.0042  max mem: 2373\n",
            "Train: Epoch[2/5]  [150/313]  eta: 0:01:46  Lr: 0.001875  Loss: 0.2370  Acc@1: 93.7500 (91.9288)  Acc@5: 100.0000 (98.9238)  time: 0.6547  data: 0.0043  max mem: 2373\n",
            "Train: Epoch[2/5]  [160/313]  eta: 0:01:40  Lr: 0.001875  Loss: 0.2273  Acc@1: 93.7500 (91.9643)  Acc@5: 100.0000 (98.9130)  time: 0.6540  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[2/5]  [170/313]  eta: 0:01:33  Lr: 0.001875  Loss: 0.1355  Acc@1: 87.5000 (91.7763)  Acc@5: 100.0000 (98.9401)  time: 0.6545  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[2/5]  [180/313]  eta: 0:01:27  Lr: 0.001875  Loss: -0.1039  Acc@1: 87.5000 (91.7472)  Acc@5: 100.0000 (98.9296)  time: 0.6548  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[2/5]  [190/313]  eta: 0:01:20  Lr: 0.001875  Loss: -0.0145  Acc@1: 93.7500 (91.6885)  Acc@5: 100.0000 (98.9202)  time: 0.6549  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[2/5]  [200/313]  eta: 0:01:13  Lr: 0.001875  Loss: 0.0289  Acc@1: 93.7500 (91.7600)  Acc@5: 100.0000 (98.9117)  time: 0.6549  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[2/5]  [210/313]  eta: 0:01:07  Lr: 0.001875  Loss: 0.1277  Acc@1: 93.7500 (91.6469)  Acc@5: 100.0000 (98.8744)  time: 0.6548  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[2/5]  [220/313]  eta: 0:01:00  Lr: 0.001875  Loss: 0.1569  Acc@1: 87.5000 (91.6290)  Acc@5: 100.0000 (98.8971)  time: 0.6550  data: 0.0026  max mem: 2373\n",
            "Train: Epoch[2/5]  [230/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.0018  Acc@1: 87.5000 (91.5855)  Acc@5: 100.0000 (98.9177)  time: 0.6552  data: 0.0028  max mem: 2373\n",
            "Train: Epoch[2/5]  [240/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.0931  Acc@1: 93.7500 (91.6234)  Acc@5: 100.0000 (98.9627)  time: 0.6547  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[2/5]  [250/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.1393  Acc@1: 93.7500 (91.5339)  Acc@5: 100.0000 (99.0040)  time: 0.6553  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[2/5]  [260/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.0930  Acc@1: 93.7500 (91.6188)  Acc@5: 100.0000 (99.0182)  time: 0.6552  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[2/5]  [270/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.0954  Acc@1: 93.7500 (91.6282)  Acc@5: 100.0000 (99.0083)  time: 0.6546  data: 0.0015  max mem: 2373\n",
            "Train: Epoch[2/5]  [280/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.0249  Acc@1: 93.7500 (91.6815)  Acc@5: 100.0000 (98.9769)  time: 0.6556  data: 0.0014  max mem: 2373\n",
            "Train: Epoch[2/5]  [290/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.3907  Acc@1: 93.7500 (91.7741)  Acc@5: 100.0000 (99.0120)  time: 0.6553  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[2/5]  [300/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.0459  Acc@1: 93.7500 (91.7774)  Acc@5: 100.0000 (99.0241)  time: 0.6551  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[2/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: -0.1483  Acc@1: 93.7500 (91.8207)  Acc@5: 100.0000 (98.9952)  time: 0.6546  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1370  Acc@1: 93.7500 (91.8400)  Acc@5: 100.0000 (99.0000)  time: 0.6383  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[2/5] Total time: 0:03:24 (0.6540 s / it)\n",
            "Averaged stats: Lr: 0.001875  Loss: -0.1370  Acc@1: 93.7500 (91.8400)  Acc@5: 100.0000 (99.0000)\n",
            "Train: Epoch[3/5]  [  0/313]  eta: 0:03:55  Lr: 0.001875  Loss: -0.0462  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.7535  data: 0.1371  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 10/313]  eta: 0:03:21  Lr: 0.001875  Loss: 0.0836  Acc@1: 87.5000 (89.7727)  Acc@5: 100.0000 (98.2955)  time: 0.6644  data: 0.0141  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 20/313]  eta: 0:03:13  Lr: 0.001875  Loss: -0.0870  Acc@1: 93.7500 (91.3690)  Acc@5: 100.0000 (99.1071)  time: 0.6550  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 30/313]  eta: 0:03:06  Lr: 0.001875  Loss: -0.0686  Acc@1: 93.7500 (92.1371)  Acc@5: 100.0000 (99.1935)  time: 0.6540  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 40/313]  eta: 0:02:59  Lr: 0.001875  Loss: 0.3331  Acc@1: 93.7500 (92.3780)  Acc@5: 100.0000 (99.2378)  time: 0.6535  data: 0.0013  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 50/313]  eta: 0:02:52  Lr: 0.001875  Loss: 0.2646  Acc@1: 93.7500 (91.9118)  Acc@5: 100.0000 (99.2647)  time: 0.6540  data: 0.0012  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 60/313]  eta: 0:02:45  Lr: 0.001875  Loss: -0.0504  Acc@1: 93.7500 (91.8033)  Acc@5: 100.0000 (99.1803)  time: 0.6536  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 70/313]  eta: 0:02:39  Lr: 0.001875  Loss: -0.1910  Acc@1: 93.7500 (91.9014)  Acc@5: 100.0000 (99.1197)  time: 0.6533  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 80/313]  eta: 0:02:32  Lr: 0.001875  Loss: -0.0791  Acc@1: 93.7500 (92.0525)  Acc@5: 100.0000 (99.1512)  time: 0.6541  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[3/5]  [ 90/313]  eta: 0:02:26  Lr: 0.001875  Loss: -0.2180  Acc@1: 93.7500 (92.1703)  Acc@5: 100.0000 (99.2445)  time: 0.6544  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[3/5]  [100/313]  eta: 0:02:19  Lr: 0.001875  Loss: -0.1137  Acc@1: 93.7500 (92.3886)  Acc@5: 100.0000 (99.3193)  time: 0.6539  data: 0.0028  max mem: 2373\n",
            "Train: Epoch[3/5]  [110/313]  eta: 0:02:12  Lr: 0.001875  Loss: 0.1697  Acc@1: 93.7500 (92.4550)  Acc@5: 100.0000 (99.3243)  time: 0.6535  data: 0.0025  max mem: 2373\n",
            "Train: Epoch[3/5]  [120/313]  eta: 0:02:06  Lr: 0.001875  Loss: -0.0335  Acc@1: 93.7500 (92.6136)  Acc@5: 100.0000 (99.3802)  time: 0.6534  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[3/5]  [130/313]  eta: 0:01:59  Lr: 0.001875  Loss: 0.0054  Acc@1: 93.7500 (92.4141)  Acc@5: 100.0000 (99.3798)  time: 0.6534  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[3/5]  [140/313]  eta: 0:01:53  Lr: 0.001875  Loss: 0.1899  Acc@1: 93.7500 (92.3316)  Acc@5: 100.0000 (99.2908)  time: 0.6536  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[3/5]  [150/313]  eta: 0:01:46  Lr: 0.001875  Loss: 0.3018  Acc@1: 93.7500 (92.2185)  Acc@5: 100.0000 (99.2964)  time: 0.6538  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[3/5]  [160/313]  eta: 0:01:40  Lr: 0.001875  Loss: 0.0740  Acc@1: 93.7500 (92.2748)  Acc@5: 100.0000 (99.3401)  time: 0.6543  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[3/5]  [170/313]  eta: 0:01:33  Lr: 0.001875  Loss: 0.3147  Acc@1: 93.7500 (92.0687)  Acc@5: 100.0000 (99.2690)  time: 0.6544  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[3/5]  [180/313]  eta: 0:01:27  Lr: 0.001875  Loss: -0.0711  Acc@1: 87.5000 (91.9890)  Acc@5: 100.0000 (99.2749)  time: 0.6538  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[3/5]  [190/313]  eta: 0:01:20  Lr: 0.001875  Loss: 0.3001  Acc@1: 87.5000 (91.9175)  Acc@5: 100.0000 (99.2474)  time: 0.6545  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[3/5]  [200/313]  eta: 0:01:13  Lr: 0.001875  Loss: -0.1651  Acc@1: 93.7500 (91.9154)  Acc@5: 100.0000 (99.2226)  time: 0.6557  data: 0.0030  max mem: 2373\n",
            "Train: Epoch[3/5]  [210/313]  eta: 0:01:07  Lr: 0.001875  Loss: 0.1701  Acc@1: 93.7500 (91.9431)  Acc@5: 100.0000 (99.2299)  time: 0.6543  data: 0.0027  max mem: 2373\n",
            "Train: Epoch[3/5]  [220/313]  eta: 0:01:00  Lr: 0.001875  Loss: -0.1672  Acc@1: 93.7500 (92.0814)  Acc@5: 100.0000 (99.2647)  time: 0.6540  data: 0.0015  max mem: 2373\n",
            "Train: Epoch[3/5]  [230/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.0187  Acc@1: 93.7500 (92.0996)  Acc@5: 100.0000 (99.2154)  time: 0.6548  data: 0.0015  max mem: 2373\n",
            "Train: Epoch[3/5]  [240/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.1326  Acc@1: 93.7500 (92.1421)  Acc@5: 100.0000 (99.2479)  time: 0.6538  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[3/5]  [250/313]  eta: 0:00:41  Lr: 0.001875  Loss: -0.1908  Acc@1: 93.7500 (92.1066)  Acc@5: 100.0000 (99.2530)  time: 0.6535  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[3/5]  [260/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.0658  Acc@1: 93.7500 (92.1935)  Acc@5: 100.0000 (99.2337)  time: 0.6544  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[3/5]  [270/313]  eta: 0:00:28  Lr: 0.001875  Loss: -0.1393  Acc@1: 93.7500 (92.2279)  Acc@5: 100.0000 (99.2620)  time: 0.6543  data: 0.0037  max mem: 2373\n",
            "Train: Epoch[3/5]  [280/313]  eta: 0:00:21  Lr: 0.001875  Loss: -0.0875  Acc@1: 93.7500 (92.2375)  Acc@5: 100.0000 (99.2215)  time: 0.6545  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[3/5]  [290/313]  eta: 0:00:15  Lr: 0.001875  Loss: -0.1256  Acc@1: 93.7500 (92.2895)  Acc@5: 100.0000 (99.2483)  time: 0.6551  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[3/5]  [300/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.1749  Acc@1: 93.7500 (92.2342)  Acc@5: 100.0000 (99.2110)  time: 0.6545  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[3/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.2913  Acc@1: 87.5000 (92.2428)  Acc@5: 100.0000 (99.2363)  time: 0.6536  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.0785  Acc@1: 87.5000 (92.2400)  Acc@5: 100.0000 (99.2400)  time: 0.6371  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[3/5] Total time: 0:03:24 (0.6536 s / it)\n",
            "Averaged stats: Lr: 0.001875  Loss: 0.0785  Acc@1: 87.5000 (92.2400)  Acc@5: 100.0000 (99.2400)\n",
            "Train: Epoch[4/5]  [  0/313]  eta: 0:04:05  Lr: 0.001875  Loss: 0.0052  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.7852  data: 0.1772  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 10/313]  eta: 0:03:21  Lr: 0.001875  Loss: -0.0151  Acc@1: 93.7500 (94.3182)  Acc@5: 100.0000 (100.0000)  time: 0.6665  data: 0.0184  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 20/313]  eta: 0:03:13  Lr: 0.001875  Loss: -0.1391  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.6541  data: 0.0015  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 30/313]  eta: 0:03:06  Lr: 0.001875  Loss: 0.2098  Acc@1: 93.7500 (93.3468)  Acc@5: 100.0000 (99.7984)  time: 0.6548  data: 0.0010  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 40/313]  eta: 0:02:59  Lr: 0.001875  Loss: 0.2381  Acc@1: 93.7500 (92.8354)  Acc@5: 100.0000 (99.6951)  time: 0.6549  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 50/313]  eta: 0:02:52  Lr: 0.001875  Loss: 0.2289  Acc@1: 93.7500 (92.4020)  Acc@5: 100.0000 (99.6324)  time: 0.6550  data: 0.0012  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 60/313]  eta: 0:02:46  Lr: 0.001875  Loss: -0.0778  Acc@1: 93.7500 (92.3156)  Acc@5: 100.0000 (99.6926)  time: 0.6562  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 70/313]  eta: 0:02:39  Lr: 0.001875  Loss: 0.4447  Acc@1: 93.7500 (92.3415)  Acc@5: 100.0000 (99.5599)  time: 0.6565  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 80/313]  eta: 0:02:33  Lr: 0.001875  Loss: 0.0280  Acc@1: 93.7500 (92.4383)  Acc@5: 100.0000 (99.6142)  time: 0.6570  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[4/5]  [ 90/313]  eta: 0:02:26  Lr: 0.001875  Loss: 0.0747  Acc@1: 93.7500 (92.5824)  Acc@5: 100.0000 (99.5879)  time: 0.6574  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[4/5]  [100/313]  eta: 0:02:19  Lr: 0.001875  Loss: -0.1284  Acc@1: 93.7500 (92.8218)  Acc@5: 100.0000 (99.6287)  time: 0.6567  data: 0.0020  max mem: 2373\n",
            "Train: Epoch[4/5]  [110/313]  eta: 0:02:13  Lr: 0.001875  Loss: 0.2308  Acc@1: 93.7500 (92.7928)  Acc@5: 100.0000 (99.4932)  time: 0.6570  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[4/5]  [120/313]  eta: 0:02:06  Lr: 0.001875  Loss: 0.4202  Acc@1: 87.5000 (92.7686)  Acc@5: 100.0000 (99.3802)  time: 0.6571  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[4/5]  [130/313]  eta: 0:02:00  Lr: 0.001875  Loss: -0.0304  Acc@1: 93.7500 (92.7481)  Acc@5: 100.0000 (99.3798)  time: 0.6569  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[4/5]  [140/313]  eta: 0:01:53  Lr: 0.001875  Loss: -0.0869  Acc@1: 93.7500 (92.7305)  Acc@5: 100.0000 (99.4238)  time: 0.6576  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[4/5]  [150/313]  eta: 0:01:47  Lr: 0.001875  Loss: 0.0069  Acc@1: 93.7500 (92.7152)  Acc@5: 100.0000 (99.4205)  time: 0.6575  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[4/5]  [160/313]  eta: 0:01:40  Lr: 0.001875  Loss: 0.3650  Acc@1: 93.7500 (92.6242)  Acc@5: 100.0000 (99.4565)  time: 0.6577  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[4/5]  [170/313]  eta: 0:01:33  Lr: 0.001875  Loss: -0.1084  Acc@1: 87.5000 (92.3977)  Acc@5: 100.0000 (99.4518)  time: 0.6579  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[4/5]  [180/313]  eta: 0:01:27  Lr: 0.001875  Loss: -0.0279  Acc@1: 87.5000 (92.3688)  Acc@5: 100.0000 (99.4475)  time: 0.6577  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[4/5]  [190/313]  eta: 0:01:20  Lr: 0.001875  Loss: -0.0916  Acc@1: 93.7500 (92.5720)  Acc@5: 100.0000 (99.4437)  time: 0.6577  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[4/5]  [200/313]  eta: 0:01:14  Lr: 0.001875  Loss: 0.1461  Acc@1: 93.7500 (92.5373)  Acc@5: 100.0000 (99.4403)  time: 0.6577  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[4/5]  [210/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.0757  Acc@1: 87.5000 (92.3874)  Acc@5: 100.0000 (99.4372)  time: 0.6576  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[4/5]  [220/313]  eta: 0:01:01  Lr: 0.001875  Loss: -0.1635  Acc@1: 93.7500 (92.5339)  Acc@5: 100.0000 (99.4627)  time: 0.6588  data: 0.0011  max mem: 2373\n",
            "Train: Epoch[4/5]  [230/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.0202  Acc@1: 93.7500 (92.5054)  Acc@5: 100.0000 (99.4048)  time: 0.6591  data: 0.0012  max mem: 2373\n",
            "Train: Epoch[4/5]  [240/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.3269  Acc@1: 93.7500 (92.6349)  Acc@5: 100.0000 (99.3776)  time: 0.6585  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[4/5]  [250/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.1692  Acc@1: 93.7500 (92.7042)  Acc@5: 100.0000 (99.4024)  time: 0.6582  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[4/5]  [260/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.1704  Acc@1: 93.7500 (92.6724)  Acc@5: 100.0000 (99.3534)  time: 0.6578  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[4/5]  [270/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.0192  Acc@1: 93.7500 (92.6199)  Acc@5: 100.0000 (99.3312)  time: 0.6585  data: 0.0025  max mem: 2373\n",
            "Train: Epoch[4/5]  [280/313]  eta: 0:00:21  Lr: 0.001875  Loss: -0.1725  Acc@1: 93.7500 (92.7936)  Acc@5: 100.0000 (99.3550)  time: 0.6591  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[4/5]  [290/313]  eta: 0:00:15  Lr: 0.001875  Loss: -0.1735  Acc@1: 100.0000 (92.8479)  Acc@5: 100.0000 (99.3557)  time: 0.6593  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[4/5]  [300/313]  eta: 0:00:08  Lr: 0.001875  Loss: -0.0423  Acc@1: 93.7500 (92.7949)  Acc@5: 100.0000 (99.3563)  time: 0.6587  data: 0.0016  max mem: 2373\n",
            "Train: Epoch[4/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: 0.2453  Acc@1: 93.7500 (92.9059)  Acc@5: 100.0000 (99.3770)  time: 0.6583  data: 0.0013  max mem: 2373\n",
            "Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.2280  Acc@1: 93.7500 (92.9400)  Acc@5: 100.0000 (99.3800)  time: 0.6421  data: 0.0012  max mem: 2373\n",
            "Train: Epoch[4/5] Total time: 0:03:25 (0.6570 s / it)\n",
            "Averaged stats: Lr: 0.001875  Loss: -0.2280  Acc@1: 93.7500 (92.9400)  Acc@5: 100.0000 (99.3800)\n",
            "Train: Epoch[5/5]  [  0/313]  eta: 0:04:15  Lr: 0.001875  Loss: 0.0251  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.8154  data: 0.1971  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 10/313]  eta: 0:03:24  Lr: 0.001875  Loss: 0.3713  Acc@1: 93.7500 (93.1818)  Acc@5: 100.0000 (100.0000)  time: 0.6733  data: 0.0218  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 20/313]  eta: 0:03:15  Lr: 0.001875  Loss: 0.0921  Acc@1: 93.7500 (92.8571)  Acc@5: 100.0000 (99.7024)  time: 0.6584  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 30/313]  eta: 0:03:07  Lr: 0.001875  Loss: 0.0379  Acc@1: 93.7500 (92.1371)  Acc@5: 100.0000 (99.7984)  time: 0.6575  data: 0.0013  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 40/313]  eta: 0:03:00  Lr: 0.001875  Loss: 0.4830  Acc@1: 93.7500 (92.2256)  Acc@5: 100.0000 (99.3902)  time: 0.6582  data: 0.0013  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 50/313]  eta: 0:02:53  Lr: 0.001875  Loss: -0.1260  Acc@1: 100.0000 (93.1373)  Acc@5: 100.0000 (99.3873)  time: 0.6590  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 60/313]  eta: 0:02:47  Lr: 0.001875  Loss: -0.1308  Acc@1: 93.7500 (93.0328)  Acc@5: 100.0000 (99.4877)  time: 0.6588  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 70/313]  eta: 0:02:40  Lr: 0.001875  Loss: -0.1733  Acc@1: 93.7500 (93.3099)  Acc@5: 100.0000 (99.4718)  time: 0.6584  data: 0.0032  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 80/313]  eta: 0:02:33  Lr: 0.001875  Loss: 0.1050  Acc@1: 93.7500 (93.3642)  Acc@5: 100.0000 (99.5370)  time: 0.6583  data: 0.0033  max mem: 2373\n",
            "Train: Epoch[5/5]  [ 90/313]  eta: 0:02:27  Lr: 0.001875  Loss: -0.1405  Acc@1: 93.7500 (93.5440)  Acc@5: 100.0000 (99.5879)  time: 0.6581  data: 0.0014  max mem: 2373\n",
            "Train: Epoch[5/5]  [100/313]  eta: 0:02:20  Lr: 0.001875  Loss: 0.1470  Acc@1: 93.7500 (93.5644)  Acc@5: 100.0000 (99.5668)  time: 0.6580  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[5/5]  [110/313]  eta: 0:02:13  Lr: 0.001875  Loss: -0.0397  Acc@1: 93.7500 (93.4685)  Acc@5: 100.0000 (99.6059)  time: 0.6582  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[5/5]  [120/313]  eta: 0:02:07  Lr: 0.001875  Loss: -0.1289  Acc@1: 93.7500 (93.5434)  Acc@5: 100.0000 (99.5868)  time: 0.6575  data: 0.0027  max mem: 2373\n",
            "Train: Epoch[5/5]  [130/313]  eta: 0:02:00  Lr: 0.001875  Loss: 0.2053  Acc@1: 93.7500 (93.6069)  Acc@5: 100.0000 (99.6183)  time: 0.6576  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[5/5]  [140/313]  eta: 0:01:54  Lr: 0.001875  Loss: 0.1035  Acc@1: 93.7500 (93.3954)  Acc@5: 100.0000 (99.6454)  time: 0.6581  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[5/5]  [150/313]  eta: 0:01:47  Lr: 0.001875  Loss: 0.0465  Acc@1: 93.7500 (93.2533)  Acc@5: 100.0000 (99.5033)  time: 0.6578  data: 0.0021  max mem: 2373\n",
            "Train: Epoch[5/5]  [160/313]  eta: 0:01:40  Lr: 0.001875  Loss: -0.0981  Acc@1: 93.7500 (93.3230)  Acc@5: 100.0000 (99.4953)  time: 0.6580  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[5/5]  [170/313]  eta: 0:01:34  Lr: 0.001875  Loss: 0.1249  Acc@1: 93.7500 (93.4211)  Acc@5: 100.0000 (99.4152)  time: 0.6585  data: 0.0015  max mem: 2373\n",
            "Train: Epoch[5/5]  [180/313]  eta: 0:01:27  Lr: 0.001875  Loss: -0.0642  Acc@1: 93.7500 (93.2320)  Acc@5: 100.0000 (99.3785)  time: 0.6594  data: 0.0024  max mem: 2373\n",
            "Train: Epoch[5/5]  [190/313]  eta: 0:01:21  Lr: 0.001875  Loss: -0.0799  Acc@1: 93.7500 (93.2592)  Acc@5: 100.0000 (99.3455)  time: 0.6597  data: 0.0026  max mem: 2373\n",
            "Train: Epoch[5/5]  [200/313]  eta: 0:01:14  Lr: 0.001875  Loss: -0.0179  Acc@1: 93.7500 (93.2214)  Acc@5: 100.0000 (99.3781)  time: 0.6591  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[5/5]  [210/313]  eta: 0:01:07  Lr: 0.001875  Loss: -0.0104  Acc@1: 93.7500 (93.1280)  Acc@5: 100.0000 (99.3483)  time: 0.6584  data: 0.0015  max mem: 2373\n",
            "Train: Epoch[5/5]  [220/313]  eta: 0:01:01  Lr: 0.001875  Loss: -0.1625  Acc@1: 93.7500 (93.2410)  Acc@5: 100.0000 (99.3495)  time: 0.6581  data: 0.0019  max mem: 2373\n",
            "Train: Epoch[5/5]  [230/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.3550  Acc@1: 93.7500 (93.1277)  Acc@5: 100.0000 (99.3506)  time: 0.6574  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[5/5]  [240/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.3070  Acc@1: 93.7500 (93.1795)  Acc@5: 100.0000 (99.3257)  time: 0.6566  data: 0.0022  max mem: 2373\n",
            "Train: Epoch[5/5]  [250/313]  eta: 0:00:41  Lr: 0.001875  Loss: -0.1482  Acc@1: 93.7500 (93.2022)  Acc@5: 100.0000 (99.3028)  time: 0.6559  data: 0.0023  max mem: 2373\n",
            "Train: Epoch[5/5]  [260/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.4703  Acc@1: 93.7500 (93.1513)  Acc@5: 100.0000 (99.3295)  time: 0.6540  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[5/5]  [270/313]  eta: 0:00:28  Lr: 0.001875  Loss: -0.0830  Acc@1: 93.7500 (93.1042)  Acc@5: 100.0000 (99.3542)  time: 0.6534  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[5/5]  [280/313]  eta: 0:00:21  Lr: 0.001875  Loss: -0.1611  Acc@1: 93.7500 (93.1272)  Acc@5: 100.0000 (99.3550)  time: 0.6538  data: 0.0017  max mem: 2373\n",
            "Train: Epoch[5/5]  [290/313]  eta: 0:00:15  Lr: 0.001875  Loss: -0.1875  Acc@1: 93.7500 (93.1271)  Acc@5: 100.0000 (99.3771)  time: 0.6534  data: 0.0018  max mem: 2373\n",
            "Train: Epoch[5/5]  [300/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.0874  Acc@1: 93.7500 (93.1894)  Acc@5: 100.0000 (99.3978)  time: 0.6531  data: 0.0027  max mem: 2373\n",
            "Train: Epoch[5/5]  [310/313]  eta: 0:00:01  Lr: 0.001875  Loss: -0.0598  Acc@1: 93.7500 (93.2878)  Acc@5: 100.0000 (99.3971)  time: 0.6525  data: 0.0025  max mem: 2373\n",
            "Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.0589  Acc@1: 93.7500 (93.2800)  Acc@5: 100.0000 (99.4000)  time: 0.6366  data: 0.0025  max mem: 2373\n",
            "Train: Epoch[5/5] Total time: 0:03:25 (0.6568 s / it)\n",
            "Averaged stats: Lr: 0.001875  Loss: 0.0589  Acc@1: 93.7500 (93.2800)  Acc@5: 100.0000 (99.4000)\n",
            "Test: [Task 1]  [ 0/63]  eta: 0:00:33  Loss: 1.0607 (1.0607)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)  time: 0.5353  data: 0.1441  max mem: 2373\n",
            "Test: [Task 1]  [10/63]  eta: 0:00:23  Loss: 0.7092 (0.6859)  Acc@1: 81.2500 (82.3864)  Acc@5: 100.0000 (97.7273)  time: 0.4353  data: 0.0194  max mem: 2373\n",
            "Test: [Task 1]  [20/63]  eta: 0:00:18  Loss: 0.7092 (0.7242)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (97.6190)  time: 0.4254  data: 0.0037  max mem: 2373\n",
            "Test: [Task 1]  [30/63]  eta: 0:00:14  Loss: 0.6609 (0.7099)  Acc@1: 81.2500 (82.4597)  Acc@5: 100.0000 (97.9839)  time: 0.4247  data: 0.0005  max mem: 2373\n",
            "Test: [Task 1]  [40/63]  eta: 0:00:09  Loss: 0.5859 (0.6928)  Acc@1: 87.5000 (83.3841)  Acc@5: 100.0000 (98.1707)  time: 0.4237  data: 0.0016  max mem: 2373\n",
            "Test: [Task 1]  [50/63]  eta: 0:00:05  Loss: 0.5919 (0.6760)  Acc@1: 87.5000 (83.5784)  Acc@5: 100.0000 (98.0392)  time: 0.4238  data: 0.0019  max mem: 2373\n",
            "Test: [Task 1]  [60/63]  eta: 0:00:01  Loss: 0.6014 (0.6583)  Acc@1: 87.5000 (84.3238)  Acc@5: 100.0000 (97.9508)  time: 0.4244  data: 0.0008  max mem: 2373\n",
            "Test: [Task 1]  [62/63]  eta: 0:00:00  Loss: 0.5542 (0.6533)  Acc@1: 87.5000 (84.6000)  Acc@5: 100.0000 (98.0000)  time: 0.4140  data: 0.0004  max mem: 2373\n",
            "Test: [Task 1] Total time: 0:00:26 (0.4238 s / it)\n",
            "* Acc@1 84.600 Acc@5 98.000 loss 0.653\n",
            "Test: [Task 2]  [ 0/63]  eta: 0:00:38  Loss: 1.0313 (1.0313)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)  time: 0.6113  data: 0.2185  max mem: 2373\n",
            "Test: [Task 2]  [10/63]  eta: 0:00:23  Loss: 0.7276 (0.7476)  Acc@1: 87.5000 (83.5227)  Acc@5: 100.0000 (97.1591)  time: 0.4416  data: 0.0256  max mem: 2373\n",
            "Test: [Task 2]  [20/63]  eta: 0:00:18  Loss: 0.7729 (0.8138)  Acc@1: 81.2500 (81.5476)  Acc@5: 93.7500 (96.1310)  time: 0.4254  data: 0.0036  max mem: 2373\n",
            "Test: [Task 2]  [30/63]  eta: 0:00:14  Loss: 0.8262 (0.8024)  Acc@1: 81.2500 (82.2581)  Acc@5: 93.7500 (96.1694)  time: 0.4252  data: 0.0008  max mem: 2373\n",
            "Test: [Task 2]  [40/63]  eta: 0:00:09  Loss: 0.7148 (0.7877)  Acc@1: 81.2500 (81.8598)  Acc@5: 93.7500 (96.1890)  time: 0.4241  data: 0.0027  max mem: 2373\n",
            "Test: [Task 2]  [50/63]  eta: 0:00:05  Loss: 0.7141 (0.7764)  Acc@1: 81.2500 (81.1275)  Acc@5: 100.0000 (96.3235)  time: 0.4247  data: 0.0029  max mem: 2373\n",
            "Test: [Task 2]  [60/63]  eta: 0:00:01  Loss: 0.6220 (0.7596)  Acc@1: 81.2500 (81.4549)  Acc@5: 100.0000 (96.6189)  time: 0.4251  data: 0.0007  max mem: 2373\n",
            "Test: [Task 2]  [62/63]  eta: 0:00:00  Loss: 0.6199 (0.7525)  Acc@1: 81.2500 (81.5000)  Acc@5: 100.0000 (96.7000)  time: 0.4150  data: 0.0003  max mem: 2373\n",
            "Test: [Task 2] Total time: 0:00:26 (0.4254 s / it)\n",
            "* Acc@1 81.500 Acc@5 96.700 loss 0.753\n",
            "Test: [Task 3]  [ 0/63]  eta: 0:00:38  Loss: 0.4178 (0.4178)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.6081  data: 0.2150  max mem: 2373\n",
            "Test: [Task 3]  [10/63]  eta: 0:00:23  Loss: 0.5965 (0.6419)  Acc@1: 81.2500 (82.9545)  Acc@5: 100.0000 (97.7273)  time: 0.4431  data: 0.0224  max mem: 2373\n",
            "Test: [Task 3]  [20/63]  eta: 0:00:18  Loss: 0.6603 (0.6451)  Acc@1: 81.2500 (82.7381)  Acc@5: 100.0000 (97.6190)  time: 0.4266  data: 0.0021  max mem: 2373\n",
            "Test: [Task 3]  [30/63]  eta: 0:00:14  Loss: 0.6461 (0.6431)  Acc@1: 81.2500 (82.2581)  Acc@5: 100.0000 (97.7823)  time: 0.4259  data: 0.0010  max mem: 2373\n",
            "Test: [Task 3]  [40/63]  eta: 0:00:09  Loss: 0.6349 (0.6432)  Acc@1: 81.2500 (82.9268)  Acc@5: 100.0000 (97.7134)  time: 0.4242  data: 0.0019  max mem: 2373\n",
            "Test: [Task 3]  [50/63]  eta: 0:00:05  Loss: 0.6752 (0.6573)  Acc@1: 87.5000 (83.4559)  Acc@5: 93.7500 (97.3039)  time: 0.4235  data: 0.0025  max mem: 2373\n",
            "Test: [Task 3]  [60/63]  eta: 0:00:01  Loss: 0.7124 (0.6601)  Acc@1: 81.2500 (83.0943)  Acc@5: 93.7500 (97.2336)  time: 0.4249  data: 0.0012  max mem: 2373\n",
            "Test: [Task 3]  [62/63]  eta: 0:00:00  Loss: 0.7007 (0.6569)  Acc@1: 81.2500 (83.0000)  Acc@5: 93.7500 (97.2000)  time: 0.4142  data: 0.0008  max mem: 2373\n",
            "Test: [Task 3] Total time: 0:00:26 (0.4256 s / it)\n",
            "* Acc@1 83.000 Acc@5 97.200 loss 0.657\n",
            "Test: [Task 4]  [ 0/63]  eta: 0:00:34  Loss: 0.8710 (0.8710)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.5448  data: 0.1452  max mem: 2373\n",
            "Test: [Task 4]  [10/63]  eta: 0:00:23  Loss: 0.7473 (0.7313)  Acc@1: 87.5000 (82.9545)  Acc@5: 93.7500 (94.8864)  time: 0.4367  data: 0.0172  max mem: 2373\n",
            "Test: [Task 4]  [20/63]  eta: 0:00:18  Loss: 0.5833 (0.7215)  Acc@1: 87.5000 (82.4405)  Acc@5: 93.7500 (94.9405)  time: 0.4270  data: 0.0031  max mem: 2373\n",
            "Test: [Task 4]  [30/63]  eta: 0:00:14  Loss: 0.5718 (0.7039)  Acc@1: 81.2500 (83.0645)  Acc@5: 93.7500 (95.5645)  time: 0.4272  data: 0.0014  max mem: 2373\n",
            "Test: [Task 4]  [40/63]  eta: 0:00:09  Loss: 0.3674 (0.6406)  Acc@1: 87.5000 (84.4512)  Acc@5: 100.0000 (96.3415)  time: 0.4265  data: 0.0016  max mem: 2373\n",
            "Test: [Task 4]  [50/63]  eta: 0:00:05  Loss: 0.4345 (0.6523)  Acc@1: 87.5000 (83.9461)  Acc@5: 100.0000 (96.3235)  time: 0.4261  data: 0.0026  max mem: 2373\n",
            "Test: [Task 4]  [60/63]  eta: 0:00:01  Loss: 0.5615 (0.6567)  Acc@1: 81.2500 (83.8115)  Acc@5: 100.0000 (96.3115)  time: 0.4256  data: 0.0016  max mem: 2373\n",
            "Test: [Task 4]  [62/63]  eta: 0:00:00  Loss: 0.5981 (0.6589)  Acc@1: 87.5000 (83.9000)  Acc@5: 100.0000 (96.4000)  time: 0.4150  data: 0.0007  max mem: 2373\n",
            "Test: [Task 4] Total time: 0:00:26 (0.4257 s / it)\n",
            "* Acc@1 83.900 Acc@5 96.400 loss 0.659\n",
            "Test: [Task 5]  [ 0/63]  eta: 0:00:38  Loss: 0.2726 (0.2726)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.6156  data: 0.2259  max mem: 2373\n",
            "Test: [Task 5]  [10/63]  eta: 0:00:23  Loss: 0.5407 (0.5960)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.2955)  time: 0.4440  data: 0.0226  max mem: 2373\n",
            "Test: [Task 5]  [20/63]  eta: 0:00:18  Loss: 0.4977 (0.5463)  Acc@1: 87.5000 (90.1786)  Acc@5: 100.0000 (98.2143)  time: 0.4270  data: 0.0023  max mem: 2373\n",
            "Test: [Task 5]  [30/63]  eta: 0:00:14  Loss: 0.5293 (0.5618)  Acc@1: 87.5000 (88.5081)  Acc@5: 100.0000 (98.1855)  time: 0.4266  data: 0.0038  max mem: 2373\n",
            "Test: [Task 5]  [40/63]  eta: 0:00:09  Loss: 0.5293 (0.5424)  Acc@1: 87.5000 (89.0244)  Acc@5: 100.0000 (98.0183)  time: 0.4266  data: 0.0037  max mem: 2373\n",
            "Test: [Task 5]  [50/63]  eta: 0:00:05  Loss: 0.4330 (0.5454)  Acc@1: 87.5000 (88.4804)  Acc@5: 100.0000 (97.9167)  time: 0.4266  data: 0.0026  max mem: 2373\n",
            "Test: [Task 5]  [60/63]  eta: 0:00:01  Loss: 0.5221 (0.5458)  Acc@1: 87.5000 (88.2172)  Acc@5: 100.0000 (97.7459)  time: 0.4259  data: 0.0017  max mem: 2373\n",
            "Test: [Task 5]  [62/63]  eta: 0:00:00  Loss: 0.5750 (0.5634)  Acc@1: 87.5000 (88.0000)  Acc@5: 100.0000 (97.5000)  time: 0.4158  data: 0.0011  max mem: 2373\n",
            "Test: [Task 5] Total time: 0:00:26 (0.4270 s / it)\n",
            "* Acc@1 88.000 Acc@5 97.500 loss 0.563\n",
            "Test: [Task 6]  [ 0/63]  eta: 0:00:35  Loss: 0.5711 (0.5711)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.5625  data: 0.1704  max mem: 2373\n",
            "Test: [Task 6]  [10/63]  eta: 0:00:23  Loss: 0.7463 (0.7321)  Acc@1: 81.2500 (79.5455)  Acc@5: 100.0000 (97.1591)  time: 0.4383  data: 0.0162  max mem: 2373\n",
            "Test: [Task 6]  [20/63]  eta: 0:00:18  Loss: 0.7673 (0.7817)  Acc@1: 81.2500 (77.3810)  Acc@5: 100.0000 (97.3214)  time: 0.4262  data: 0.0017  max mem: 2373\n",
            "Test: [Task 6]  [30/63]  eta: 0:00:14  Loss: 0.7497 (0.7797)  Acc@1: 75.0000 (77.6210)  Acc@5: 100.0000 (97.9839)  time: 0.4262  data: 0.0017  max mem: 2373\n",
            "Test: [Task 6]  [40/63]  eta: 0:00:09  Loss: 0.7741 (0.8152)  Acc@1: 75.0000 (75.9146)  Acc@5: 100.0000 (97.8659)  time: 0.4255  data: 0.0017  max mem: 2373\n",
            "Test: [Task 6]  [50/63]  eta: 0:00:05  Loss: 0.8114 (0.7984)  Acc@1: 81.2500 (76.9608)  Acc@5: 100.0000 (97.9167)  time: 0.4254  data: 0.0036  max mem: 2373\n",
            "Test: [Task 6]  [60/63]  eta: 0:00:01  Loss: 0.8114 (0.8152)  Acc@1: 81.2500 (76.9467)  Acc@5: 100.0000 (97.5410)  time: 0.4262  data: 0.0024  max mem: 2373\n",
            "Test: [Task 6]  [62/63]  eta: 0:00:00  Loss: 0.7793 (0.8097)  Acc@1: 81.2500 (77.2000)  Acc@5: 100.0000 (97.6000)  time: 0.4159  data: 0.0018  max mem: 2373\n",
            "Test: [Task 6] Total time: 0:00:26 (0.4257 s / it)\n",
            "* Acc@1 77.200 Acc@5 97.600 loss 0.810\n",
            "Test: [Task 7]  [ 0/63]  eta: 0:00:33  Loss: 0.8152 (0.8152)  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (100.0000)  time: 0.5312  data: 0.1355  max mem: 2373\n",
            "Test: [Task 7]  [10/63]  eta: 0:00:23  Loss: 0.5650 (0.6577)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (98.2955)  time: 0.4375  data: 0.0133  max mem: 2373\n",
            "Test: [Task 7]  [20/63]  eta: 0:00:18  Loss: 0.6167 (0.7259)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (96.4286)  time: 0.4280  data: 0.0019  max mem: 2373\n",
            "Test: [Task 7]  [30/63]  eta: 0:00:14  Loss: 0.6977 (0.7159)  Acc@1: 81.2500 (80.8468)  Acc@5: 100.0000 (96.7742)  time: 0.4278  data: 0.0019  max mem: 2373\n",
            "Test: [Task 7]  [40/63]  eta: 0:00:09  Loss: 0.6199 (0.7113)  Acc@1: 81.2500 (81.4024)  Acc@5: 100.0000 (96.3415)  time: 0.4275  data: 0.0011  max mem: 2373\n",
            "Test: [Task 7]  [50/63]  eta: 0:00:05  Loss: 0.7646 (0.7376)  Acc@1: 81.2500 (80.7598)  Acc@5: 93.7500 (96.0784)  time: 0.4276  data: 0.0039  max mem: 2373\n",
            "Test: [Task 7]  [60/63]  eta: 0:00:01  Loss: 0.7646 (0.7218)  Acc@1: 81.2500 (81.4549)  Acc@5: 93.7500 (96.1066)  time: 0.4278  data: 0.0035  max mem: 2373\n",
            "Test: [Task 7]  [62/63]  eta: 0:00:00  Loss: 0.7948 (0.7260)  Acc@1: 81.2500 (81.4000)  Acc@5: 93.7500 (96.1000)  time: 0.4168  data: 0.0025  max mem: 2373\n",
            "Test: [Task 7] Total time: 0:00:26 (0.4268 s / it)\n",
            "* Acc@1 81.400 Acc@5 96.100 loss 0.726\n",
            "Test: [Task 8]  [ 0/63]  eta: 0:00:37  Loss: 0.4498 (0.4498)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.6011  data: 0.2075  max mem: 2373\n",
            "Test: [Task 8]  [10/63]  eta: 0:00:23  Loss: 0.5870 (0.6843)  Acc@1: 87.5000 (81.2500)  Acc@5: 100.0000 (97.1591)  time: 0.4442  data: 0.0199  max mem: 2373\n",
            "Test: [Task 8]  [20/63]  eta: 0:00:18  Loss: 0.5870 (0.7271)  Acc@1: 75.0000 (80.3571)  Acc@5: 100.0000 (96.4286)  time: 0.4289  data: 0.0010  max mem: 2373\n",
            "Test: [Task 8]  [30/63]  eta: 0:00:14  Loss: 0.5833 (0.6943)  Acc@1: 87.5000 (81.2500)  Acc@5: 100.0000 (96.9758)  time: 0.4285  data: 0.0006  max mem: 2373\n",
            "Test: [Task 8]  [40/63]  eta: 0:00:09  Loss: 0.6001 (0.6863)  Acc@1: 87.5000 (81.5549)  Acc@5: 100.0000 (96.7988)  time: 0.4275  data: 0.0007  max mem: 2373\n",
            "Test: [Task 8]  [50/63]  eta: 0:00:05  Loss: 0.6281 (0.6771)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (97.0588)  time: 0.4267  data: 0.0036  max mem: 2373\n",
            "Test: [Task 8]  [60/63]  eta: 0:00:01  Loss: 0.7728 (0.7050)  Acc@1: 81.2500 (80.9426)  Acc@5: 93.7500 (96.6189)  time: 0.4270  data: 0.0034  max mem: 2373\n",
            "Test: [Task 8]  [62/63]  eta: 0:00:00  Loss: 0.7146 (0.6971)  Acc@1: 81.2500 (81.2000)  Acc@5: 100.0000 (96.7000)  time: 0.4164  data: 0.0031  max mem: 2373\n",
            "Test: [Task 8] Total time: 0:00:26 (0.4281 s / it)\n",
            "* Acc@1 81.200 Acc@5 96.700 loss 0.697\n",
            "Test: [Task 9]  [ 0/63]  eta: 0:00:37  Loss: 0.1779 (0.1779)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.5901  data: 0.1967  max mem: 2373\n",
            "Test: [Task 9]  [10/63]  eta: 0:00:23  Loss: 0.4537 (0.5005)  Acc@1: 87.5000 (86.9318)  Acc@5: 100.0000 (98.2955)  time: 0.4413  data: 0.0185  max mem: 2373\n",
            "Test: [Task 9]  [20/63]  eta: 0:00:18  Loss: 0.4537 (0.5295)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.2143)  time: 0.4279  data: 0.0019  max mem: 2373\n",
            "Test: [Task 9]  [30/63]  eta: 0:00:14  Loss: 0.4095 (0.4931)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.7903)  time: 0.4277  data: 0.0020  max mem: 2373\n",
            "Test: [Task 9]  [40/63]  eta: 0:00:09  Loss: 0.3601 (0.4974)  Acc@1: 87.5000 (86.7378)  Acc@5: 100.0000 (98.6280)  time: 0.4263  data: 0.0007  max mem: 2373\n",
            "Test: [Task 9]  [50/63]  eta: 0:00:05  Loss: 0.4035 (0.4993)  Acc@1: 87.5000 (86.6422)  Acc@5: 100.0000 (98.5294)  time: 0.4255  data: 0.0026  max mem: 2373\n",
            "Test: [Task 9]  [60/63]  eta: 0:00:01  Loss: 0.3788 (0.4769)  Acc@1: 87.5000 (87.6025)  Acc@5: 100.0000 (98.4631)  time: 0.4256  data: 0.0025  max mem: 2373\n",
            "Test: [Task 9]  [62/63]  eta: 0:00:00  Loss: 0.3695 (0.4691)  Acc@1: 93.7500 (87.8000)  Acc@5: 100.0000 (98.5000)  time: 0.4151  data: 0.0021  max mem: 2373\n",
            "Test: [Task 9] Total time: 0:00:26 (0.4267 s / it)\n",
            "* Acc@1 87.800 Acc@5 98.500 loss 0.469\n",
            "Test: [Task 10]  [ 0/63]  eta: 0:00:34  Loss: 0.5736 (0.5736)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.5453  data: 0.1505  max mem: 2373\n",
            "Test: [Task 10]  [10/63]  eta: 0:00:23  Loss: 0.5316 (0.5173)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (97.7273)  time: 0.4381  data: 0.0147  max mem: 2373\n",
            "Test: [Task 10]  [20/63]  eta: 0:00:18  Loss: 0.5316 (0.5424)  Acc@1: 87.5000 (86.0119)  Acc@5: 100.0000 (98.2143)  time: 0.4277  data: 0.0023  max mem: 2373\n",
            "Test: [Task 10]  [30/63]  eta: 0:00:14  Loss: 0.5593 (0.5355)  Acc@1: 87.5000 (85.2823)  Acc@5: 100.0000 (98.5887)  time: 0.4275  data: 0.0025  max mem: 2373\n",
            "Test: [Task 10]  [40/63]  eta: 0:00:09  Loss: 0.5069 (0.5236)  Acc@1: 87.5000 (86.1280)  Acc@5: 100.0000 (98.7805)  time: 0.4265  data: 0.0010  max mem: 2373\n",
            "Test: [Task 10]  [50/63]  eta: 0:00:05  Loss: 0.4918 (0.5159)  Acc@1: 87.5000 (86.5196)  Acc@5: 100.0000 (99.0196)  time: 0.4257  data: 0.0034  max mem: 2373\n",
            "Test: [Task 10]  [60/63]  eta: 0:00:01  Loss: 0.4941 (0.5201)  Acc@1: 87.5000 (86.4754)  Acc@5: 100.0000 (98.7705)  time: 0.4259  data: 0.0033  max mem: 2373\n",
            "Test: [Task 10]  [62/63]  eta: 0:00:00  Loss: 0.4941 (0.5170)  Acc@1: 87.5000 (86.6000)  Acc@5: 100.0000 (98.8000)  time: 0.4157  data: 0.0031  max mem: 2373\n",
            "Test: [Task 10] Total time: 0:00:26 (0.4261 s / it)\n",
            "* Acc@1 86.600 Acc@5 98.800 loss 0.517\n",
            "[Average accuracy till task10]\tAcc@1: 83.5200\tAcc@5: 97.3500\tLoss: 0.6504\tForgetting: 6.7333\tBackward: -6.6000\n",
            "Total training time: 3:15:51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m torch.distributed.launch \\\n",
        "        --nproc_per_node=1 \\\n",
        "        --use_env /content/l2p-pytorch/main.py \\\n",
        "        TinyImagenet \\\n",
        "        --model vit_base_patch16_224 \\\n",
        "        --batch-size 16 \\\n",
        "        --data-path /local_datasets/ \\\n",
        "        --output_dir ./output "
      ],
      "metadata": {
        "id": "45kqXo8eqRXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m torch.distributed.launch \\\n",
        "        --nproc_per_node=1 \\\n",
        "        --use_env /content/l2p-pytorch/main.py \\\n",
        "        Imagenet-R \\\n",
        "        --model vit_base_patch16_224 \\\n",
        "        --batch-size 16 \\\n",
        "        --data-path /local_datasets/ \\\n",
        "        --output_dir ./output "
      ],
      "metadata": {
        "id": "w5aBGWfUqUZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m torch.distributed.launch --nproc_per_node=1 --use_env /content/l2p-pytorch/main.py cifar100_l2p --eval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbiUfIHyQ02t",
        "outputId": "a9bdf4e5-7482-438a-eac0-3ab44bd6d1d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated\n",
            "and will be removed in future. Use torchrun.\n",
            "Note that --use-env is set by default in torchrun.\n",
            "If your script expects `--local-rank` argument to be set, please\n",
            "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
            "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
            "further instructions\n",
            "\n",
            "  warnings.warn(\n",
            "MAIN OK\n",
            "| distributed init (rank 0): env://\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Creating original model: vit_base_patch16_224\n",
            "Creating model: vit_base_patch16_224\n",
            "Namespace(subparser_name='cifar100_l2p', batch_size=16, epochs=5, model='vit_base_patch16_224', input_size=224, pretrained=True, drop=0.0, drop_path=0.0, opt='adam', opt_eps=1e-08, opt_betas=(0.9, 0.999), clip_grad=1.0, momentum=0.9, weight_decay=0.0, reinit_optimizer=True, sched='constant', lr=0.03, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-05, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, unscale_lr=True, color_jitter=None, aa=None, smoothing=0.1, train_interpolation='bicubic', reprob=0.0, remode='pixel', recount=1, data_path='/local_datasets/', dataset='Split-CIFAR100', name='Split-CIFAR100', shuffle=False, output_dir='./output', device='cuda', seed=42, eval=True, num_workers=4, pin_mem=True, world_size=1, dist_url='env://', num_tasks=10, train_mask=True, task_inc=False, prompt_pool=True, size=10, length=5, top_k=5, initializer='uniform', prompt_key=True, prompt_key_init='uniform', use_prompt_mask=False, shared_prompt_pool=False, shared_prompt_key=False, batchwise_prompt=True, embedding_key='cls', predefined_key='', pull_constraint=True, pull_constraint_coeff=0.1, global_pool='token', head_type='prompt', freeze=['blocks', 'patch_embed', 'cls_token', 'norm', 'pos_embed'], print_freq=10, rank=0, gpu=0, distributed=True, dist_backend='nccl', nb_classes=100)\n",
            "Loading checkpoint from: ./output/checkpoint/task1_checkpoint.pth\n",
            "Test: [Task 1]  [ 0/63]  eta: 0:01:41  Loss: 0.4745 (0.4745)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 1.6102  data: 0.5781  max mem: 1156\n",
            "Test: [Task 1]  [10/63]  eta: 0:00:27  Loss: 0.4401 (0.4363)  Acc@1: 100.0000 (97.1591)  Acc@5: 100.0000 (100.0000)  time: 0.5181  data: 0.0548  max mem: 1157\n",
            "Test: [Task 1]  [20/63]  eta: 0:00:20  Loss: 0.4390 (0.4939)  Acc@1: 93.7500 (95.5357)  Acc@5: 100.0000 (100.0000)  time: 0.4133  data: 0.0015  max mem: 1157\n",
            "Test: [Task 1]  [30/63]  eta: 0:00:15  Loss: 0.3494 (0.4385)  Acc@1: 100.0000 (96.7742)  Acc@5: 100.0000 (100.0000)  time: 0.4220  data: 0.0005  max mem: 1157\n",
            "Test: [Task 1]  [40/63]  eta: 0:00:10  Loss: 0.3218 (0.4334)  Acc@1: 100.0000 (96.9512)  Acc@5: 100.0000 (100.0000)  time: 0.4292  data: 0.0014  max mem: 1157\n",
            "Test: [Task 1]  [50/63]  eta: 0:00:05  Loss: 0.3670 (0.4215)  Acc@1: 100.0000 (97.1814)  Acc@5: 100.0000 (99.8775)  time: 0.4365  data: 0.0015  max mem: 1157\n",
            "Test: [Task 1]  [60/63]  eta: 0:00:01  Loss: 0.3710 (0.4158)  Acc@1: 100.0000 (97.4385)  Acc@5: 100.0000 (99.8975)  time: 0.4444  data: 0.0004  max mem: 1157\n",
            "Test: [Task 1]  [62/63]  eta: 0:00:00  Loss: 0.3670 (0.4151)  Acc@1: 100.0000 (97.5000)  Acc@5: 100.0000 (99.9000)  time: 0.4357  data: 0.0004  max mem: 1157\n",
            "Test: [Task 1] Total time: 0:00:28 (0.4466 s / it)\n",
            "* Acc@1 97.500 Acc@5 99.900 loss 0.415\n",
            "[Average accuracy till task1]\tAcc@1: 97.5000\tAcc@5: 99.9000\tLoss: 0.4151\n",
            "Loading checkpoint from: ./output/checkpoint/task2_checkpoint.pth\n",
            "Test: [Task 1]  [ 0/63]  eta: 0:00:46  Loss: 0.5565 (0.5565)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.7319  data: 0.3125  max mem: 1323\n",
            "Test: [Task 1]  [10/63]  eta: 0:00:25  Loss: 0.5089 (0.4841)  Acc@1: 93.7500 (92.0455)  Acc@5: 100.0000 (100.0000)  time: 0.4789  data: 0.0301  max mem: 1323\n",
            "Test: [Task 1]  [20/63]  eta: 0:00:20  Loss: 0.5089 (0.5326)  Acc@1: 93.7500 (90.4762)  Acc@5: 100.0000 (100.0000)  time: 0.4518  data: 0.0012  max mem: 1323\n",
            "Test: [Task 1]  [30/63]  eta: 0:00:15  Loss: 0.4271 (0.5053)  Acc@1: 93.7500 (91.3306)  Acc@5: 100.0000 (100.0000)  time: 0.4473  data: 0.0026  max mem: 1323\n",
            "Test: [Task 1]  [40/63]  eta: 0:00:10  Loss: 0.4271 (0.4990)  Acc@1: 93.7500 (91.3110)  Acc@5: 100.0000 (100.0000)  time: 0.4411  data: 0.0033  max mem: 1323\n",
            "Test: [Task 1]  [50/63]  eta: 0:00:05  Loss: 0.3878 (0.4723)  Acc@1: 93.7500 (92.1569)  Acc@5: 100.0000 (100.0000)  time: 0.4356  data: 0.0013  max mem: 1323\n",
            "Test: [Task 1]  [60/63]  eta: 0:00:01  Loss: 0.3878 (0.4665)  Acc@1: 93.7500 (92.5205)  Acc@5: 100.0000 (100.0000)  time: 0.4310  data: 0.0005  max mem: 1323\n",
            "Test: [Task 1]  [62/63]  eta: 0:00:00  Loss: 0.3878 (0.4631)  Acc@1: 100.0000 (92.7000)  Acc@5: 100.0000 (100.0000)  time: 0.4198  data: 0.0005  max mem: 1323\n",
            "Test: [Task 1] Total time: 0:00:27 (0.4436 s / it)\n",
            "* Acc@1 92.700 Acc@5 100.000 loss 0.463\n",
            "Test: [Task 2]  [ 0/63]  eta: 0:00:43  Loss: 0.5596 (0.5596)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.6878  data: 0.2899  max mem: 1323\n",
            "Test: [Task 2]  [10/63]  eta: 0:00:23  Loss: 0.5499 (0.5059)  Acc@1: 100.0000 (98.2955)  Acc@5: 100.0000 (99.4318)  time: 0.4474  data: 0.0269  max mem: 1323\n",
            "Test: [Task 2]  [20/63]  eta: 0:00:18  Loss: 0.5499 (0.5859)  Acc@1: 100.0000 (95.8333)  Acc@5: 100.0000 (99.4048)  time: 0.4233  data: 0.0005  max mem: 1323\n",
            "Test: [Task 2]  [30/63]  eta: 0:00:14  Loss: 0.5888 (0.5866)  Acc@1: 93.7500 (94.9597)  Acc@5: 100.0000 (99.1935)  time: 0.4214  data: 0.0025  max mem: 1323\n",
            "Test: [Task 2]  [40/63]  eta: 0:00:09  Loss: 0.5164 (0.5661)  Acc@1: 93.7500 (94.9695)  Acc@5: 100.0000 (99.2378)  time: 0.4190  data: 0.0033  max mem: 1323\n",
            "Test: [Task 2]  [50/63]  eta: 0:00:05  Loss: 0.4803 (0.5611)  Acc@1: 93.7500 (94.6078)  Acc@5: 100.0000 (99.1422)  time: 0.4184  data: 0.0013  max mem: 1323\n",
            "Test: [Task 2]  [60/63]  eta: 0:00:01  Loss: 0.4483 (0.5375)  Acc@1: 93.7500 (94.9795)  Acc@5: 100.0000 (99.2828)  time: 0.4185  data: 0.0004  max mem: 1323\n",
            "Test: [Task 2]  [62/63]  eta: 0:00:00  Loss: 0.4400 (0.5294)  Acc@1: 93.7500 (95.1000)  Acc@5: 100.0000 (99.3000)  time: 0.4081  data: 0.0004  max mem: 1323\n",
            "Test: [Task 2] Total time: 0:00:26 (0.4227 s / it)\n",
            "* Acc@1 95.100 Acc@5 99.300 loss 0.529\n",
            "[Average accuracy till task2]\tAcc@1: 93.9000\tAcc@5: 99.6500\tLoss: 0.4962\tForgetting: 4.8000\tBackward: -4.8000\n",
            "Loading checkpoint from: ./output/checkpoint/task3_checkpoint.pth\n",
            "Test: [Task 1]  [ 0/63]  eta: 0:00:43  Loss: 0.5769 (0.5769)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.6976  data: 0.3096  max mem: 1323\n",
            "Test: [Task 1]  [10/63]  eta: 0:00:23  Loss: 0.5445 (0.5064)  Acc@1: 93.7500 (88.6364)  Acc@5: 100.0000 (100.0000)  time: 0.4439  data: 0.0291  max mem: 1323\n",
            "Test: [Task 1]  [20/63]  eta: 0:00:18  Loss: 0.5417 (0.5556)  Acc@1: 87.5000 (88.3929)  Acc@5: 100.0000 (99.7024)  time: 0.4198  data: 0.0008  max mem: 1323\n",
            "Test: [Task 1]  [30/63]  eta: 0:00:14  Loss: 0.4876 (0.5435)  Acc@1: 87.5000 (88.9113)  Acc@5: 100.0000 (99.7984)  time: 0.4224  data: 0.0024  max mem: 1323\n",
            "Test: [Task 1]  [40/63]  eta: 0:00:09  Loss: 0.4551 (0.5286)  Acc@1: 93.7500 (89.3293)  Acc@5: 100.0000 (99.8476)  time: 0.4240  data: 0.0027  max mem: 1323\n",
            "Test: [Task 1]  [50/63]  eta: 0:00:05  Loss: 0.4254 (0.5032)  Acc@1: 93.7500 (90.3186)  Acc@5: 100.0000 (99.7549)  time: 0.4256  data: 0.0009  max mem: 1323\n",
            "Test: [Task 1]  [60/63]  eta: 0:00:01  Loss: 0.4094 (0.4914)  Acc@1: 93.7500 (90.6762)  Acc@5: 100.0000 (99.6926)  time: 0.4282  data: 0.0004  max mem: 1323\n",
            "Test: [Task 1]  [62/63]  eta: 0:00:00  Loss: 0.4007 (0.4889)  Acc@1: 93.7500 (90.8000)  Acc@5: 100.0000 (99.7000)  time: 0.4182  data: 0.0004  max mem: 1323\n",
            "Test: [Task 1] Total time: 0:00:26 (0.4267 s / it)\n",
            "* Acc@1 90.800 Acc@5 99.700 loss 0.489\n",
            "Test: [Task 2]  [ 0/63]  eta: 0:00:51  Loss: 0.6200 (0.6200)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.8223  data: 0.4178  max mem: 1323\n",
            "Test: [Task 2]  [10/63]  eta: 0:00:24  Loss: 0.5573 (0.5992)  Acc@1: 93.7500 (94.8864)  Acc@5: 100.0000 (98.2955)  time: 0.4668  data: 0.0412  max mem: 1323\n",
            "Test: [Task 2]  [20/63]  eta: 0:00:19  Loss: 0.5785 (0.6813)  Acc@1: 93.7500 (92.2619)  Acc@5: 100.0000 (98.8095)  time: 0.4324  data: 0.0020  max mem: 1323\n",
            "Test: [Task 2]  [30/63]  eta: 0:00:14  Loss: 0.6411 (0.6599)  Acc@1: 93.7500 (92.3387)  Acc@5: 100.0000 (98.3871)  time: 0.4328  data: 0.0008  max mem: 1323\n",
            "Test: [Task 2]  [40/63]  eta: 0:00:10  Loss: 0.6135 (0.6412)  Acc@1: 93.7500 (92.3780)  Acc@5: 100.0000 (98.6280)  time: 0.4316  data: 0.0033  max mem: 1323\n",
            "Test: [Task 2]  [50/63]  eta: 0:00:05  Loss: 0.5286 (0.6336)  Acc@1: 93.7500 (92.2794)  Acc@5: 100.0000 (98.6520)  time: 0.4306  data: 0.0029  max mem: 1323\n",
            "Test: [Task 2]  [60/63]  eta: 0:00:01  Loss: 0.5286 (0.6146)  Acc@1: 93.7500 (92.2131)  Acc@5: 100.0000 (98.8730)  time: 0.4297  data: 0.0003  max mem: 1323\n",
            "Test: [Task 2]  [62/63]  eta: 0:00:00  Loss: 0.5086 (0.6055)  Acc@1: 93.7500 (92.3000)  Acc@5: 100.0000 (98.9000)  time: 0.4185  data: 0.0003  max mem: 1323\n",
            "Test: [Task 2] Total time: 0:00:27 (0.4356 s / it)\n",
            "* Acc@1 92.300 Acc@5 98.900 loss 0.606\n",
            "Test: [Task 3]  [ 0/63]  eta: 0:00:49  Loss: 0.2661 (0.2661)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.7793  data: 0.3825  max mem: 1323\n",
            "Test: [Task 3]  [10/63]  eta: 0:00:24  Loss: 0.4616 (0.4745)  Acc@1: 87.5000 (89.2045)  Acc@5: 100.0000 (98.8636)  time: 0.4602  data: 0.0384  max mem: 1323\n",
            "Test: [Task 3]  [20/63]  eta: 0:00:19  Loss: 0.4914 (0.4960)  Acc@1: 87.5000 (89.5833)  Acc@5: 100.0000 (98.8095)  time: 0.4278  data: 0.0023  max mem: 1323\n",
            "Test: [Task 3]  [30/63]  eta: 0:00:14  Loss: 0.5654 (0.4790)  Acc@1: 93.7500 (90.3226)  Acc@5: 100.0000 (98.9919)  time: 0.4256  data: 0.0006  max mem: 1323\n",
            "Test: [Task 3]  [40/63]  eta: 0:00:09  Loss: 0.3778 (0.4795)  Acc@1: 93.7500 (90.8537)  Acc@5: 100.0000 (99.0854)  time: 0.4238  data: 0.0023  max mem: 1323\n",
            "Test: [Task 3]  [50/63]  eta: 0:00:05  Loss: 0.3778 (0.4763)  Acc@1: 93.7500 (91.0539)  Acc@5: 100.0000 (99.0196)  time: 0.4237  data: 0.0023  max mem: 1323\n",
            "Test: [Task 3]  [60/63]  eta: 0:00:01  Loss: 0.4568 (0.4831)  Acc@1: 93.7500 (90.9836)  Acc@5: 100.0000 (99.1803)  time: 0.4238  data: 0.0005  max mem: 1323\n",
            "Test: [Task 3]  [62/63]  eta: 0:00:00  Loss: 0.4795 (0.4846)  Acc@1: 87.5000 (90.9000)  Acc@5: 100.0000 (99.2000)  time: 0.4130  data: 0.0005  max mem: 1323\n",
            "Test: [Task 3] Total time: 0:00:27 (0.4288 s / it)\n",
            "* Acc@1 90.900 Acc@5 99.200 loss 0.485\n",
            "[Average accuracy till task3]\tAcc@1: 91.3333\tAcc@5: 99.2667\tLoss: 0.5263\tForgetting: 4.7500\tBackward: -4.7500\n",
            "Loading checkpoint from: ./output/checkpoint/task4_checkpoint.pth\n",
            "Test: [Task 1]  [ 0/63]  eta: 0:00:51  Loss: 0.6645 (0.6645)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.8232  data: 0.4286  max mem: 1323\n",
            "Test: [Task 1]  [10/63]  eta: 0:00:24  Loss: 0.4877 (0.5266)  Acc@1: 87.5000 (89.2045)  Acc@5: 100.0000 (99.4318)  time: 0.4598  data: 0.0432  max mem: 1323\n",
            "Test: [Task 1]  [20/63]  eta: 0:00:19  Loss: 0.5238 (0.5756)  Acc@1: 87.5000 (88.9881)  Acc@5: 100.0000 (99.1071)  time: 0.4234  data: 0.0027  max mem: 1323\n",
            "Test: [Task 1]  [30/63]  eta: 0:00:14  Loss: 0.5312 (0.5715)  Acc@1: 87.5000 (88.7097)  Acc@5: 100.0000 (99.1935)  time: 0.4237  data: 0.0006  max mem: 1323\n",
            "Test: [Task 1]  [40/63]  eta: 0:00:09  Loss: 0.4865 (0.5634)  Acc@1: 87.5000 (88.8720)  Acc@5: 100.0000 (99.3902)  time: 0.4237  data: 0.0024  max mem: 1323\n",
            "Test: [Task 1]  [50/63]  eta: 0:00:05  Loss: 0.4727 (0.5406)  Acc@1: 87.5000 (89.3382)  Acc@5: 100.0000 (99.5098)  time: 0.4235  data: 0.0024  max mem: 1323\n",
            "Test: [Task 1]  [60/63]  eta: 0:00:01  Loss: 0.4688 (0.5322)  Acc@1: 93.7500 (89.4467)  Acc@5: 100.0000 (99.2828)  time: 0.4248  data: 0.0005  max mem: 1323\n",
            "Test: [Task 1]  [62/63]  eta: 0:00:00  Loss: 0.4615 (0.5320)  Acc@1: 93.7500 (89.6000)  Acc@5: 100.0000 (99.3000)  time: 0.4144  data: 0.0005  max mem: 1323\n",
            "Test: [Task 1] Total time: 0:00:26 (0.4284 s / it)\n",
            "* Acc@1 89.600 Acc@5 99.300 loss 0.532\n",
            "Test: [Task 2]  [ 0/63]  eta: 0:00:47  Loss: 0.7674 (0.7674)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.7604  data: 0.3619  max mem: 1323\n",
            "Test: [Task 2]  [10/63]  eta: 0:00:24  Loss: 0.6293 (0.6542)  Acc@1: 87.5000 (90.3409)  Acc@5: 100.0000 (98.2955)  time: 0.4592  data: 0.0367  max mem: 1323\n",
            "Test: [Task 2]  [20/63]  eta: 0:00:19  Loss: 0.6496 (0.7237)  Acc@1: 87.5000 (88.9881)  Acc@5: 100.0000 (97.9167)  time: 0.4298  data: 0.0027  max mem: 1323\n",
            "Test: [Task 2]  [30/63]  eta: 0:00:14  Loss: 0.6496 (0.7138)  Acc@1: 93.7500 (90.1210)  Acc@5: 100.0000 (97.7823)  time: 0.4293  data: 0.0012  max mem: 1323\n",
            "Test: [Task 2]  [40/63]  eta: 0:00:10  Loss: 0.6273 (0.6947)  Acc@1: 93.7500 (90.0915)  Acc@5: 100.0000 (98.0183)  time: 0.4283  data: 0.0027  max mem: 1323\n",
            "Test: [Task 2]  [50/63]  eta: 0:00:05  Loss: 0.6153 (0.6913)  Acc@1: 87.5000 (89.2157)  Acc@5: 100.0000 (98.1618)  time: 0.4287  data: 0.0023  max mem: 1323\n",
            "Test: [Task 2]  [60/63]  eta: 0:00:01  Loss: 0.5578 (0.6705)  Acc@1: 87.5000 (89.6516)  Acc@5: 100.0000 (98.3607)  time: 0.4282  data: 0.0004  max mem: 1323\n",
            "Test: [Task 2]  [62/63]  eta: 0:00:00  Loss: 0.5578 (0.6615)  Acc@1: 87.5000 (89.7000)  Acc@5: 100.0000 (98.4000)  time: 0.4174  data: 0.0004  max mem: 1323\n",
            "Test: [Task 2] Total time: 0:00:27 (0.4322 s / it)\n",
            "* Acc@1 89.700 Acc@5 98.400 loss 0.662\n",
            "Test: [Task 3]  [ 0/63]  eta: 0:00:47  Loss: 0.3662 (0.3662)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.7595  data: 0.3426  max mem: 1323\n",
            "Test: [Task 3]  [10/63]  eta: 0:00:24  Loss: 0.5109 (0.5167)  Acc@1: 87.5000 (90.3409)  Acc@5: 100.0000 (98.8636)  time: 0.4567  data: 0.0357  max mem: 1323\n",
            "Test: [Task 3]  [20/63]  eta: 0:00:19  Loss: 0.5497 (0.5291)  Acc@1: 87.5000 (89.5833)  Acc@5: 100.0000 (98.5119)  time: 0.4272  data: 0.0030  max mem: 1323\n",
            "Test: [Task 3]  [30/63]  eta: 0:00:14  Loss: 0.5421 (0.5235)  Acc@1: 87.5000 (88.7097)  Acc@5: 100.0000 (98.7903)  time: 0.4269  data: 0.0008  max mem: 1323\n",
            "Test: [Task 3]  [40/63]  eta: 0:00:09  Loss: 0.4206 (0.5143)  Acc@1: 87.5000 (89.3293)  Acc@5: 100.0000 (99.0854)  time: 0.4254  data: 0.0030  max mem: 1323\n",
            "Test: [Task 3]  [50/63]  eta: 0:00:05  Loss: 0.4624 (0.5206)  Acc@1: 93.7500 (89.3382)  Acc@5: 100.0000 (98.8971)  time: 0.4260  data: 0.0030  max mem: 1323\n",
            "Test: [Task 3]  [60/63]  eta: 0:00:01  Loss: 0.5319 (0.5327)  Acc@1: 87.5000 (88.4221)  Acc@5: 100.0000 (99.0779)  time: 0.4253  data: 0.0004  max mem: 1323\n",
            "Test: [Task 3]  [62/63]  eta: 0:00:00  Loss: 0.5565 (0.5330)  Acc@1: 87.5000 (88.5000)  Acc@5: 100.0000 (99.1000)  time: 0.4143  data: 0.0004  max mem: 1323\n",
            "Test: [Task 3] Total time: 0:00:27 (0.4293 s / it)\n",
            "* Acc@1 88.500 Acc@5 99.100 loss 0.533\n",
            "Test: [Task 4]  [ 0/63]  eta: 0:00:47  Loss: 0.6950 (0.6950)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.7585  data: 0.3520  max mem: 1323\n",
            "Test: [Task 4]  [10/63]  eta: 0:00:24  Loss: 0.5117 (0.5535)  Acc@1: 93.7500 (89.2045)  Acc@5: 100.0000 (99.4318)  time: 0.4557  data: 0.0356  max mem: 1323\n",
            "Test: [Task 4]  [20/63]  eta: 0:00:18  Loss: 0.5090 (0.5704)  Acc@1: 87.5000 (87.2024)  Acc@5: 100.0000 (98.5119)  time: 0.4260  data: 0.0022  max mem: 1323\n",
            "Test: [Task 4]  [30/63]  eta: 0:00:14  Loss: 0.5090 (0.5546)  Acc@1: 87.5000 (88.3065)  Acc@5: 100.0000 (98.5887)  time: 0.4260  data: 0.0005  max mem: 1323\n",
            "Test: [Task 4]  [40/63]  eta: 0:00:09  Loss: 0.3947 (0.5098)  Acc@1: 93.7500 (89.6341)  Acc@5: 100.0000 (98.7805)  time: 0.4247  data: 0.0037  max mem: 1323\n",
            "Test: [Task 4]  [50/63]  eta: 0:00:05  Loss: 0.4213 (0.5220)  Acc@1: 93.7500 (89.9510)  Acc@5: 100.0000 (98.8971)  time: 0.4248  data: 0.0037  max mem: 1323\n",
            "Test: [Task 4]  [60/63]  eta: 0:00:01  Loss: 0.4480 (0.5399)  Acc@1: 87.5000 (89.3443)  Acc@5: 100.0000 (98.4631)  time: 0.4249  data: 0.0004  max mem: 1323\n",
            "Test: [Task 4]  [62/63]  eta: 0:00:00  Loss: 0.4336 (0.5326)  Acc@1: 87.5000 (89.6000)  Acc@5: 100.0000 (98.5000)  time: 0.4140  data: 0.0003  max mem: 1323\n",
            "Test: [Task 4] Total time: 0:00:27 (0.4290 s / it)\n",
            "* Acc@1 89.600 Acc@5 98.500 loss 0.533\n",
            "[Average accuracy till task4]\tAcc@1: 89.3500\tAcc@5: 98.8250\tLoss: 0.5648\tForgetting: 5.2333\tBackward: -5.2333\n",
            "Loading checkpoint from: ./output/checkpoint/task5_checkpoint.pth\n",
            "Test: [Task 1]  [ 0/63]  eta: 0:00:43  Loss: 0.7503 (0.7503)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.6951  data: 0.3004  max mem: 1323\n",
            "Test: [Task 1]  [10/63]  eta: 0:00:23  Loss: 0.5877 (0.5818)  Acc@1: 87.5000 (85.7955)  Acc@5: 100.0000 (99.4318)  time: 0.4501  data: 0.0314  max mem: 1323\n",
            "Test: [Task 1]  [20/63]  eta: 0:00:18  Loss: 0.5877 (0.6316)  Acc@1: 87.5000 (85.1190)  Acc@5: 100.0000 (98.8095)  time: 0.4259  data: 0.0026  max mem: 1323\n",
            "Test: [Task 1]  [30/63]  eta: 0:00:14  Loss: 0.6013 (0.6214)  Acc@1: 87.5000 (85.4839)  Acc@5: 100.0000 (98.9919)  time: 0.4250  data: 0.0008  max mem: 1323\n",
            "Test: [Task 1]  [40/63]  eta: 0:00:09  Loss: 0.5650 (0.6138)  Acc@1: 81.2500 (85.9756)  Acc@5: 100.0000 (98.9329)  time: 0.4239  data: 0.0025  max mem: 1323\n",
            "Test: [Task 1]  [50/63]  eta: 0:00:05  Loss: 0.4937 (0.5861)  Acc@1: 93.7500 (86.7647)  Acc@5: 100.0000 (99.0196)  time: 0.4239  data: 0.0022  max mem: 1323\n",
            "Test: [Task 1]  [60/63]  eta: 0:00:01  Loss: 0.4897 (0.5744)  Acc@1: 93.7500 (87.0902)  Acc@5: 100.0000 (98.9754)  time: 0.4237  data: 0.0004  max mem: 1323\n",
            "Test: [Task 1]  [62/63]  eta: 0:00:00  Loss: 0.4628 (0.5722)  Acc@1: 93.7500 (87.2000)  Acc@5: 100.0000 (99.0000)  time: 0.4131  data: 0.0003  max mem: 1323\n",
            "Test: [Task 1] Total time: 0:00:26 (0.4270 s / it)\n",
            "* Acc@1 87.200 Acc@5 99.000 loss 0.572\n",
            "Test: [Task 2]  [ 0/63]  eta: 0:00:49  Loss: 0.7777 (0.7777)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.7784  data: 0.3800  max mem: 1323\n",
            "Test: [Task 2]  [10/63]  eta: 0:00:24  Loss: 0.6821 (0.7217)  Acc@1: 87.5000 (88.0682)  Acc@5: 100.0000 (97.1591)  time: 0.4558  data: 0.0388  max mem: 1323\n",
            "Test: [Task 2]  [20/63]  eta: 0:00:18  Loss: 0.7135 (0.7628)  Acc@1: 87.5000 (85.7143)  Acc@5: 100.0000 (97.9167)  time: 0.4247  data: 0.0027  max mem: 1323\n",
            "Test: [Task 2]  [30/63]  eta: 0:00:14  Loss: 0.7374 (0.7516)  Acc@1: 87.5000 (86.4919)  Acc@5: 100.0000 (96.9758)  time: 0.4249  data: 0.0007  max mem: 1323\n",
            "Test: [Task 2]  [40/63]  eta: 0:00:09  Loss: 0.7374 (0.7364)  Acc@1: 87.5000 (86.8902)  Acc@5: 100.0000 (97.2561)  time: 0.4236  data: 0.0030  max mem: 1323\n",
            "Test: [Task 2]  [50/63]  eta: 0:00:05  Loss: 0.6470 (0.7321)  Acc@1: 87.5000 (86.2745)  Acc@5: 100.0000 (97.4265)  time: 0.4235  data: 0.0029  max mem: 1323\n",
            "Test: [Task 2]  [60/63]  eta: 0:00:01  Loss: 0.5891 (0.7054)  Acc@1: 87.5000 (86.7828)  Acc@5: 100.0000 (97.7459)  time: 0.4238  data: 0.0004  max mem: 1323\n",
            "Test: [Task 2]  [62/63]  eta: 0:00:00  Loss: 0.5881 (0.6963)  Acc@1: 87.5000 (86.9000)  Acc@5: 100.0000 (97.8000)  time: 0.4131  data: 0.0003  max mem: 1323\n",
            "Test: [Task 2] Total time: 0:00:26 (0.4278 s / it)\n",
            "* Acc@1 86.900 Acc@5 97.800 loss 0.696\n",
            "Test: [Task 3]  [ 0/63]  eta: 0:00:45  Loss: 0.4146 (0.4146)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.7213  data: 0.3193  max mem: 1323\n",
            "Test: [Task 3]  [10/63]  eta: 0:00:23  Loss: 0.5895 (0.5824)  Acc@1: 81.2500 (84.0909)  Acc@5: 100.0000 (98.8636)  time: 0.4522  data: 0.0328  max mem: 1323\n",
            "Test: [Task 3]  [20/63]  eta: 0:00:18  Loss: 0.5940 (0.6018)  Acc@1: 81.2500 (83.9286)  Acc@5: 100.0000 (97.9167)  time: 0.4260  data: 0.0024  max mem: 1323\n",
            "Test: [Task 3]  [30/63]  eta: 0:00:14  Loss: 0.5752 (0.5908)  Acc@1: 87.5000 (84.4758)  Acc@5: 100.0000 (98.3871)  time: 0.4258  data: 0.0006  max mem: 1323\n",
            "Test: [Task 3]  [40/63]  eta: 0:00:09  Loss: 0.4465 (0.5813)  Acc@1: 87.5000 (85.6707)  Acc@5: 100.0000 (98.6280)  time: 0.4239  data: 0.0027  max mem: 1323\n",
            "Test: [Task 3]  [50/63]  eta: 0:00:05  Loss: 0.5805 (0.5876)  Acc@1: 87.5000 (86.0294)  Acc@5: 100.0000 (98.2843)  time: 0.4236  data: 0.0028  max mem: 1323\n",
            "Test: [Task 3]  [60/63]  eta: 0:00:01  Loss: 0.5805 (0.5934)  Acc@1: 87.5000 (86.0656)  Acc@5: 100.0000 (98.3607)  time: 0.4241  data: 0.0006  max mem: 1323\n",
            "Test: [Task 3]  [62/63]  eta: 0:00:00  Loss: 0.5815 (0.5924)  Acc@1: 87.5000 (86.0000)  Acc@5: 100.0000 (98.4000)  time: 0.4131  data: 0.0006  max mem: 1323\n",
            "Test: [Task 3] Total time: 0:00:26 (0.4271 s / it)\n",
            "* Acc@1 86.000 Acc@5 98.400 loss 0.592\n",
            "Test: [Task 4]  [ 0/63]  eta: 0:00:35  Loss: 0.8205 (0.8205)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.5605  data: 0.1669  max mem: 1323\n",
            "Test: [Task 4]  [10/63]  eta: 0:00:23  Loss: 0.5514 (0.5958)  Acc@1: 87.5000 (86.3636)  Acc@5: 100.0000 (98.8636)  time: 0.4378  data: 0.0197  max mem: 1323\n",
            "Test: [Task 4]  [20/63]  eta: 0:00:18  Loss: 0.5422 (0.6171)  Acc@1: 81.2500 (83.9286)  Acc@5: 100.0000 (97.6190)  time: 0.4258  data: 0.0029  max mem: 1323\n",
            "Test: [Task 4]  [30/63]  eta: 0:00:14  Loss: 0.5584 (0.6035)  Acc@1: 87.5000 (85.6855)  Acc@5: 93.7500 (97.1774)  time: 0.4249  data: 0.0007  max mem: 1323\n",
            "Test: [Task 4]  [40/63]  eta: 0:00:09  Loss: 0.4335 (0.5564)  Acc@1: 93.7500 (87.5000)  Acc@5: 100.0000 (97.7134)  time: 0.4239  data: 0.0012  max mem: 1323\n",
            "Test: [Task 4]  [50/63]  eta: 0:00:05  Loss: 0.4229 (0.5715)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (97.6716)  time: 0.4247  data: 0.0017  max mem: 1323\n",
            "Test: [Task 4]  [60/63]  eta: 0:00:01  Loss: 0.5442 (0.5883)  Acc@1: 87.5000 (87.0902)  Acc@5: 100.0000 (97.4385)  time: 0.4246  data: 0.0013  max mem: 1323\n",
            "Test: [Task 4]  [62/63]  eta: 0:00:00  Loss: 0.4782 (0.5853)  Acc@1: 87.5000 (87.3000)  Acc@5: 100.0000 (97.5000)  time: 0.4141  data: 0.0007  max mem: 1323\n",
            "Test: [Task 4] Total time: 0:00:26 (0.4246 s / it)\n",
            "* Acc@1 87.300 Acc@5 97.500 loss 0.585\n",
            "Test: [Task 5]  [ 0/63]  eta: 0:00:38  Loss: 0.2273 (0.2273)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.6062  data: 0.2136  max mem: 1323\n",
            "Test: [Task 5]  [10/63]  eta: 0:00:23  Loss: 0.4662 (0.5839)  Acc@1: 87.5000 (89.2045)  Acc@5: 100.0000 (97.7273)  time: 0.4432  data: 0.0225  max mem: 1323\n",
            "Test: [Task 5]  [20/63]  eta: 0:00:18  Loss: 0.4662 (0.5364)  Acc@1: 93.7500 (90.4762)  Acc@5: 100.0000 (97.6190)  time: 0.4262  data: 0.0020  max mem: 1323\n",
            "Test: [Task 5]  [30/63]  eta: 0:00:14  Loss: 0.4013 (0.5155)  Acc@1: 93.7500 (90.3226)  Acc@5: 100.0000 (97.9839)  time: 0.4254  data: 0.0028  max mem: 1323\n",
            "Test: [Task 5]  [40/63]  eta: 0:00:09  Loss: 0.3784 (0.4897)  Acc@1: 93.7500 (90.5488)  Acc@5: 100.0000 (98.0183)  time: 0.4246  data: 0.0057  max mem: 1323\n",
            "Test: [Task 5]  [50/63]  eta: 0:00:05  Loss: 0.4565 (0.4885)  Acc@1: 93.7500 (91.0539)  Acc@5: 100.0000 (98.1618)  time: 0.4242  data: 0.0043  max mem: 1323\n",
            "Test: [Task 5]  [60/63]  eta: 0:00:01  Loss: 0.4768 (0.4925)  Acc@1: 93.7500 (90.7787)  Acc@5: 100.0000 (98.1557)  time: 0.4247  data: 0.0014  max mem: 1323\n",
            "Test: [Task 5]  [62/63]  eta: 0:00:00  Loss: 0.4816 (0.5123)  Acc@1: 87.5000 (90.4000)  Acc@5: 100.0000 (98.0000)  time: 0.4143  data: 0.0007  max mem: 1323\n",
            "Test: [Task 5] Total time: 0:00:26 (0.4258 s / it)\n",
            "* Acc@1 90.400 Acc@5 98.000 loss 0.512\n",
            "[Average accuracy till task5]\tAcc@1: 87.5600\tAcc@5: 98.1400\tLoss: 0.5917\tForgetting: 6.4250\tBackward: -6.4250\n",
            "Loading checkpoint from: ./output/checkpoint/task6_checkpoint.pth\n",
            "Test: [Task 1]  [ 0/63]  eta: 0:00:37  Loss: 0.8777 (0.8777)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.5953  data: 0.2039  max mem: 1323\n",
            "Test: [Task 1]  [10/63]  eta: 0:00:23  Loss: 0.7007 (0.6269)  Acc@1: 87.5000 (85.2273)  Acc@5: 100.0000 (98.2955)  time: 0.4412  data: 0.0222  max mem: 1323\n",
            "Test: [Task 1]  [20/63]  eta: 0:00:18  Loss: 0.7007 (0.6898)  Acc@1: 81.2500 (81.8452)  Acc@5: 100.0000 (97.9167)  time: 0.4265  data: 0.0032  max mem: 1323\n",
            "Test: [Task 1]  [30/63]  eta: 0:00:14  Loss: 0.6036 (0.6643)  Acc@1: 81.2500 (82.8629)  Acc@5: 100.0000 (98.3871)  time: 0.4264  data: 0.0014  max mem: 1323\n",
            "Test: [Task 1]  [40/63]  eta: 0:00:09  Loss: 0.5757 (0.6480)  Acc@1: 81.2500 (83.5366)  Acc@5: 100.0000 (98.6280)  time: 0.4254  data: 0.0015  max mem: 1323\n",
            "Test: [Task 1]  [50/63]  eta: 0:00:05  Loss: 0.5014 (0.6183)  Acc@1: 87.5000 (84.5588)  Acc@5: 100.0000 (98.7745)  time: 0.4253  data: 0.0026  max mem: 1323\n",
            "Test: [Task 1]  [60/63]  eta: 0:00:01  Loss: 0.4991 (0.6024)  Acc@1: 87.5000 (85.5533)  Acc@5: 100.0000 (98.6680)  time: 0.4256  data: 0.0018  max mem: 1323\n",
            "Test: [Task 1]  [62/63]  eta: 0:00:00  Loss: 0.4555 (0.5968)  Acc@1: 93.7500 (85.9000)  Acc@5: 100.0000 (98.7000)  time: 0.4150  data: 0.0011  max mem: 1323\n",
            "Test: [Task 1] Total time: 0:00:26 (0.4263 s / it)\n",
            "* Acc@1 85.900 Acc@5 98.700 loss 0.597\n",
            "Test: [Task 2]  [ 0/63]  eta: 0:00:38  Loss: 0.8147 (0.8147)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)  time: 0.6101  data: 0.2194  max mem: 1323\n",
            "Test: [Task 2]  [10/63]  eta: 0:00:23  Loss: 0.7636 (0.7247)  Acc@1: 87.5000 (86.3636)  Acc@5: 100.0000 (97.1591)  time: 0.4420  data: 0.0225  max mem: 1323\n",
            "Test: [Task 2]  [20/63]  eta: 0:00:18  Loss: 0.6940 (0.7668)  Acc@1: 81.2500 (83.6310)  Acc@5: 100.0000 (97.0238)  time: 0.4261  data: 0.0025  max mem: 1323\n",
            "Test: [Task 2]  [30/63]  eta: 0:00:14  Loss: 0.6940 (0.7430)  Acc@1: 81.2500 (84.6774)  Acc@5: 100.0000 (96.7742)  time: 0.4255  data: 0.0013  max mem: 1323\n",
            "Test: [Task 2]  [40/63]  eta: 0:00:09  Loss: 0.6262 (0.7242)  Acc@1: 87.5000 (85.0610)  Acc@5: 100.0000 (96.9512)  time: 0.4244  data: 0.0014  max mem: 1323\n",
            "Test: [Task 2]  [50/63]  eta: 0:00:05  Loss: 0.6082 (0.7159)  Acc@1: 81.2500 (84.5588)  Acc@5: 100.0000 (97.0588)  time: 0.4249  data: 0.0031  max mem: 1323\n",
            "Test: [Task 2]  [60/63]  eta: 0:00:01  Loss: 0.6082 (0.6972)  Acc@1: 81.2500 (85.2459)  Acc@5: 100.0000 (97.4385)  time: 0.4257  data: 0.0020  max mem: 1323\n",
            "Test: [Task 2]  [62/63]  eta: 0:00:00  Loss: 0.5469 (0.6881)  Acc@1: 87.5000 (85.3000)  Acc@5: 100.0000 (97.5000)  time: 0.4153  data: 0.0013  max mem: 1323\n",
            "Test: [Task 2] Total time: 0:00:26 (0.4261 s / it)\n",
            "* Acc@1 85.300 Acc@5 97.500 loss 0.688\n",
            "Test: [Task 3]  [ 0/63]  eta: 0:00:34  Loss: 0.3517 (0.3517)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.5474  data: 0.1510  max mem: 1323\n",
            "Test: [Task 3]  [10/63]  eta: 0:00:23  Loss: 0.6365 (0.5770)  Acc@1: 87.5000 (85.7955)  Acc@5: 100.0000 (98.2955)  time: 0.4357  data: 0.0159  max mem: 1323\n",
            "Test: [Task 3]  [20/63]  eta: 0:00:18  Loss: 0.6459 (0.5970)  Acc@1: 81.2500 (83.6310)  Acc@5: 100.0000 (98.2143)  time: 0.4260  data: 0.0030  max mem: 1323\n",
            "Test: [Task 3]  [30/63]  eta: 0:00:14  Loss: 0.6490 (0.6000)  Acc@1: 81.2500 (84.0726)  Acc@5: 100.0000 (98.5887)  time: 0.4264  data: 0.0020  max mem: 1323\n",
            "Test: [Task 3]  [40/63]  eta: 0:00:09  Loss: 0.6220 (0.5987)  Acc@1: 87.5000 (84.9085)  Acc@5: 100.0000 (98.4756)  time: 0.4255  data: 0.0008  max mem: 1323\n",
            "Test: [Task 3]  [50/63]  eta: 0:00:05  Loss: 0.6431 (0.6057)  Acc@1: 87.5000 (85.2941)  Acc@5: 100.0000 (98.2843)  time: 0.4255  data: 0.0027  max mem: 1323\n",
            "Test: [Task 3]  [60/63]  eta: 0:00:01  Loss: 0.6241 (0.6138)  Acc@1: 87.5000 (85.0410)  Acc@5: 100.0000 (98.3607)  time: 0.4249  data: 0.0023  max mem: 1323\n",
            "Test: [Task 3]  [62/63]  eta: 0:00:00  Loss: 0.6743 (0.6135)  Acc@1: 87.5000 (85.1000)  Acc@5: 100.0000 (98.3000)  time: 0.4144  data: 0.0016  max mem: 1323\n",
            "Test: [Task 3] Total time: 0:00:26 (0.4250 s / it)\n",
            "* Acc@1 85.100 Acc@5 98.300 loss 0.613\n",
            "Test: [Task 4]  [ 0/63]  eta: 0:00:35  Loss: 0.8177 (0.8177)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.5660  data: 0.1683  max mem: 1323\n",
            "Test: [Task 4]  [10/63]  eta: 0:00:23  Loss: 0.7502 (0.6813)  Acc@1: 81.2500 (82.9545)  Acc@5: 100.0000 (97.1591)  time: 0.4391  data: 0.0169  max mem: 1323\n",
            "Test: [Task 4]  [20/63]  eta: 0:00:18  Loss: 0.6663 (0.6685)  Acc@1: 81.2500 (82.4405)  Acc@5: 100.0000 (97.0238)  time: 0.4269  data: 0.0018  max mem: 1323\n",
            "Test: [Task 4]  [30/63]  eta: 0:00:14  Loss: 0.5057 (0.6269)  Acc@1: 87.5000 (84.2742)  Acc@5: 100.0000 (97.3790)  time: 0.4266  data: 0.0012  max mem: 1323\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m torch.distributed.launch --nproc_per_node=1 --use_env /content/l2p-pytorch/main.py TinyImagenet --eval"
      ],
      "metadata": {
        "id": "O6gAp7JXsW7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m torch.distributed.launch --nproc_per_node=1 --use_env /content/l2p-pytorch/main.py Imagenet-R --eval"
      ],
      "metadata": {
        "id": "v_s5jV_xsGF7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}